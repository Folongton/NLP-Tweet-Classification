{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'data/tweet_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(785916, 18)\n",
      "Index(['tweetID', 'crDate', 'edInput', 'editor', 'engages', 'isApproved',\n",
      "       'isEdNeed', 'isRT', 'likes', 'photoUrl', 'retweets', 'rtUsID', 'text',\n",
      "       'topicName', 'usFlwrs', 'usID', 'usName', 'videoUrl'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetID</th>\n",
       "      <th>crDate</th>\n",
       "      <th>edInput</th>\n",
       "      <th>editor</th>\n",
       "      <th>engages</th>\n",
       "      <th>isApproved</th>\n",
       "      <th>isEdNeed</th>\n",
       "      <th>isRT</th>\n",
       "      <th>likes</th>\n",
       "      <th>photoUrl</th>\n",
       "      <th>retweets</th>\n",
       "      <th>rtUsID</th>\n",
       "      <th>text</th>\n",
       "      <th>topicName</th>\n",
       "      <th>usFlwrs</th>\n",
       "      <th>usID</th>\n",
       "      <th>usName</th>\n",
       "      <th>videoUrl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1070867471245164544</td>\n",
       "      <td>2018-12-07 02:27:55</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>98</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>https://pbs.twimg.com/media/Dtx8SiIWkAImVsb.jpg</td>\n",
       "      <td>34</td>\n",
       "      <td>-1</td>\n",
       "      <td>The immediate impulse for an alliance of the EU's northern states is Brexit https://t.co/nlhUD36hay https://t.co/shwMWpjjuK</td>\n",
       "      <td>Business</td>\n",
       "      <td>23464532</td>\n",
       "      <td>5988062</td>\n",
       "      <td>The Economist</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1070868017888837633</td>\n",
       "      <td>2018-12-07 02:30:05</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>https://pbs.twimg.com/media/Dtx8yTyW4AEciqP.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>America's economy is flashing some warning signs, but -- for now -- the labor market appears to be going strong https://t.co/xvCPgtqMzy https://t.co/0sQdzAsME3</td>\n",
       "      <td>Business</td>\n",
       "      <td>1732809</td>\n",
       "      <td>16184358</td>\n",
       "      <td>CNN Business</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tweetID               crDate  edInput  editor  engages  \\\n",
       "0  1070867471245164544  2018-12-07 02:27:55       -1      -1       98   \n",
       "1  1070868017888837633  2018-12-07 02:30:05       -1      -1       13   \n",
       "\n",
       "   isApproved  isEdNeed   isRT  likes  \\\n",
       "0       False      True  False     64   \n",
       "1       False      True  False     10   \n",
       "\n",
       "                                          photoUrl  retweets  rtUsID  \\\n",
       "0  https://pbs.twimg.com/media/Dtx8SiIWkAImVsb.jpg        34      -1   \n",
       "1  https://pbs.twimg.com/media/Dtx8yTyW4AEciqP.jpg         3      -1   \n",
       "\n",
       "                                                                                                                                                              text  \\\n",
       "0                                      The immediate impulse for an alliance of the EU's northern states is Brexit https://t.co/nlhUD36hay https://t.co/shwMWpjjuK   \n",
       "1  America's economy is flashing some warning signs, but -- for now -- the labor market appears to be going strong https://t.co/xvCPgtqMzy https://t.co/0sQdzAsME3   \n",
       "\n",
       "  topicName   usFlwrs      usID         usName videoUrl  \n",
       "0  Business  23464532   5988062  The Economist      NaN  \n",
       "1  Business   1732809  16184358   CNN Business      NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.columns)\n",
    "df.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* After observation of the data, we can see :\n",
    "1. Columns which are definitelly not be used: crDate, engages, likes, photoUrl, retweets, usFlwrs, rtUsID, usID, videoUrl - will be dropped.\n",
    "2. Columns which will be definitelly used: tweetID(for indexing purposes), edInput(Label), text, topicName\n",
    "3. Columns which need more analysis: editor, isApproved, isEdNeed, isRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['tweetID', 'edInput', 'editor', 'isApproved',\n",
    "       'isEdNeed', 'isRT', 'text',\n",
    "       'topicName', 'usName', ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetID</th>\n",
       "      <th>edInput</th>\n",
       "      <th>editor</th>\n",
       "      <th>isApproved</th>\n",
       "      <th>isEdNeed</th>\n",
       "      <th>isRT</th>\n",
       "      <th>text</th>\n",
       "      <th>topicName</th>\n",
       "      <th>usName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1070867471245164544</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>The immediate impulse for an alliance of the EU's northern states is Brexit https://t.co/nlhUD36hay https://t.co/shwMWpjjuK</td>\n",
       "      <td>Business</td>\n",
       "      <td>The Economist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1070868017888837633</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>America's economy is flashing some warning signs, but -- for now -- the labor market appears to be going strong https://t.co/xvCPgtqMzy https://t.co/0sQdzAsME3</td>\n",
       "      <td>Business</td>\n",
       "      <td>CNN Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1070868012864028673</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Lyft files for what is expected to be one of the hottest IPOs in 2019 https://t.co/qEjyniazlD</td>\n",
       "      <td>Business</td>\n",
       "      <td>FORTUNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1070867995239555075</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Exporters still waiting to get Rs 6,000 crore worth of input tax credit refunds\\n\\nMany being denied tax refunds by state governments, such as Andhra Pradesh, Uttar Pradesh, Bihar and Chhattisgarh, who say they are cash starved\\n\\n@Subhayan_ism @GST_Council\\n\\nhttps://t.co/QRBg8b98Rr</td>\n",
       "      <td>Business</td>\n",
       "      <td>Business Standard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1070867995205885952</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Ride-hailing firm Lyft races to leave Uber behind in IPO chase https://t.co/0qCsdx2LYS https://t.co/gHZLUntYkL</td>\n",
       "      <td>Business</td>\n",
       "      <td>Reuters Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785911</th>\n",
       "      <td>1147325851614117888</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Relations are DIFFERENT\\nnot DIFFICULT.</td>\n",
       "      <td>Motivational</td>\n",
       "      <td>Wit &amp; Wisdom üíØ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785912</th>\n",
       "      <td>1153184058714624001</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>\"to live a creative life, we must lose our fear of being wrong\"......... https://t.co/LF0e0xV5Q7</td>\n",
       "      <td>Interesting</td>\n",
       "      <td>DeepFeling‚Ñ¢</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785913</th>\n",
       "      <td>1153048802116292608</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Who's your comic crush? https://t.co/H29dhXw3kf</td>\n",
       "      <td>Memes</td>\n",
       "      <td>Twitter Movies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785914</th>\n",
       "      <td>1154063052997836801</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>After a flight of 195 hours, 18 minutes, 35 seconds - the #Apollo11 crew splashed down in the North Pacific Ocean, 900 miles southwest of Hawaii! Here‚Äôs a photo of their recovery as we celebrate the #Apollo50th anniversary: https://t.co/Y4zhGTQlPj https://t.co/fBpvcECsjp</td>\n",
       "      <td>Random</td>\n",
       "      <td>NASA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785915</th>\n",
       "      <td>1073723027718688768</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Scarface's Action Figure Tony Montana cutting open a pack of Flour on a kitchen table\\n(by artist VSE OK) https://t.co/vOqvOh7EFn</td>\n",
       "      <td>Photography</td>\n",
       "      <td>41 Strange</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>785916 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    tweetID  edInput  editor  isApproved  isEdNeed   isRT  \\\n",
       "0       1070867471245164544       -1      -1       False      True  False   \n",
       "1       1070868017888837633       -1      -1       False      True  False   \n",
       "2       1070868012864028673       -1      -1       False      True  False   \n",
       "3       1070867995239555075       -1      -1       False      True  False   \n",
       "4       1070867995205885952       -1      -1       False      True  False   \n",
       "...                     ...      ...     ...         ...       ...    ...   \n",
       "785911  1147325851614117888       -1      -1       False      True   True   \n",
       "785912  1153184058714624001       -1      -1       False      True   True   \n",
       "785913  1153048802116292608       -1      -1       False      True   True   \n",
       "785914  1154063052997836801       -1      -1        True      True  False   \n",
       "785915  1073723027718688768       -1      -1       False      True   True   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                text  \\\n",
       "0                                                                                                                                                                        The immediate impulse for an alliance of the EU's northern states is Brexit https://t.co/nlhUD36hay https://t.co/shwMWpjjuK   \n",
       "1                                                                                                                                    America's economy is flashing some warning signs, but -- for now -- the labor market appears to be going strong https://t.co/xvCPgtqMzy https://t.co/0sQdzAsME3   \n",
       "2                                                                                                                                                                                                      Lyft files for what is expected to be one of the hottest IPOs in 2019 https://t.co/qEjyniazlD   \n",
       "3       Exporters still waiting to get Rs 6,000 crore worth of input tax credit refunds\\n\\nMany being denied tax refunds by state governments, such as Andhra Pradesh, Uttar Pradesh, Bihar and Chhattisgarh, who say they are cash starved\\n\\n@Subhayan_ism @GST_Council\\n\\nhttps://t.co/QRBg8b98Rr   \n",
       "4                                                                                                                                                                                     Ride-hailing firm Lyft races to leave Uber behind in IPO chase https://t.co/0qCsdx2LYS https://t.co/gHZLUntYkL   \n",
       "...                                                                                                                                                                                                                                                                                              ...   \n",
       "785911                                                                                                                                                                                                                                                       Relations are DIFFERENT\\nnot DIFFICULT.   \n",
       "785912                                                                                                                                                                                              \"to live a creative life, we must lose our fear of being wrong\"......... https://t.co/LF0e0xV5Q7   \n",
       "785913                                                                                                                                                                                                                                               Who's your comic crush? https://t.co/H29dhXw3kf   \n",
       "785914               After a flight of 195 hours, 18 minutes, 35 seconds - the #Apollo11 crew splashed down in the North Pacific Ocean, 900 miles southwest of Hawaii! Here‚Äôs a photo of their recovery as we celebrate the #Apollo50th anniversary: https://t.co/Y4zhGTQlPj https://t.co/fBpvcECsjp   \n",
       "785915                                                                                                                                                             Scarface's Action Figure Tony Montana cutting open a pack of Flour on a kitchen table\\n(by artist VSE OK) https://t.co/vOqvOh7EFn   \n",
       "\n",
       "           topicName             usName  \n",
       "0           Business      The Economist  \n",
       "1           Business       CNN Business  \n",
       "2           Business            FORTUNE  \n",
       "3           Business  Business Standard  \n",
       "4           Business   Reuters Business  \n",
       "...              ...                ...  \n",
       "785911  Motivational     Wit & Wisdom üíØ  \n",
       "785912   Interesting        DeepFeling‚Ñ¢  \n",
       "785913         Memes     Twitter Movies  \n",
       "785914        Random               NASA  \n",
       "785915   Photography         41 Strange  \n",
       "\n",
       "[785916 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 785916 entries, 0 to 785915\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   tweetID     785916 non-null  int64 \n",
      " 1   edInput     785916 non-null  int64 \n",
      " 2   editor      785916 non-null  int64 \n",
      " 3   isApproved  785916 non-null  bool  \n",
      " 4   isEdNeed    785916 non-null  bool  \n",
      " 5   isRT        785916 non-null  bool  \n",
      " 6   text        785916 non-null  object\n",
      " 7   topicName   785916 non-null  object\n",
      " 8   usName      785916 non-null  object\n",
      "dtypes: bool(3), int64(3), object(3)\n",
      "memory usage: 38.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    422665\n",
       " 1    215577\n",
       " 2    106741\n",
       " 4     32733\n",
       " 3      8200\n",
       "Name: edInput, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['edInput'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1       422665\n",
       " 5004     68536\n",
       " 5003     68186\n",
       " 5002     59317\n",
       " 5001     52629\n",
       " 5006     40658\n",
       " 5007     27722\n",
       " 5005     24934\n",
       " 5008     21167\n",
       " 5101        44\n",
       " 1001        36\n",
       " 2001        22\n",
       "Name: editor, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['editor'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True    785916\n",
       "Name: isEdNeed, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['isEdNeed'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Dropping 'isEdNeed' as it is the same values for all the rows. Dropping 'editor' as this seems to be an editor IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['isEdNeed','editor'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* we can drop rows with 'edinput' other than -1,1,2 as we don't know what they mean and more client communication needed to understand them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['edInput'].isin([-1,1,2])]\n",
    "df = df.set_index('tweetID', drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(744983, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edInput</th>\n",
       "      <th>isApproved</th>\n",
       "      <th>isRT</th>\n",
       "      <th>text</th>\n",
       "      <th>topicName</th>\n",
       "      <th>usName</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweetID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1070867471245164544</th>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>The immediate impulse for an alliance of the EU's northern states is Brexit https://t.co/nlhUD36hay https://t.co/shwMWpjjuK</td>\n",
       "      <td>Business</td>\n",
       "      <td>The Economist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070868017888837633</th>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>America's economy is flashing some warning signs, but -- for now -- the labor market appears to be going strong https://t.co/xvCPgtqMzy https://t.co/0sQdzAsME3</td>\n",
       "      <td>Business</td>\n",
       "      <td>CNN Business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     edInput  isApproved   isRT  \\\n",
       "tweetID                                           \n",
       "1070867471245164544       -1       False  False   \n",
       "1070868017888837633       -1       False  False   \n",
       "\n",
       "                                                                                                                                                                                text  \\\n",
       "tweetID                                                                                                                                                                                \n",
       "1070867471245164544                                      The immediate impulse for an alliance of the EU's northern states is Brexit https://t.co/nlhUD36hay https://t.co/shwMWpjjuK   \n",
       "1070868017888837633  America's economy is flashing some warning signs, but -- for now -- the labor market appears to be going strong https://t.co/xvCPgtqMzy https://t.co/0sQdzAsME3   \n",
       "\n",
       "                    topicName         usName  \n",
       "tweetID                                       \n",
       "1070867471245164544  Business  The Economist  \n",
       "1070868017888837633  Business   CNN Business  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's run correlation matrix to see if we not missing anything before dropping IsApproved and isRT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edInput</th>\n",
       "      <th>isApproved</th>\n",
       "      <th>isRT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>edInput</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.246425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isApproved</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.246425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isRT</th>\n",
       "      <td>0.246425</td>\n",
       "      <td>-0.246425</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             edInput  isApproved      isRT\n",
       "edInput     1.000000   -1.000000  0.246425\n",
       "isApproved -1.000000    1.000000 -0.246425\n",
       "isRT        0.246425   -0.246425  1.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['edInput']!=-1][['edInput','isApproved','isRT']].corr()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As we see from the correlation matrix, we can drop 'isApproved' as it is the same as our label.\n",
    "* isRT column - after quick google search it seems that it is a boolean column which indicates if the tweet is a retweet or not. We can remove it.\n",
    "* We also split the data into labeled and not yet labeled data. We need labeled data in order to train our model. I'll keep our unlabeled data to use it later for predictions on the \"real world\" data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['isApproved','isRT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unlabeled = df[df['edInput']==-1]\n",
    "df = df[df['edInput']!=-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(422665, 4)\n",
      "(322318, 4)\n"
     ]
    }
   ],
   "source": [
    "print(df_unlabeled.shape)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['edInput', 'text', 'topicName', 'usName'], dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edInput</th>\n",
       "      <th>topicName</th>\n",
       "      <th>usName</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweetID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1070970722598707200</th>\n",
       "      <td>1</td>\n",
       "      <td>Fashion</td>\n",
       "      <td>Gentleman‚Äôs style</td>\n",
       "      <td>Which one would you choose? üëÄ https://t.co/U0s3alfBNp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070981773616648193</th>\n",
       "      <td>1</td>\n",
       "      <td>Interesting</td>\n",
       "      <td>Satisfying Slime</td>\n",
       "      <td>How it‚Äôs made. üòä https://t.co/3XjOw4gIkg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916500037818916866</th>\n",
       "      <td>2</td>\n",
       "      <td>Interesting</td>\n",
       "      <td>Tips &amp; Tricks Ideas ‚úå</td>\n",
       "      <td>Smile, because it confuses people. Smile, because it‚Äôs easier than explaining what is killing you inside. https://t.co/FGlnnRfP5w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071135340696625152</th>\n",
       "      <td>1</td>\n",
       "      <td>Art</td>\n",
       "      <td>ùê¥ùëüùë°.</td>\n",
       "      <td>ùê∂ùëôùëéùë¢ùëëùëí ùëÄùëúùëõùëíùë° https://t.co/WdavWJcSyw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071141175606829056</th>\n",
       "      <td>1</td>\n",
       "      <td>Animal</td>\n",
       "      <td>Nature is Amazing ‚òòÔ∏è</td>\n",
       "      <td>Baby Alpacas are so under appreciated. https://t.co/SDXjKaVscv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153952965650079744</th>\n",
       "      <td>1</td>\n",
       "      <td>Flowers</td>\n",
       "      <td>BGCI</td>\n",
       "      <td>Apply for a grant to implement plant conservation at your botanic garden today! https://t.co/gj2eDzIWeB https://t.co/z1iJjZPOFn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154059414174703617</th>\n",
       "      <td>2</td>\n",
       "      <td>Business</td>\n",
       "      <td>FOOD INSIDER</td>\n",
       "      <td>Are you team Shake Shack or team In-N-Out? https://t.co/3bDmzocr6P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154061474383441920</th>\n",
       "      <td>1</td>\n",
       "      <td>Art</td>\n",
       "      <td>Phaidon</td>\n",
       "      <td>How @OlafurEliasson's 'hedonistic' dad helped his art https://t.co/x9tFi65TjW @BBCHARDtalk @TheZeinabBadawi https://t.co/Ocuv6jrVbH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154130836217683968</th>\n",
       "      <td>1</td>\n",
       "      <td>Art</td>\n",
       "      <td>Alice Waters</td>\n",
       "      <td>I am delighted that @IfOnly and @Sothebys are offering a special auction lot to cook at my home with @CiaoSamin! Bidding ends Friday and proceeds support the @edibleschoolyrd! \\n\\nhttps://t.co/jmHg5unL2w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154108888116940800</th>\n",
       "      <td>1</td>\n",
       "      <td>Cryptocurrency</td>\n",
       "      <td>üçÑüå≤BenjaminBluntsüå≤üçÑ</td>\n",
       "      <td>btc dominance is now in a downtrend and alts are a poppin.\\n\\ncongratz fam we made it https://t.co/MsPcAPdpAm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>322318 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     edInput       topicName                 usName  \\\n",
       "tweetID                                                               \n",
       "1070970722598707200        1         Fashion      Gentleman‚Äôs style   \n",
       "1070981773616648193        1     Interesting       Satisfying Slime   \n",
       "916500037818916866         2     Interesting  Tips & Tricks Ideas ‚úå   \n",
       "1071135340696625152        1             Art                   ùê¥ùëüùë°.   \n",
       "1071141175606829056        1          Animal   Nature is Amazing ‚òòÔ∏è   \n",
       "...                      ...             ...                    ...   \n",
       "1153952965650079744        1         Flowers                   BGCI   \n",
       "1154059414174703617        2        Business           FOOD INSIDER   \n",
       "1154061474383441920        1             Art                Phaidon   \n",
       "1154130836217683968        1             Art           Alice Waters   \n",
       "1154108888116940800        1  Cryptocurrency     üçÑüå≤BenjaminBluntsüå≤üçÑ   \n",
       "\n",
       "                                                                                                                                                                                                                            text  \n",
       "tweetID                                                                                                                                                                                                                           \n",
       "1070970722598707200                                                                                                                                                        Which one would you choose? üëÄ https://t.co/U0s3alfBNp  \n",
       "1070981773616648193                                                                                                                                                                     How it‚Äôs made. üòä https://t.co/3XjOw4gIkg  \n",
       "916500037818916866                                                                             Smile, because it confuses people. Smile, because it‚Äôs easier than explaining what is killing you inside. https://t.co/FGlnnRfP5w  \n",
       "1071135340696625152                                                                                                                                                                         ùê∂ùëôùëéùë¢ùëëùëí ùëÄùëúùëõùëíùë° https://t.co/WdavWJcSyw  \n",
       "1071141175606829056                                                                                                                                               Baby Alpacas are so under appreciated. https://t.co/SDXjKaVscv  \n",
       "...                                                                                                                                                                                                                          ...  \n",
       "1153952965650079744                                                                              Apply for a grant to implement plant conservation at your botanic garden today! https://t.co/gj2eDzIWeB https://t.co/z1iJjZPOFn  \n",
       "1154059414174703617                                                                                                                                           Are you team Shake Shack or team In-N-Out? https://t.co/3bDmzocr6P  \n",
       "1154061474383441920                                                                          How @OlafurEliasson's 'hedonistic' dad helped his art https://t.co/x9tFi65TjW @BBCHARDtalk @TheZeinabBadawi https://t.co/Ocuv6jrVbH  \n",
       "1154130836217683968  I am delighted that @IfOnly and @Sothebys are offering a special auction lot to cook at my home with @CiaoSamin! Bidding ends Friday and proceeds support the @edibleschoolyrd! \\n\\nhttps://t.co/jmHg5unL2w  \n",
       "1154108888116940800                                                                                                btc dominance is now in a downtrend and alts are a poppin.\\n\\ncongratz fam we made it https://t.co/MsPcAPdpAm  \n",
       "\n",
       "[322318 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['edInput', 'topicName', 'usName','text' ]]\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Since we will be clasifying only Business or no business tweets, we need to create a new column which will be :\n",
    "1. 1 if the 'topicName' == Business and 'edInput' == 1 \n",
    "2. We drop other topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30024, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.copy(deep=True)\n",
    "df = df[df['topicName']=='Business']\n",
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Removing topicName and edInput columns as we don't need them anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IsBusiness</th>\n",
       "      <th>usName</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweetID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1072758722315862021</th>\n",
       "      <td>0</td>\n",
       "      <td>BBC Breaking News</td>\n",
       "      <td>UK Prime Minister Theresa May will face a vote of no confidence in her leadership later on Wednesday https://t.co/wzta1v9ScU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072959907958276096</th>\n",
       "      <td>0</td>\n",
       "      <td>BBC Breaking News</td>\n",
       "      <td>UK PM Theresa May wins confidence vote with 200 out of 317 Tory MPs supporting her to stay on as leader\\n\\nhttps://t.co/9Vw2gOQoDc https://t.co/bafuUsZoKa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     IsBusiness             usName  \\\n",
       "tweetID                                              \n",
       "1072758722315862021           0  BBC Breaking News   \n",
       "1072959907958276096           0  BBC Breaking News   \n",
       "\n",
       "                                                                                                                                                                           text  \n",
       "tweetID                                                                                                                                                                          \n",
       "1072758722315862021                                UK Prime Minister Theresa May will face a vote of no confidence in her leadership later on Wednesday https://t.co/wzta1v9ScU  \n",
       "1072959907958276096  UK PM Theresa May wins confidence vote with 200 out of 317 Tory MPs supporting her to stay on as leader\\n\\nhttps://t.co/9Vw2gOQoDc https://t.co/bafuUsZoKa  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:,'IsBusiness'] = np.where(df['edInput']==1, 1, 0)\n",
    "df = df[['IsBusiness', 'usName', 'text']]\n",
    "df.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cheching how balanced our data is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    17836\n",
      "0    12188\n",
      "Name: IsBusiness, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['IsBusiness'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(3,3))\n",
    "plt.pie(df['IsBusiness'].value_counts(), labels=['Not Business', 'Business'], autopct='%1.1f%%', startangle=90, colors=['#ED9B9D','#B5E8C0'])\n",
    "plt.title('Business Tweets')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can clearly see, that the data is not balanced. We will need to balance the data before training the model.\n",
    "Few possible ways to approach:\n",
    "1. __Using the correct metrics for imbalanced data.__ I will not use Accuracy as it will not give us a good results as we can classify all samples as \"Not Business\" and get an accuracy of 94.5%, yet totally failing to catch \"Business\" samples. I'll use F1 score. F1 is a harmonic mean of precision and recall. It is a good metric to use when we have imbalanced data.\n",
    "2. __Oversampling__ - Randomly increasing of the minority class using the same data points. This technic can be pron to overfitting, especially if we oversample too much.  \n",
    "3. __Synthetic Minority Oversampling Technique - SMOTE__ - This technic will create new samples based on the existing ones. It will not overfit as much as the oversampling, but it can be pron to overfitting as well. This generaes \"Similar\" samples, but not the same.\n",
    "3. __Undersampling__ - This will help us to balance the data, but we will lose some of the data randomly truncated. Using this we can lose some crutial information. \n",
    "5. __Using Bagging__ - BalancedBaggingClassifier - sklearn classifier but with additional balancing.\n",
    "6. __Treshhold moving + Grid Search__ - We can try to move the treshhold for the classification and see if we can get better results. For imbalanced data sets default 0.5 treshhold doesn't work well. We can also use Grid Search to find the best treshhold."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Before dealing with the imbalanced data:\n",
    "1. Let's clean obvious noise: \n",
    "    1. Scikit-learn has basic buit-in text cleanng regex. \n",
    "    2. And we need to deal with URLs inside all docs.\n",
    "    3. As well as with emojis.\n",
    "    4. And Stopwords.\n",
    "2. Train the model with the default parameters and see what we get to estimate the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Vasyl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression # Our Baseline Model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# import precision_recall_fscore_support as score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import re\n",
    "import demoji\n",
    "from unidecode import unidecode\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenizer(doc):   \n",
    "    # define stopwords \n",
    "    stops = (stopwords.words('english'))\n",
    "    stops.extend([])    \n",
    "\n",
    "    doc = demoji.replace_with_desc(doc, sep=' ') # replace emojis with text\n",
    "    doc = unidecode(doc) # remove accents\n",
    "    doc = re.sub(r'http\\S+', '', doc) # remove urls\n",
    "    doc = re.sub(r'\\b\\d+\\b','', doc) # remove numbers\n",
    "    doc = doc.lower() # decapitalization\n",
    "    doc = re.findall(r'(?u)\\b\\w\\w+\\b', doc) # standard scikit-learn pattern\n",
    "\n",
    "    tokens = [word for word in doc if word not in stops] # remove stopwords\n",
    "\n",
    "    return tokens\n",
    "\n",
    "# ---------------- For testing ----------------\n",
    "# print(df['text'].iloc[0])\n",
    "# doc = df['text'].iloc[0] + ' 544' + ' Them' + ' Abig' + ' Êù±Êó•Êú¨Â§ßÈúáÁÅΩ„Åã„Çâ8Âπ¥'\n",
    "# custom_tokenizer(doc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Splitting the data into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24019,) (24019,)\n",
      "(6005,) (6005,)\n"
     ]
    }
   ],
   "source": [
    "y = df['IsBusiness']\n",
    "X = df['text']\n",
    "\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=777, stratify=y)\n",
    "print (X_train_text.shape, y_train.shape)\n",
    "print (X_test_text.shape, y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Checking split results to see if we have the same distribution of classes in both sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6832994603686313\n",
      "0.6834875245304177\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts().iloc[1]/y_train.value_counts().iloc[0])\n",
    "print(y_test.value_counts().iloc[1]/y_test.value_counts().iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing more pythonic way to save and load objects\n",
    "def save_load_obj(obj, path, mode='save'):\n",
    "    if mode == 'save':\n",
    "        with open(path, 'wb') as file:\n",
    "            pickle.dump(obj, file)\n",
    "    else:\n",
    "        with open(path, 'rb') as file:\n",
    "            return pickle.load(file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here data prep ends and we start looking for better relampling and model tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Stop Execution",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Raising error to be able to jump to different cells after data prep.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mStop Execution\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mException\u001b[0m: Stop Execution"
     ]
    }
   ],
   "source": [
    "# Raising error to be able to jump to different cells after data prep.\n",
    "raise Exception('Stop Execution')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(tokenizer=custom_tokenizer, min_df=5, max_df=0.2, ngram_range=(1,2))\n",
    "# Tokenization and building vocabulary with Fit\n",
    "vect_fitted = vect.fit(X_train_text)\n",
    "\n",
    "save_load_obj(vect_fitted, r'1st run\\TfidfVect-X_train-fit-mindf-5-maxdf-02-ngram-2.pkl', mode='save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_fitted = save_load_obj('', r'1st run\\TfidfVect-X_train-fit-mindf-5-maxdf-02-ngram-2.pkl', mode='load')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 10130\n",
      "\n",
      "Every 10000th word: \n",
      " ['10th', 'costs', 'help employees', 'next iphone', 'sharp', 'worrying']\n",
      "\n",
      "Fisrt 25 words: \n",
      " ['10th' '11th' '17th' '18th' '1960s' '1970s' '1980s' '1mdb' '1mdb scandal'\n",
      " '1st' '21st' '21st century' '2nd' '30s' '35s' '3d' '3rd' '40s' '4th'\n",
      " '50s' '50th' '50th anniversary' '5g' '5g mobile' '5g network']\n",
      "\n",
      "Last 25 words: \n",
      " ['york times' 'yorkers' 'young' 'young people' 'younger' 'youngest'\n",
      " 'youth' 'youtube' 'youtube star' 'youtuber' 'yuan' 'zealand'\n",
      " 'zealand mosque' 'zealand prime' 'zero' 'zhong' 'zimbabwe' 'zimmern'\n",
      " 'zion' 'zion williamson' 'zip' 'zone' 'zones' 'zuckerberg'\n",
      " 'zuckerberg says']\n"
     ]
    }
   ],
   "source": [
    "feature_names = vect_fitted.get_feature_names_out()\n",
    "\n",
    "print(f'Vocabulary size: {len(vect_fitted.vocabulary_)}')\n",
    "\n",
    "c = 0\n",
    "to_print = []\n",
    "for i, value in enumerate(feature_names):\n",
    "    # print every 2000th key\n",
    "    if c % 2000 == 0:\n",
    "        to_print.append(value)\n",
    "    c += 1\n",
    "print(f'\\nEvery 10000th word: \\n {to_print}')\n",
    "print(f'\\nFisrt 25 words: \\n {feature_names[:25]}')\n",
    "print(f'\\nLast 25 words: \\n {feature_names[-25:]}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Features seems to be ok to start working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the training data into a document-term sparce matrix\n",
    "X_train = vect_fitted.transform(X_train_text)\n",
    "save_load_obj(X_train, r'1st run\\X_train-transformed.pkl', mode='save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: <24019x10130 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 242922 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "X_train = save_load_obj('', r'1st run\\X_train-transformed.pkl', mode='load')\n",
    "print(f'X_train: {repr(X_train)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now Let's try evaluating LogReg with cross validation and see what we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation F1 Scores: [0.85454545 0.84555855 0.85142469 0.84575097 0.85488747 0.847981\n",
      " 0.85123687 0.85182049 0.85027726 0.84810765 0.85074878 0.85128031\n",
      " 0.85079151 0.85169563 0.8499242  0.85435587 0.84457974 0.85254692\n",
      " 0.85361731 0.84517981]\n"
     ]
    }
   ],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=4, random_state=777) # Creating a cross-validation object to account for class imbalance.\n",
    "lg = LogisticRegression(max_iter=500, n_jobs=-1)\n",
    "scores = cross_val_score(lg, X_train, y_train, cv=cv, scoring='f1') # Picking F1 score as it is not balanced dataset.\n",
    "print(f'Cross-Validation F1 Scores: {scores}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 0.8503155247158449\n",
      "Best parameters: {'C': 1}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [0.01, 0.1, 1, 10, 100, 1000]}\n",
    "grid = GridSearchCV(lg, param_grid, cv=cv, scoring='f1')\n",
    "grid.fit(X_train, y_train)\n",
    "print(f'Best cross-validation score: {grid.best_score_}')\n",
    "print(f'Best parameters: {grid.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base LogReg Prediction score: 0.8462162162162162\n"
     ]
    }
   ],
   "source": [
    "X_test = vect_fitted.transform(X_test_text)\n",
    "print(f'Base LogReg Prediction score: {grid.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving time by saving the model\n",
    "save_load_obj(grid, r'1st run\\LogReg-C-1-max_iter-500.pkl', mode='save')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Initial results are not exactly the best ones, but we can do better. Let's try to:\n",
    "1. Balance the data and see if we can get better results.( Oversampling - SMOTE/ADASYN, Undersampling, BaggingClassifier)\n",
    "2. Modify TF-IDF parameters and see if we can get better results.\n",
    "3. Try different models and see if we can get better results."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Balancing Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd Run\n",
    "* Oversampling - SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: <24019x10130 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 242922 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "# Loading X_train from the previous run\n",
    "X_train = save_load_obj('', r'1st run\\X_train-transformed.pkl', mode='load')\n",
    "print(f'X_train: {repr(X_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling the minority class.\n",
    "sm = SMOTE(random_state=777)\n",
    "# Fit the model to generate the data.\n",
    "oversampled_X_train, oversampled_y_train = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oversampled_X shape: (28538, 10130)\n",
      "oversampled_y shape: (28538,)\n",
      "oversampler_y value counts:\n",
      " 1    14269\n",
      "0    14269\n",
      "Name: IsBusiness, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f'oversampled_X shape: {oversampled_X_train.shape}')\n",
    "print(f'oversampled_y shape: {oversampled_y_train.shape}')\n",
    "print(f'oversampler_y value counts:\\n',oversampled_y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 0.8346745308992229\n",
      "Best parameters: {'C': 1}\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV\n",
    "param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "grid = GridSearchCV(lg, param_grid, cv=5, scoring='f1') # Maybe change to accuracy as it is balanced now ?\n",
    "grid.fit(oversampled_X_train, oversampled_y_train)\n",
    "print(f'Best cross-validation score: {grid.best_score_}')\n",
    "print(f'Best parameters: {grid.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base LogReg Prediction score: 83\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------\n",
    "# Predicting on the test set\n",
    "X_test = vect_fitted.transform(X_test_text)\n",
    "score = int(round(grid.score(X_test, y_test), 2)*100)\n",
    "print(f'Base LogReg Prediction score: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_load_obj(grid, rf'2nd run - SMOTE\\LogReg-C-1-max_iter-500-F1-{score}%.pkl', mode='save')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3rd Run\n",
    "* Oversampling ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: <24019x10130 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 242922 stored elements in Compressed Sparse Row format>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Study 2018 and later\\Mignimind Bootcamp\\Code\\P4-NLP-Tweet-Classification\\.venv\\lib\\site-packages\\imblearn\\over_sampling\\_adasyn.py:156: FutureWarning: The parameter `n_jobs` has been deprecated in 0.10 and will be removed in 0.12. You can pass an nearest neighbors estimator where `n_jobs` is already set instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oversampled_X shape: (30486, 10130)\n",
      "oversampled_y shape: (30486,)\n",
      "oversampler_y value counts:\n",
      " 0    16217\n",
      "1    14269\n",
      "Name: IsBusiness, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Loading X_train from the previous run\n",
    "X_train = save_load_obj('', r'1st run\\X_train-transformed.pkl', mode='load')\n",
    "print(f'X_train: {repr(X_train)}')\n",
    "\n",
    "# Resampling the minority class.\n",
    "ada = ADASYN(random_state=77)\n",
    "# Fit the model to generate the data.\n",
    "oversampled_X_train, oversampled_y_train = ada.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f'oversampled_X shape: {oversampled_X_train.shape}')\n",
    "print(f'oversampled_y shape: {oversampled_y_train.shape}')\n",
    "print(f'oversampler_y value counts:\\n',oversampled_y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAc0AAAEjCAYAAABQC1rvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAm/UlEQVR4nO3df3RNd77/8dcRzQnGSRD5dZtG0PpRIaS3EepXaULTVnq1Uz/aMILRFZ1W/EzrEjX36jCqTIulP0TXcKt6y1IsJPEjo1IkxM8yRVJMnbgtySElIvb3j1nZ356JHzsk0vB8rLXXsj+f9977vbN6+lr77LPPsRmGYQgAANxSnZpuAACA2oLQBADAIkITAACLCE0AACwiNAEAsIjQBADAIkITAACLCE0AACwiNAEAsIjQBFCtUlNTZbPZlJ+fX9OtAHeM0ATuwPHjx/X73/9ezZs3l5eXlxwOh7p27ap58+bp0qVLNd2eJGnBggVKTU2t6TZuy+HDh5WSkkLg4lfDxnfPArdn3bp1evHFF2W32xUfH6927drpypUr2r59u/73f/9Xw4YN0+LFi2u6TbVr106+vr7aunVrjRy/rKxMpaWlstvtstlsldr2iy++0IsvvqgtW7aoZ8+e1dMgUAl1a7oBoDbKy8vTwIEDFRISos2bNyswMNCcS0xM1LFjx7Ru3boa7PDXw8PDQx4eHjXdBlAleHsWuA2zZs3SxYsX9fHHH7sFZrmWLVvq9ddfN9evXr2qGTNmqEWLFrLb7WrWrJnefPNNlZSUuG1ns9mUkpJSYX/NmjXTsGHDzPXy+4Rff/21kpKS1LRpUzVo0EDPP/+8/u///s9tu0OHDmnbtm2y2Wyy2Ww3vWLLz8+XzWbTn//8Z82dO1chISGqV6+eevTooYMHD1ao37x5s7p166YGDRrIx8dH/fv317fffutWc717ms2aNdMzzzyj7du36/HHH5eXl5eaN2+uTz/91G27F198UZLUq1cvs//yK+bs7GzFxMTI19dX9erVU2hoqIYPH37DcwOqAleawG346quv1Lx5c3Xp0sVS/YgRI7R06VK98MILGjdunHbu3KmZM2fq22+/1apVq267j9dee02NGjXStGnTlJ+fr/fee09jxozRihUrJEnvvfeeXnvtNf3mN7/RW2+9JUny9/e/5X4//fRTXbhwQYmJibp8+bLmzZunJ598UgcOHDC3T09PV79+/dS8eXOlpKTo0qVL+stf/qKuXbtqz549atas2U2PcezYMb3wwgtKSEjQ0KFD9cknn2jYsGGKiIjQo48+qu7du+sPf/iD5s+frzfffFNt2rSRJLVp00Znz55VdHS0mjZtqsmTJ8vHx0f5+fn68ssvb/tvCVhiAKiUoqIiQ5LRv39/S/W5ubmGJGPEiBFu4+PHjzckGZs3bzbHJBnTpk2rsI+QkBBj6NCh5vqSJUsMSUafPn2Ma9eumeNjx441PDw8jMLCQnPs0UcfNXr06GGp17y8PEOSUa9ePeP06dPm+M6dOw1JxtixY82x8PBww8/Pz/jpp5/MsX379hl16tQx4uPjK/Sal5fndj6SjMzMTHPs7Nmzht1uN8aNG2eOrVy50pBkbNmyxa3PVatWGZKM3bt3WzovoKrw9ixQSS6XS5LUsGFDS/Xr16+XJCUlJbmNjxs3TpLu6N7nqFGj3D5c061bN5WVlen777+/7X1KUlxcnP7t3/7NXH/88ccVGRlpnsuZM2eUm5urYcOGqXHjxmZd+/bt9dRTT5l1N9O2bVt169bNXG/atKlatWqlEydO3HJbHx8fSdLatWtVWlpq9bSAO0ZoApXkcDgkSRcuXLBU//3336tOnTpq2bKl23hAQIB8fHzuKOAeeught/VGjRpJks6fP3/b+5Skhx9+uMLYI488Yt6XLO+5VatWFeratGmjH3/8UcXFxTc9xr/2Lv2zfyu99+jRQwMGDND06dPl6+ur/v37a8mSJRXuEQNVjdAEKsnhcCgoKOi6H4y5mco+bvFLZWVl1x2/0adSjVrwJNmd9G6z2fTFF18oKytLY8aM0T/+8Q8NHz5cERERunjxYlW3CpgITeA2PPPMMzp+/LiysrJuWRsSEqJr167pu+++cxsvKChQYWGhQkJCzLFGjRqpsLDQre7KlSs6c+bMbfd6O2H9r71K0t///nfzwz3lPR89erRC3ZEjR+Tr66sGDRpU+rj/6la9d+7cWf/1X/+l7OxsLVu2TIcOHdJnn312x8cFboTQBG7DxIkT1aBBA40YMUIFBQUV5o8fP6558+ZJkp5++mlJ//wk6y+9++67kqTY2FhzrEWLFsrMzHSrW7x48Q2vNK1o0KBBhSC+ldWrV+sf//iHub5r1y7t3LlT/fr1kyQFBgYqPDxcS5cuddv3wYMHtWnTJvOc71R58P5r/+fPn69wRRoeHi5JvEWLasUjJ8BtaNGihZYvX66XXnpJbdq0cftGoB07dmjlypXmc5UdOnTQ0KFDtXjxYhUWFqpHjx7atWuXli5dqri4OPXq1cvc74gRIzR69GgNGDBATz31lPbt26eNGzfK19f3tnuNiIjQwoUL9cc//lEtW7aUn5+fnnzyyZtu07JlSz3xxBN69dVXVVJSovfee09NmjTRxIkTzZrZs2erX79+ioqKUkJCgvnIibe393WfNb0d4eHh8vDw0J/+9CcVFRXJbrfrySef1PLly7VgwQI9//zzatGihS5cuKAPP/xQDoejygIbuK4a/vQuUKv9/e9/N0aOHGk0a9bM8PT0NBo2bGh07drV+Mtf/mJcvnzZrCstLTWmT59uhIaGGg888IARHBxsJCcnu9UYhmGUlZUZkyZNMnx9fY369esbMTExxrFjx274yMm/PnKxZcuWCo9oOJ1OIzY21mjYsKEh6aaPn5Q/cjJ79mxjzpw5RnBwsGG3241u3boZ+/btq1Cfnp5udO3a1ahXr57hcDiMZ5991jh8+LBbzY0eOYmNja2wvx49elTo78MPPzSaN29ueHh4mOe2Z88eY9CgQcZDDz1k2O12w8/Pz3jmmWeM7OzsG54bUBX47lkApvz8fIWGhmr27NkaP358TbcD/OpwTxMAAIsITQAALCI0AQCwiHuaAABYxJUmAAAW3dfPaV67dk0//PCDGjZseEdfcQYAqL0Mw9CFCxcUFBSkOnVufi15X4fmDz/8oODg4JpuAwDwK3Dq1Ck9+OCDN625r0Oz/KedTp06Zf5yBQDg/uJyuRQcHGzp5/7u69Asf0vW4XAQmgBwn7Nym44PAgEAYBGhCQCARYQmAAAWEZoAAFhEaAIAYBGhCQCARYQmAAAWEZoAAFh0X3+5wb2g2eR1Nd3CfS//ndiabgHAXcKVJgAAFhGaAABYRGgCAGARoQkAgEWEJgAAFhGaAABYRGgCAGARoQkAgEWEJgAAFhGaAABYRGgCAGARoQkAgEWVDs3MzEw9++yzCgoKks1m0+rVq93mhw0bJpvN5rb07dvXrebcuXMaMmSIHA6HfHx8lJCQoIsXL7rV7N+/X926dZOXl5eCg4M1a9asCr2sXLlSrVu3lpeXl8LCwrR+/frKng4AAJZVOjSLi4vVoUMHffDBBzes6du3r86cOWMu//M//+M2P2TIEB06dEhpaWlau3atMjMzNWrUKHPe5XIpOjpaISEhysnJ0ezZs5WSkqLFixebNTt27NCgQYOUkJCgvXv3Ki4uTnFxcTp48GBlTwkAAEtshmEYt72xzaZVq1YpLi7OHBs2bJgKCwsrXIGW+/bbb9W2bVvt3r1bjz32mCRpw4YNevrpp3X69GkFBQVp4cKFeuutt+R0OuXp6SlJmjx5slavXq0jR45Ikl566SUVFxdr7dq15r47d+6s8PBwLVq0yFL/LpdL3t7eKioqksPhuI2/QM3jp8FqHj8NBtRulcmCarmnuXXrVvn5+alVq1Z69dVX9dNPP5lzWVlZ8vHxMQNTkvr06aM6depo586dZk337t3NwJSkmJgYHT16VOfPnzdr+vTp43bcmJgYZWVl3bCvkpISuVwutwUAAKuqPDT79u2rTz/9VBkZGfrTn/6kbdu2qV+/fiorK5MkOZ1O+fn5uW1Tt25dNW7cWE6n06zx9/d3qylfv1VN+fz1zJw5U97e3uYSHBx8ZycLALiv1K3qHQ4cOND8d1hYmNq3b68WLVpo69at6t27d1UfrlKSk5OVlJRkrrtcLoITAGBZtT9y0rx5c/n6+urYsWOSpICAAJ09e9at5urVqzp37pwCAgLMmoKCArea8vVb1ZTPX4/dbpfD4XBbAACwqtpD8/Tp0/rpp58UGBgoSYqKilJhYaFycnLMms2bN+vatWuKjIw0azIzM1VaWmrWpKWlqVWrVmrUqJFZk5GR4XastLQ0RUVFVfcpAQDuU5UOzYsXLyo3N1e5ubmSpLy8POXm5urkyZO6ePGiJkyYoG+++Ub5+fnKyMhQ//791bJlS8XExEiS2rRpo759+2rkyJHatWuXvv76a40ZM0YDBw5UUFCQJGnw4MHy9PRUQkKCDh06pBUrVmjevHlub62+/vrr2rBhg+bMmaMjR44oJSVF2dnZGjNmTBX8WQAAqKjSoZmdna2OHTuqY8eOkqSkpCR17NhRU6dOlYeHh/bv36/nnntOjzzyiBISEhQREaG//e1vstvt5j6WLVum1q1bq3fv3nr66af1xBNPuD2D6e3trU2bNikvL08REREaN26cpk6d6vYsZ5cuXbR8+XItXrxYHTp00BdffKHVq1erXbt2d/L3AADghu7oOc3ajuc0URV4ThOo3Wr8OU0AAO5FhCYAABYRmgAAWFTlX24AAHcb9/Zr3v1yb58rTQAALCI0AQCwiNAEAMAiQhMAAIsITQAALCI0AQCwiNAEAMAiQhMAAIsITQAALCI0AQCwiNAEAMAiQhMAAIsITQAALCI0AQCwiNAEAMAiQhMAAIsITQAALCI0AQCwiNAEAMCiSodmZmamnn32WQUFBclms2n16tXmXGlpqSZNmqSwsDA1aNBAQUFBio+P1w8//OC2j2bNmslms7kt77zzjlvN/v371a1bN3l5eSk4OFizZs2q0MvKlSvVunVreXl5KSwsTOvXr6/s6QAAYFmlQ7O4uFgdOnTQBx98UGHu559/1p49e/Sf//mf2rNnj7788ksdPXpUzz33XIXat99+W2fOnDGX1157zZxzuVyKjo5WSEiIcnJyNHv2bKWkpGjx4sVmzY4dOzRo0CAlJCRo7969iouLU1xcnA4ePFjZUwIAwJK6ld2gX79+6tev33XnvL29lZaW5jb2/vvv6/HHH9fJkyf10EMPmeMNGzZUQEDAdfezbNkyXblyRZ988ok8PT316KOPKjc3V++++65GjRolSZo3b5769u2rCRMmSJJmzJihtLQ0vf/++1q0aFFlTwsAgFuq9nuaRUVFstls8vHxcRt/55131KRJE3Xs2FGzZ8/W1atXzbmsrCx1795dnp6e5lhMTIyOHj2q8+fPmzV9+vRx22dMTIyysrJu2EtJSYlcLpfbAgCAVZW+0qyMy5cva9KkSRo0aJAcDoc5/oc//EGdOnVS48aNtWPHDiUnJ+vMmTN69913JUlOp1OhoaFu+/L39zfnGjVqJKfTaY79ssbpdN6wn5kzZ2r69OlVdXoAgPtMtYVmaWmpfvvb38owDC1cuNBtLikpyfx3+/bt5enpqd///veaOXOm7HZ7dbWk5ORkt2O7XC4FBwdX2/EAAPeWagnN8sD8/vvvtXnzZrerzOuJjIzU1atXlZ+fr1atWikgIEAFBQVuNeXr5fdBb1Rzo/ukkmS326s1lAEA97Yqv6dZHpjfffed0tPT1aRJk1tuk5ubqzp16sjPz0+SFBUVpczMTJWWlpo1aWlpatWqlRo1amTWZGRkuO0nLS1NUVFRVXg2AAD8f5W+0rx48aKOHTtmrufl5Sk3N1eNGzdWYGCgXnjhBe3Zs0dr165VWVmZeY+xcePG8vT0VFZWlnbu3KlevXqpYcOGysrK0tixY/Xyyy+bgTh48GBNnz5dCQkJmjRpkg4ePKh58+Zp7ty55nFff/119ejRQ3PmzFFsbKw+++wzZWdnuz2WAgBAVap0aGZnZ6tXr17mevk9wqFDhyolJUVr1qyRJIWHh7ttt2XLFvXs2VN2u12fffaZUlJSVFJSotDQUI0dO9btXqO3t7c2bdqkxMRERUREyNfXV1OnTjUfN5GkLl26aPny5ZoyZYrefPNNPfzww1q9erXatWtX2VMCAMASm2EYRk03UVNcLpe8vb1VVFR0y/uuv1bNJq+r6Rbue/nvxNZ0C/c9Xgc1rza/DiqTBXz3LAAAFhGaAABYRGgCAGARoQkAgEWEJgAAFhGaAABYRGgCAGARoQkAgEWEJgAAFhGaAABYRGgCAGARoQkAgEWEJgAAFhGaAABYRGgCAGARoQkAgEWEJgAAFhGaAABYRGgCAGARoQkAgEWEJgAAFhGaAABYRGgCAGBRpUMzMzNTzz77rIKCgmSz2bR69Wq3ecMwNHXqVAUGBqpevXrq06ePvvvuO7eac+fOaciQIXI4HPLx8VFCQoIuXrzoVrN//35169ZNXl5eCg4O1qxZsyr0snLlSrVu3VpeXl4KCwvT+vXrK3s6AABYVunQLC4uVocOHfTBBx9cd37WrFmaP3++Fi1apJ07d6pBgwaKiYnR5cuXzZohQ4bo0KFDSktL09q1a5WZmalRo0aZ8y6XS9HR0QoJCVFOTo5mz56tlJQULV682KzZsWOHBg0apISEBO3du1dxcXGKi4vTwYMHK3tKAABYYjMMw7jtjW02rVq1SnFxcZL+eZUZFBSkcePGafz48ZKkoqIi+fv7KzU1VQMHDtS3336rtm3bavfu3XrsscckSRs2bNDTTz+t06dPKygoSAsXLtRbb70lp9MpT09PSdLkyZO1evVqHTlyRJL00ksvqbi4WGvXrjX76dy5s8LDw7Vo0SJL/btcLnl7e6uoqEgOh+N2/ww1qtnkdTXdwn0v/53Ymm7hvsfroObV5tdBZbKgSu9p5uXlyel0qk+fPuaYt7e3IiMjlZWVJUnKysqSj4+PGZiS1KdPH9WpU0c7d+40a7p3724GpiTFxMTo6NGjOn/+vFnzy+OU15Qf53pKSkrkcrncFgAArKrS0HQ6nZIkf39/t3F/f39zzul0ys/Pz22+bt26aty4sVvN9fbxy2PcqKZ8/npmzpwpb29vcwkODq7sKQIA7mP31adnk5OTVVRUZC6nTp2q6ZYAALVIlYZmQECAJKmgoMBtvKCgwJwLCAjQ2bNn3eavXr2qc+fOudVcbx+/PMaNasrnr8dut8vhcLgtAABYVaWhGRoaqoCAAGVkZJhjLpdLO3fuVFRUlCQpKipKhYWFysnJMWs2b96sa9euKTIy0qzJzMxUaWmpWZOWlqZWrVqpUaNGZs0vj1NeU34cAACqWqVD8+LFi8rNzVVubq6kf374Jzc3VydPnpTNZtMbb7yhP/7xj1qzZo0OHDig+Ph4BQUFmZ+wbdOmjfr27auRI0dq165d+vrrrzVmzBgNHDhQQUFBkqTBgwfL09NTCQkJOnTokFasWKF58+YpKSnJ7OP111/Xhg0bNGfOHB05ckQpKSnKzs7WmDFj7vyvAgDAddSt7AbZ2dnq1auXuV4eZEOHDlVqaqomTpyo4uJijRo1SoWFhXriiSe0YcMGeXl5mdssW7ZMY8aMUe/evVWnTh0NGDBA8+fPN+e9vb21adMmJSYmKiIiQr6+vpo6darbs5xdunTR8uXLNWXKFL355pt6+OGHtXr1arVr1+62/hAAANzKHT2nWdvxnCaqQm1+Pu1eweug5tXm10GNPacJAMC9jNAEAMAiQhMAAIsITQAALCI0AQCwiNAEAMAiQhMAAIsITQAALCI0AQCwiNAEAMAiQhMAAIsITQAALCI0AQCwiNAEAMAiQhMAAIsITQAALCI0AQCwiNAEAMAiQhMAAIsITQAALCI0AQCwiNAEAMAiQhMAAIuqPDSbNWsmm81WYUlMTJQk9ezZs8Lc6NGj3fZx8uRJxcbGqn79+vLz89OECRN09epVt5qtW7eqU6dOstvtatmypVJTU6v6VAAAcFO3qne4e/dulZWVmesHDx7UU089pRdffNEcGzlypN5++21zvX79+ua/y8rKFBsbq4CAAO3YsUNnzpxRfHy8HnjgAf33f/+3JCkvL0+xsbEaPXq0li1bpoyMDI0YMUKBgYGKiYmp6lMCAEBSNYRm06ZN3dbfeecdtWjRQj169DDH6tevr4CAgOtuv2nTJh0+fFjp6eny9/dXeHi4ZsyYoUmTJiklJUWenp5atGiRQkNDNWfOHElSmzZttH37ds2dO5fQBABUm2q9p3nlyhX99a9/1fDhw2Wz2czxZcuWydfXV+3atVNycrJ+/vlncy4rK0thYWHy9/c3x2JiYuRyuXTo0CGzpk+fPm7HiomJUVZW1k37KSkpkcvlclsAALCqyq80f2n16tUqLCzUsGHDzLHBgwcrJCREQUFB2r9/vyZNmqSjR4/qyy+/lCQ5nU63wJRkrjudzpvWuFwuXbp0SfXq1btuPzNnztT06dOr6vQAAPeZag3Njz/+WP369VNQUJA5NmrUKPPfYWFhCgwMVO/evXX8+HG1aNGiOttRcnKykpKSzHWXy6Xg4OBqPSYA4N5RbaH5/fffKz093byCvJHIyEhJ0rFjx9SiRQsFBARo165dbjUFBQWSZN4HDQgIMMd+WeNwOG54lSlJdrtddru90ucCAIBUjfc0lyxZIj8/P8XGxt60Ljc3V5IUGBgoSYqKitKBAwd09uxZsyYtLU0Oh0Nt27Y1azIyMtz2k5aWpqioqCo8AwAA3FVLaF67dk1LlizR0KFDVbfu/7+YPX78uGbMmKGcnBzl5+drzZo1io+PV/fu3dW+fXtJUnR0tNq2batXXnlF+/bt08aNGzVlyhQlJiaaV4mjR4/WiRMnNHHiRB05ckQLFizQ559/rrFjx1bH6QAAIKmaQjM9PV0nT57U8OHD3cY9PT2Vnp6u6OhotW7dWuPGjdOAAQP01VdfmTUeHh5au3atPDw8FBUVpZdfflnx8fFuz3WGhoZq3bp1SktLU4cOHTRnzhx99NFHPG4CAKhW1XJPMzo6WoZhVBgPDg7Wtm3bbrl9SEiI1q9ff9Oanj17au/evbfdIwAAlcV3zwIAYBGhCQCARYQmAAAWEZoAAFhEaAIAYBGhCQCARYQmAAAWEZoAAFhEaAIAYBGhCQCARYQmAAAWEZoAAFhEaAIAYBGhCQCARYQmAAAWEZoAAFhEaAIAYBGhCQCARYQmAAAWEZoAAFhEaAIAYBGhCQCARYQmAAAWVXlopqSkyGazuS2tW7c25y9fvqzExEQ1adJEv/nNbzRgwAAVFBS47ePkyZOKjY1V/fr15efnpwkTJujq1atuNVu3blWnTp1kt9vVsmVLpaamVvWpAADgplquNB999FGdOXPGXLZv327OjR07Vl999ZVWrlypbdu26YcfftB//Md/mPNlZWWKjY3VlStXtGPHDi1dulSpqamaOnWqWZOXl6fY2Fj16tVLubm5euONNzRixAht3LixOk4HAABJUt1q2WndugoICKgwXlRUpI8//ljLly/Xk08+KUlasmSJ2rRpo2+++UadO3fWpk2bdPjwYaWnp8vf31/h4eGaMWOGJk2apJSUFHl6emrRokUKDQ3VnDlzJElt2rTR9u3bNXfuXMXExFTHKQEAUD1Xmt99952CgoLUvHlzDRkyRCdPnpQk5eTkqLS0VH369DFrW7durYceekhZWVmSpKysLIWFhcnf39+siYmJkcvl0qFDh8yaX+6jvKZ8HzdSUlIil8vltgAAYFWVh2ZkZKRSU1O1YcMGLVy4UHl5eerWrZsuXLggp9MpT09P+fj4uG3j7+8vp9MpSXI6nW6BWT5fPnezGpfLpUuXLt2wt5kzZ8rb29tcgoOD7/R0AQD3kSp/e7Zfv37mv9u3b6/IyEiFhITo888/V7169ar6cJWSnJyspKQkc93lchGcAADLqv2REx8fHz3yyCM6duyYAgICdOXKFRUWFrrVFBQUmPdAAwICKnyatnz9VjUOh+OmwWy32+VwONwWAACsqvbQvHjxoo4fP67AwEBFRETogQceUEZGhjl/9OhRnTx5UlFRUZKkqKgoHThwQGfPnjVr0tLS5HA41LZtW7Pml/sorynfBwAA1aHKQ3P8+PHatm2b8vPztWPHDj3//PPy8PDQoEGD5O3trYSEBCUlJWnLli3KycnR7373O0VFRalz586SpOjoaLVt21avvPKK9u3bp40bN2rKlClKTEyU3W6XJI0ePVonTpzQxIkTdeTIES1YsECff/65xo4dW9WnAwCAqcrvaZ4+fVqDBg3STz/9pKZNm+qJJ57QN998o6ZNm0qS5s6dqzp16mjAgAEqKSlRTEyMFixYYG7v4eGhtWvX6tVXX1VUVJQaNGigoUOH6u233zZrQkNDtW7dOo0dO1bz5s3Tgw8+qI8++ojHTQAA1cpmGIZR003UFJfLJW9vbxUVFdXa+5vNJq+r6Rbue/nvxNZ0C/c9Xgc1rza/DiqTBXz3LAAAFhGaAABYRGgCAGARoQkAgEWEJgAAFhGaAABYRGgCAGARoQkAgEWEJgAAFhGaAABYRGgCAGARoQkAgEWEJgAAFhGaAABYRGgCAGARoQkAgEWEJgAAFhGaAABYRGgCAGARoQkAgEWEJgAAFhGaAABYRGgCAGBRlYfmzJkz9e///u9q2LCh/Pz8FBcXp6NHj7rV9OzZUzabzW0ZPXq0W83JkycVGxur+vXry8/PTxMmTNDVq1fdarZu3apOnTrJbrerZcuWSk1NrerTAQDAVOWhuW3bNiUmJuqbb75RWlqaSktLFR0dreLiYre6kSNH6syZM+Yya9Ysc66srEyxsbG6cuWKduzYoaVLlyo1NVVTp041a/Ly8hQbG6tevXopNzdXb7zxhkaMGKGNGzdW9SkBACBJqlvVO9ywYYPbempqqvz8/JSTk6Pu3bub4/Xr11dAQMB197Fp0yYdPnxY6enp8vf3V3h4uGbMmKFJkyYpJSVFnp6eWrRokUJDQzVnzhxJUps2bbR9+3bNnTtXMTEx191vSUmJSkpKzHWXy3WnpwsAuI9U+z3NoqIiSVLjxo3dxpctWyZfX1+1a9dOycnJ+vnnn825rKwshYWFyd/f3xyLiYmRy+XSoUOHzJo+ffq47TMmJkZZWVk37GXmzJny9vY2l+Dg4Ds+PwDA/aPKrzR/6dq1a3rjjTfUtWtXtWvXzhwfPHiwQkJCFBQUpP3792vSpEk6evSovvzyS0mS0+l0C0xJ5rrT6bxpjcvl0qVLl1SvXr0K/SQnJyspKclcd7lcBCcAwLJqDc3ExEQdPHhQ27dvdxsfNWqU+e+wsDAFBgaqd+/eOn78uFq0aFFt/djtdtnt9mrbPwDg3lZtb8+OGTNGa9eu1ZYtW/Tggw/etDYyMlKSdOzYMUlSQECACgoK3GrK18vvg96oxuFwXPcqEwCAO1XloWkYhsaMGaNVq1Zp8+bNCg0NveU2ubm5kqTAwEBJUlRUlA4cOKCzZ8+aNWlpaXI4HGrbtq1Zk5GR4baftLQ0RUVFVdGZAADgrspDMzExUX/961+1fPlyNWzYUE6nU06nU5cuXZIkHT9+XDNmzFBOTo7y8/O1Zs0axcfHq3v37mrfvr0kKTo6Wm3bttUrr7yiffv2aePGjZoyZYoSExPNt1dHjx6tEydOaOLEiTpy5IgWLFigzz//XGPHjq3qUwIAQFI1hObChQtVVFSknj17KjAw0FxWrFghSfL09FR6erqio6PVunVrjRs3TgMGDNBXX31l7sPDw0Nr166Vh4eHoqKi9PLLLys+Pl5vv/22WRMaGqp169YpLS1NHTp00Jw5c/TRRx/d8HETAADuVJV/EMgwjJvOBwcHa9u2bbfcT0hIiNavX3/Tmp49e2rv3r2V6g8AgNvFd88CAGARoQkAgEWEJgAAFhGaAABYRGgCAGARoQkAgEWEJgAAFhGaAABYRGgCAGARoQkAgEWEJgAAFhGaAABYRGgCAGARoQkAgEWEJgAAFhGaAABYRGgCAGARoQkAgEWEJgAAFhGaAABYRGgCAGARoQkAgEWEJgAAFtX60Pzggw/UrFkzeXl5KTIyUrt27arplgAA96haHZorVqxQUlKSpk2bpj179qhDhw6KiYnR2bNna7o1AMA9qG5NN3An3n33XY0cOVK/+93vJEmLFi3SunXr9Mknn2jy5MkV6ktKSlRSUmKuFxUVSZJcLtfdabgaXCv5uaZbuO/V5v9+7hW8DmpebX4dlPduGMati41aqqSkxPDw8DBWrVrlNh4fH28899xz191m2rRphiQWFhYWFpYKy6lTp26ZPbX2SvPHH39UWVmZ/P393cb9/f115MiR626TnJyspKQkc/3atWs6d+6cmjRpIpvNVq39oiKXy6Xg4GCdOnVKDoejptsBagSvg5pnGIYuXLigoKCgW9bW2tC8HXa7XXa73W3Mx8enZpqByeFw8D8L3Pd4HdQsb29vS3W19oNAvr6+8vDwUEFBgdt4QUGBAgICaqgrAMC9rNaGpqenpyIiIpSRkWGOXbt2TRkZGYqKiqrBzgAA96pa/fZsUlKShg4dqscee0yPP/643nvvPRUXF5ufpsWvm91u17Rp0yq8ZQ7cT3gd1C42w7DyGdtfr/fff1+zZ8+W0+lUeHi45s+fr8jIyJpuCwBwD6r1oQkAwN1Sa+9pAgBwtxGaAABYRGgCAGARoQkAgEWEJgAAFtXq5zRRu/z444/65JNPlJWVJafTKUkKCAhQly5dNGzYMDVt2rSGOwSAm+NKE3fF7t279cgjj2j+/Pny9vZW9+7d1b17d3l7e2v+/Plq3bq1srOza7pNoMadOnVKw4cPr+k2cAM8p4m7onPnzurQoYMWLVpU4RdlDMPQ6NGjtX//fmVlZdVQh8Cvw759+9SpUyeVlZXVdCu4Dt6exV2xb98+paamXvcn2Gw2m8aOHauOHTvWQGfA3bVmzZqbzp84ceIudYLbQWjirggICNCuXbvUunXr687v2rWrwm+jAveiuLg42Ww23exNPn7f99eL0MRdMX78eI0aNUo5OTnq3bu3GZAFBQXKyMjQhx9+qD//+c813CVQ/QIDA7VgwQL179//uvO5ubmKiIi4y13BKkITd0ViYqJ8fX01d+5cLViwwLxf4+HhoYiICKWmpuq3v/1tDXcJVL+IiAjl5OTcMDRvdRWKmsUHgXDXlZaW6scff5T0zx8Tf+CBB2q4I+Du+dvf/qbi4mL17dv3uvPFxcXKzs5Wjx497nJnsILQBADAIp7TBADAIkITAACLCE0AACwiNAEAsIjQBADAIkITAACLCE0AACz6f5sw30w4vIKiAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "oversampled_y_train.value_counts().plot(kind='bar', title='Count points', figsize=(5, 2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 0.8326337342684461\n",
      "Best parameters: {'C': 10}\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV\n",
    "param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "grid = GridSearchCV(lg, param_grid, cv=5, scoring='f1') # Maybe change to accuracy as it is balanced now ?\n",
    "grid.fit(oversampled_X_train, oversampled_y_train)\n",
    "print(f'Best cross-validation score: {grid.best_score_}')\n",
    "print(f'Best parameters: {grid.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base LogReg Prediction score: 83%\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------\n",
    "# Predicting on the test set\n",
    "X_test = vect_fitted.transform(X_test_text)\n",
    "score = int(round(grid.score(X_test, y_test), 2)*100)\n",
    "print(f'Base LogReg Prediction score: {score}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_load_obj(grid, rf'3rd run - ADASYN\\LogReg-C-10-max_iter-500-F1-{score}%.pkl', mode='save')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4th Run\n",
    "* Undersampling - ClusterCentroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = LogisticRegression(max_iter=500, n_jobs=-1)\n",
    "vect_fitted = save_load_obj('', r'1st run\\TfidfVect-X_train-fit-mindf-5-maxdf-02-ngram-2.pkl', mode='load')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: <24019x10130 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 242922 stored elements in Compressed Sparse Row format>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Study 2018 and later\\Mignimind Bootcamp\\Code\\P4-NLP-Tweet-Classification\\.venv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oversampled_X shape: (19500, 10130)\n",
      "oversampled_y shape: (19500,)\n",
      "oversampler_y value counts:\n",
      " 0    9750\n",
      "1    9750\n",
      "Name: IsBusiness, dtype: int64\n",
      "[(0, 9750), (1, 9750)]\n"
     ]
    }
   ],
   "source": [
    "# Loading X_train from the previous run\n",
    "X_train = save_load_obj('', r'1st run\\X_train-transformed.pkl', mode='load')\n",
    "print(f'X_train: {repr(X_train)}')\n",
    "\n",
    "from collections import Counter \n",
    "cc = ClusterCentroids(random_state=77)\n",
    "undersam_X_train, undersam_y_train = cc.fit_resample(X_train, y_train)\n",
    "\n",
    "save_load_obj(undersam_X_train, r'4th run - Undersample - ClusterCentroids\\undersam_X_train.pkl', mode='save')\n",
    "save_load_obj(undersam_y_train, r'4th run - Undersample - ClusterCentroids\\undersam_y_train.pkl', mode='save')\n",
    "\n",
    "print(f'oversampled_X shape: {undersam_X_train.shape}')\n",
    "print(f'oversampled_y shape: {undersam_y_train.shape}')\n",
    "print(f'oversampler_y value counts:\\n',undersam_y_train.value_counts())\n",
    "print(sorted(Counter(undersam_y_train).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 0.8010998669643417\n",
      "Best parameters: {'C': 1}\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV\n",
    "param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "grid = GridSearchCV(lg, param_grid, cv=5, scoring='f1') # Maybe change to accuracy as it is balanced now ?\n",
    "grid.fit(undersam_X_train, undersam_y_train)\n",
    "print(f'Best cross-validation score: {grid.best_score_}')\n",
    "print(f'Best parameters: {grid.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base LogReg Prediction score: 83%\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------\n",
    "# Predicting on the test set\n",
    "X_test = vect_fitted.transform(X_test_text)\n",
    "score = int(round(grid.score(X_test, y_test), 2)*100)\n",
    "print(f'Base LogReg Prediction score: {score}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_load_obj(grid, rf'4th run - Undersample - ClusterCentroids\\LogReg-C-1-max_iter-500-F1-{score}%.pkl', mode='save')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5th Run\n",
    "* BalancedBaggingClassifier with sampling_strategy  \n",
    "This is one of the methods to deal with imbalanced data. It is a bagging classifier which uses balanced bootstrap to create new samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = LogisticRegression(max_iter=500, n_jobs=-1)\n",
    "vect_fitted = save_load_obj('', r'1st run\\TfidfVect-X_train-fit-mindf-5-maxdf-02-ngram-2.pkl', mode='load')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: <24019x10130 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 242922 stored elements in Compressed Sparse Row format>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Study 2018 and later\\Mignimind Bootcamp\\Code\\P4-NLP-Tweet-Classification\\.venv\\lib\\site-packages\\imblearn\\ensemble\\_bagging.py:353: FutureWarning: `base_estimator` was renamed to `estimator` in version 0.10 and will be removed in 0.12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base LogReg Prediction score: 81%\n"
     ]
    }
   ],
   "source": [
    "# Loading X_train from the previous run\n",
    "X_train = save_load_obj('', r'1st run\\X_train-transformed.pkl', mode='load')\n",
    "print(f'X_train: {repr(X_train)}')\n",
    "\n",
    "bbc = BalancedBaggingClassifier(base_estimator=lg,\n",
    "                                sampling_strategy='not majority', # upsample the minority class\n",
    "                                replacement=False, \n",
    "                                random_state=77)\n",
    "bbc.fit(X_train, y_train)\n",
    "#---------------------------------------\n",
    "# Predicting on the test set\n",
    "X_test = vect_fitted.transform(X_test_text)\n",
    "score = int(round(bbc.score(X_test, y_test), 2)*100)\n",
    "print(f'Base LogReg Prediction score: {score}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_load_obj(bbc, rf'5th run - BalancedBaggingClassifier\\BBC-sampling_str-not-majority-F1-{score}%.pkl', mode='save')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Seems like the best result we had with StratifiedKFold, so we try to tune the different models with GridSearchCV using StratifiedKFold as our CV."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6th Run\n",
    "* DecisionTreeClassifier with StratifiedKFold and GridSearchCV  \n",
    "I wll try DecisionTreeClassifier as it is simple and quick model. If any good results come out of it, we can easily explain the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation F1 Scores: [0.7872191  0.78423237 0.79264731 0.78219895 0.79362329 0.78835425\n",
      " 0.80338924 0.79354055 0.78780488 0.78938237 0.7849556  0.79091703\n",
      " 0.79166667 0.79447853 0.78940993 0.79481417 0.78268489 0.79384296\n",
      " 0.78319736 0.78133193]\n"
     ]
    }
   ],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=4, random_state=777) # Creating a cross-validation object to account for class imbalance.\n",
    "dtc = DecisionTreeClassifier(random_state=77)\n",
    "scores = cross_val_score(dtc, X_train, y_train, cv=cv, scoring='f1') # Picking F1 score as it is not balanced dataset.\n",
    "print(f'Cross-Validation F1 Scores: {scores}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 0.7569765045551312\n",
      "Best parameters: {'criterion': 'gini', 'max_depth': 13}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
    "              'criterion': ['gini', 'entropy']}\n",
    "grid = GridSearchCV(dtc, param_grid, cv=cv, scoring='f1')\n",
    "grid.fit(X_train, y_train)\n",
    "print(f'Best cross-validation score: {grid.best_score_}')\n",
    "print(f'Best parameters: {grid.best_params_}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Decision Tree Classifier Prediction score: 76%\n"
     ]
    }
   ],
   "source": [
    "# Predicting on the test set\n",
    "X_test = vect_fitted.transform(X_test_text)\n",
    "score = int(round(grid.score(X_test, y_test), 2)*100)\n",
    "print(f'Base Decision Tree Classifier Prediction score: {score}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* I'm not going to even save it. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7th Run\n",
    "* XGBClassifier with StratifiedKFold and GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: <24019x10130 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 242922 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "# Loading X_train, fitted vectorizer from the previous run\n",
    "X_train = save_load_obj('', r'1st run\\X_train-transformed.pkl', mode='load')\n",
    "vect_fitted = save_load_obj('', r'1st run\\TfidfVect-X_train-fit-mindf-5-maxdf-02-ngram-2.pkl', mode='load')\n",
    "print(f'X_train: {repr(X_train)}')\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=4, random_state=777) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation F1 Scores: [0.80372493 0.80620715 0.80816832 0.80886427 0.8019943  0.80769231\n",
      " 0.8057598  0.79202899 0.79681851 0.80656674]\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier()\n",
    "\n",
    "scores = cross_val_score(xgb_model, X_train, y_train, cv=cv, scoring='f1') \n",
    "print(f'Cross-Validation F1 Scores: {scores}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 36 candidates, totalling 720 fits\n",
      "[CV 1/20; 1/36] START learning_rate=0.1, max_depth=3, n_estimators=5............\n",
      "[CV 1/20; 1/36] END learning_rate=0.1, max_depth=3, n_estimators=5;, score=0.749 total time=   0.2s\n",
      "[CV 2/20; 1/36] START learning_rate=0.1, max_depth=3, n_estimators=5............\n",
      "[CV 2/20; 1/36] END learning_rate=0.1, max_depth=3, n_estimators=5;, score=0.746 total time=   0.1s\n",
      "[CV 3/20; 1/36] START learning_rate=0.1, max_depth=3, n_estimators=5............\n",
      "[CV 3/20; 1/36] END learning_rate=0.1, max_depth=3, n_estimators=5;, score=0.752 total time=   0.0s\n",
      "[CV 4/20; 1/36] START learning_rate=0.1, max_depth=3, n_estimators=5............\n",
      "[CV 4/20; 1/36] END learning_rate=0.1, max_depth=3, n_estimators=5;, score=0.748 total time=   0.0s\n",
      "[CV 5/20; 1/36] START learning_rate=0.1, max_depth=3, n_estimators=5............\n",
      "[CV 5/20; 1/36] END learning_rate=0.1, max_depth=3, n_estimators=5;, score=0.748 total time=   0.0s\n",
      "[CV 6/20; 1/36] START learning_rate=0.1, max_depth=3, n_estimators=5............\n",
      "[CV 6/20; 1/36] END learning_rate=0.1, max_depth=3, n_estimators=5;, score=0.750 total time=   0.1s\n",
      "[CV 7/20; 1/36] START learning_rate=0.1, max_depth=3, n_estimators=5............\n",
      "[CV 7/20; 1/36] END learning_rate=0.1, max_depth=3, n_estimators=5;, score=0.747 total time=   0.0s\n",
      "[CV 8/20; 1/36] START learning_rate=0.1, max_depth=3, n_estimators=5............\n",
      "[CV 8/20; 1/36] END learning_rate=0.1, max_depth=3, n_estimators=5;, score=0.751 total time=   0.0s\n",
      "[CV 9/20; 1/36] START learning_rate=0.1, max_depth=3, n_estimators=5............\n",
      "[CV 9/20; 1/36] END learning_rate=0.1, max_depth=3, n_estimators=5;, score=0.751 total time=   0.0s\n",
      "[CV 10/20; 1/36] START learning_rate=0.1, max_depth=3, n_estimators=5...........\n",
      "[CV 10/20; 1/36] END learning_rate=0.1, max_depth=3, n_estimators=5;, score=0.741 total time=   0.0s\n",
      "[CV 11/20; 1/36] START learning_rate=0.1, max_depth=3, n_estimators=5...........\n",
      "[CV 11/20; 1/36] END learning_rate=0.1, max_depth=3, n_estimators=5;, score=0.747 total time=   0.0s\n",
      "[CV 12/20; 1/36] START learning_rate=0.1, max_depth=3, n_estimators=5...........\n",
      "[CV 12/20; 1/36] END learning_rate=0.1, max_depth=3, n_estimators=5;, score=0.746 total time=   0.0s\n",
      "[CV 13/20; 1/36] START learning_rate=0.1, max_depth=3, n_estimators=5...........\n",
      "[CV 13/20; 1/36] END learning_rate=0.1, max_depth=3, n_estimators=5;, score=0.750 total time=   0.0s\n",
      "[CV 14/20; 1/36] START learning_rate=0.1, max_depth=3, n_estimators=5...........\n",
      "[CV 14/20; 1/36] END learning_rate=0.1, max_depth=3, n_estimators=5;, score=0.748 total time=   0.0s\n",
      "[CV 15/20; 1/36] START learning_rate=0.1, max_depth=3, n_estimators=5...........\n",
      "[CV 15/20; 1/36] END learning_rate=0.1, max_depth=3, n_estimators=5;, score=0.749 total time=   0.0s\n",
      "[CV 16/20; 1/36] START learning_rate=0.1, max_depth=3, n_estimators=5...........\n",
      "[CV 16/20; 1/36] END learning_rate=0.1, max_depth=3, n_estimators=5;, score=0.750 total time=   0.0s\n",
      "[CV 17/20; 1/36] START learning_rate=0.1, max_depth=3, n_estimators=5...........\n",
      "[CV 17/20; 1/36] END learning_rate=0.1, max_depth=3, n_estimators=5;, score=0.751 total time=   0.0s\n",
      "[CV 18/20; 1/36] START learning_rate=0.1, max_depth=3, n_estimators=5...........\n",
      "[CV 18/20; 1/36] END learning_rate=0.1, max_depth=3, n_estimators=5;, score=0.747 total time=   0.0s\n",
      "[CV 19/20; 1/36] START learning_rate=0.1, max_depth=3, n_estimators=5...........\n",
      "[CV 19/20; 1/36] END learning_rate=0.1, max_depth=3, n_estimators=5;, score=0.747 total time=   0.0s\n",
      "[CV 20/20; 1/36] START learning_rate=0.1, max_depth=3, n_estimators=5...........\n",
      "[CV 20/20; 1/36] END learning_rate=0.1, max_depth=3, n_estimators=5;, score=0.748 total time=   0.0s\n",
      "[CV 1/20; 2/36] START learning_rate=0.1, max_depth=3, n_estimators=50...........\n",
      "[CV 1/20; 2/36] END learning_rate=0.1, max_depth=3, n_estimators=50;, score=0.749 total time=   0.4s\n",
      "[CV 2/20; 2/36] START learning_rate=0.1, max_depth=3, n_estimators=50...........\n",
      "[CV 2/20; 2/36] END learning_rate=0.1, max_depth=3, n_estimators=50;, score=0.746 total time=   0.4s\n",
      "[CV 3/20; 2/36] START learning_rate=0.1, max_depth=3, n_estimators=50...........\n",
      "[CV 3/20; 2/36] END learning_rate=0.1, max_depth=3, n_estimators=50;, score=0.750 total time=   0.4s\n",
      "[CV 4/20; 2/36] START learning_rate=0.1, max_depth=3, n_estimators=50...........\n",
      "[CV 4/20; 2/36] END learning_rate=0.1, max_depth=3, n_estimators=50;, score=0.748 total time=   0.4s\n",
      "[CV 5/20; 2/36] START learning_rate=0.1, max_depth=3, n_estimators=50...........\n",
      "[CV 5/20; 2/36] END learning_rate=0.1, max_depth=3, n_estimators=50;, score=0.748 total time=   0.4s\n",
      "[CV 6/20; 2/36] START learning_rate=0.1, max_depth=3, n_estimators=50...........\n",
      "[CV 6/20; 2/36] END learning_rate=0.1, max_depth=3, n_estimators=50;, score=0.750 total time=   0.4s\n",
      "[CV 7/20; 2/36] START learning_rate=0.1, max_depth=3, n_estimators=50...........\n",
      "[CV 7/20; 2/36] END learning_rate=0.1, max_depth=3, n_estimators=50;, score=0.747 total time=   0.4s\n",
      "[CV 8/20; 2/36] START learning_rate=0.1, max_depth=3, n_estimators=50...........\n",
      "[CV 8/20; 2/36] END learning_rate=0.1, max_depth=3, n_estimators=50;, score=0.751 total time=   0.4s\n",
      "[CV 9/20; 2/36] START learning_rate=0.1, max_depth=3, n_estimators=50...........\n",
      "[CV 9/20; 2/36] END learning_rate=0.1, max_depth=3, n_estimators=50;, score=0.748 total time=   0.5s\n",
      "[CV 10/20; 2/36] START learning_rate=0.1, max_depth=3, n_estimators=50..........\n",
      "[CV 10/20; 2/36] END learning_rate=0.1, max_depth=3, n_estimators=50;, score=0.741 total time=   0.3s\n",
      "[CV 11/20; 2/36] START learning_rate=0.1, max_depth=3, n_estimators=50..........\n",
      "[CV 11/20; 2/36] END learning_rate=0.1, max_depth=3, n_estimators=50;, score=0.747 total time=   0.4s\n",
      "[CV 12/20; 2/36] START learning_rate=0.1, max_depth=3, n_estimators=50..........\n",
      "[CV 12/20; 2/36] END learning_rate=0.1, max_depth=3, n_estimators=50;, score=0.746 total time=   0.4s\n",
      "[CV 13/20; 2/36] START learning_rate=0.1, max_depth=3, n_estimators=50..........\n",
      "[CV 13/20; 2/36] END learning_rate=0.1, max_depth=3, n_estimators=50;, score=0.750 total time=   0.4s\n",
      "[CV 14/20; 2/36] START learning_rate=0.1, max_depth=3, n_estimators=50..........\n",
      "[CV 14/20; 2/36] END learning_rate=0.1, max_depth=3, n_estimators=50;, score=0.748 total time=   0.4s\n",
      "[CV 15/20; 2/36] START learning_rate=0.1, max_depth=3, n_estimators=50..........\n",
      "[CV 15/20; 2/36] END learning_rate=0.1, max_depth=3, n_estimators=50;, score=0.750 total time=   0.4s\n",
      "[CV 16/20; 2/36] START learning_rate=0.1, max_depth=3, n_estimators=50..........\n",
      "[CV 16/20; 2/36] END learning_rate=0.1, max_depth=3, n_estimators=50;, score=0.750 total time=   0.4s\n",
      "[CV 17/20; 2/36] START learning_rate=0.1, max_depth=3, n_estimators=50..........\n",
      "[CV 17/20; 2/36] END learning_rate=0.1, max_depth=3, n_estimators=50;, score=0.750 total time=   0.4s\n",
      "[CV 18/20; 2/36] START learning_rate=0.1, max_depth=3, n_estimators=50..........\n",
      "[CV 18/20; 2/36] END learning_rate=0.1, max_depth=3, n_estimators=50;, score=0.747 total time=   0.4s\n",
      "[CV 19/20; 2/36] START learning_rate=0.1, max_depth=3, n_estimators=50..........\n",
      "[CV 19/20; 2/36] END learning_rate=0.1, max_depth=3, n_estimators=50;, score=0.747 total time=   0.3s\n",
      "[CV 20/20; 2/36] START learning_rate=0.1, max_depth=3, n_estimators=50..........\n",
      "[CV 20/20; 2/36] END learning_rate=0.1, max_depth=3, n_estimators=50;, score=0.748 total time=   0.4s\n",
      "[CV 1/20; 3/36] START learning_rate=0.1, max_depth=3, n_estimators=120..........\n",
      "[CV 1/20; 3/36] END learning_rate=0.1, max_depth=3, n_estimators=120;, score=0.749 total time=   0.9s\n",
      "[CV 2/20; 3/36] START learning_rate=0.1, max_depth=3, n_estimators=120..........\n",
      "[CV 2/20; 3/36] END learning_rate=0.1, max_depth=3, n_estimators=120;, score=0.746 total time=   0.9s\n",
      "[CV 3/20; 3/36] START learning_rate=0.1, max_depth=3, n_estimators=120..........\n",
      "[CV 3/20; 3/36] END learning_rate=0.1, max_depth=3, n_estimators=120;, score=0.750 total time=   0.9s\n",
      "[CV 4/20; 3/36] START learning_rate=0.1, max_depth=3, n_estimators=120..........\n",
      "[CV 4/20; 3/36] END learning_rate=0.1, max_depth=3, n_estimators=120;, score=0.748 total time=   0.9s\n",
      "[CV 5/20; 3/36] START learning_rate=0.1, max_depth=3, n_estimators=120..........\n",
      "[CV 5/20; 3/36] END learning_rate=0.1, max_depth=3, n_estimators=120;, score=0.748 total time=   0.9s\n",
      "[CV 6/20; 3/36] START learning_rate=0.1, max_depth=3, n_estimators=120..........\n",
      "[CV 6/20; 3/36] END learning_rate=0.1, max_depth=3, n_estimators=120;, score=0.750 total time=   0.9s\n",
      "[CV 7/20; 3/36] START learning_rate=0.1, max_depth=3, n_estimators=120..........\n",
      "[CV 7/20; 3/36] END learning_rate=0.1, max_depth=3, n_estimators=120;, score=0.747 total time=   0.9s\n",
      "[CV 8/20; 3/36] START learning_rate=0.1, max_depth=3, n_estimators=120..........\n",
      "[CV 8/20; 3/36] END learning_rate=0.1, max_depth=3, n_estimators=120;, score=0.751 total time=   0.9s\n",
      "[CV 9/20; 3/36] START learning_rate=0.1, max_depth=3, n_estimators=120..........\n",
      "[CV 9/20; 3/36] END learning_rate=0.1, max_depth=3, n_estimators=120;, score=0.748 total time=   0.9s\n",
      "[CV 10/20; 3/36] START learning_rate=0.1, max_depth=3, n_estimators=120.........\n",
      "[CV 10/20; 3/36] END learning_rate=0.1, max_depth=3, n_estimators=120;, score=0.741 total time=   0.8s\n",
      "[CV 11/20; 3/36] START learning_rate=0.1, max_depth=3, n_estimators=120.........\n",
      "[CV 11/20; 3/36] END learning_rate=0.1, max_depth=3, n_estimators=120;, score=0.747 total time=   0.9s\n",
      "[CV 12/20; 3/36] START learning_rate=0.1, max_depth=3, n_estimators=120.........\n",
      "[CV 12/20; 3/36] END learning_rate=0.1, max_depth=3, n_estimators=120;, score=0.746 total time=   0.9s\n",
      "[CV 13/20; 3/36] START learning_rate=0.1, max_depth=3, n_estimators=120.........\n",
      "[CV 13/20; 3/36] END learning_rate=0.1, max_depth=3, n_estimators=120;, score=0.750 total time=   0.9s\n",
      "[CV 14/20; 3/36] START learning_rate=0.1, max_depth=3, n_estimators=120.........\n",
      "[CV 14/20; 3/36] END learning_rate=0.1, max_depth=3, n_estimators=120;, score=0.748 total time=   0.9s\n",
      "[CV 15/20; 3/36] START learning_rate=0.1, max_depth=3, n_estimators=120.........\n",
      "[CV 15/20; 3/36] END learning_rate=0.1, max_depth=3, n_estimators=120;, score=0.750 total time=   0.9s\n",
      "[CV 16/20; 3/36] START learning_rate=0.1, max_depth=3, n_estimators=120.........\n",
      "[CV 16/20; 3/36] END learning_rate=0.1, max_depth=3, n_estimators=120;, score=0.749 total time=   0.9s\n",
      "[CV 17/20; 3/36] START learning_rate=0.1, max_depth=3, n_estimators=120.........\n",
      "[CV 17/20; 3/36] END learning_rate=0.1, max_depth=3, n_estimators=120;, score=0.750 total time=   0.9s\n",
      "[CV 18/20; 3/36] START learning_rate=0.1, max_depth=3, n_estimators=120.........\n",
      "[CV 18/20; 3/36] END learning_rate=0.1, max_depth=3, n_estimators=120;, score=0.747 total time=   0.9s\n",
      "[CV 19/20; 3/36] START learning_rate=0.1, max_depth=3, n_estimators=120.........\n",
      "[CV 19/20; 3/36] END learning_rate=0.1, max_depth=3, n_estimators=120;, score=0.747 total time=   0.9s\n",
      "[CV 20/20; 3/36] START learning_rate=0.1, max_depth=3, n_estimators=120.........\n",
      "[CV 20/20; 3/36] END learning_rate=0.1, max_depth=3, n_estimators=120;, score=0.748 total time=   0.9s\n",
      "[CV 1/20; 4/36] START learning_rate=0.1, max_depth=5, n_estimators=5............\n",
      "[CV 1/20; 4/36] END learning_rate=0.1, max_depth=5, n_estimators=5;, score=0.749 total time=   0.2s\n",
      "[CV 2/20; 4/36] START learning_rate=0.1, max_depth=5, n_estimators=5............\n",
      "[CV 2/20; 4/36] END learning_rate=0.1, max_depth=5, n_estimators=5;, score=0.746 total time=   0.1s\n",
      "[CV 3/20; 4/36] START learning_rate=0.1, max_depth=5, n_estimators=5............\n",
      "[CV 3/20; 4/36] END learning_rate=0.1, max_depth=5, n_estimators=5;, score=0.750 total time=   0.0s\n",
      "[CV 4/20; 4/36] START learning_rate=0.1, max_depth=5, n_estimators=5............\n",
      "[CV 4/20; 4/36] END learning_rate=0.1, max_depth=5, n_estimators=5;, score=0.748 total time=   0.0s\n",
      "[CV 5/20; 4/36] START learning_rate=0.1, max_depth=5, n_estimators=5............\n",
      "[CV 5/20; 4/36] END learning_rate=0.1, max_depth=5, n_estimators=5;, score=0.748 total time=   0.0s\n",
      "[CV 6/20; 4/36] START learning_rate=0.1, max_depth=5, n_estimators=5............\n",
      "[CV 6/20; 4/36] END learning_rate=0.1, max_depth=5, n_estimators=5;, score=0.750 total time=   0.0s\n",
      "[CV 7/20; 4/36] START learning_rate=0.1, max_depth=5, n_estimators=5............\n",
      "[CV 7/20; 4/36] END learning_rate=0.1, max_depth=5, n_estimators=5;, score=0.747 total time=   0.0s\n",
      "[CV 8/20; 4/36] START learning_rate=0.1, max_depth=5, n_estimators=5............\n",
      "[CV 8/20; 4/36] END learning_rate=0.1, max_depth=5, n_estimators=5;, score=0.751 total time=   0.0s\n",
      "[CV 9/20; 4/36] START learning_rate=0.1, max_depth=5, n_estimators=5............\n",
      "[CV 9/20; 4/36] END learning_rate=0.1, max_depth=5, n_estimators=5;, score=0.748 total time=   0.1s\n",
      "[CV 10/20; 4/36] START learning_rate=0.1, max_depth=5, n_estimators=5...........\n",
      "[CV 10/20; 4/36] END learning_rate=0.1, max_depth=5, n_estimators=5;, score=0.737 total time=   0.0s\n",
      "[CV 11/20; 4/36] START learning_rate=0.1, max_depth=5, n_estimators=5...........\n",
      "[CV 11/20; 4/36] END learning_rate=0.1, max_depth=5, n_estimators=5;, score=0.747 total time=   0.0s\n",
      "[CV 12/20; 4/36] START learning_rate=0.1, max_depth=5, n_estimators=5...........\n",
      "[CV 12/20; 4/36] END learning_rate=0.1, max_depth=5, n_estimators=5;, score=0.746 total time=   0.0s\n",
      "[CV 13/20; 4/36] START learning_rate=0.1, max_depth=5, n_estimators=5...........\n",
      "[CV 13/20; 4/36] END learning_rate=0.1, max_depth=5, n_estimators=5;, score=0.750 total time=   0.1s\n",
      "[CV 14/20; 4/36] START learning_rate=0.1, max_depth=5, n_estimators=5...........\n",
      "[CV 14/20; 4/36] END learning_rate=0.1, max_depth=5, n_estimators=5;, score=0.748 total time=   0.0s\n",
      "[CV 15/20; 4/36] START learning_rate=0.1, max_depth=5, n_estimators=5...........\n",
      "[CV 15/20; 4/36] END learning_rate=0.1, max_depth=5, n_estimators=5;, score=0.749 total time=   0.0s\n",
      "[CV 16/20; 4/36] START learning_rate=0.1, max_depth=5, n_estimators=5...........\n",
      "[CV 16/20; 4/36] END learning_rate=0.1, max_depth=5, n_estimators=5;, score=0.749 total time=   0.0s\n",
      "[CV 17/20; 4/36] START learning_rate=0.1, max_depth=5, n_estimators=5...........\n",
      "[CV 17/20; 4/36] END learning_rate=0.1, max_depth=5, n_estimators=5;, score=0.750 total time=   0.1s\n",
      "[CV 18/20; 4/36] START learning_rate=0.1, max_depth=5, n_estimators=5...........\n",
      "[CV 18/20; 4/36] END learning_rate=0.1, max_depth=5, n_estimators=5;, score=0.747 total time=   0.0s\n",
      "[CV 19/20; 4/36] START learning_rate=0.1, max_depth=5, n_estimators=5...........\n",
      "[CV 19/20; 4/36] END learning_rate=0.1, max_depth=5, n_estimators=5;, score=0.747 total time=   0.0s\n",
      "[CV 20/20; 4/36] START learning_rate=0.1, max_depth=5, n_estimators=5...........\n",
      "[CV 20/20; 4/36] END learning_rate=0.1, max_depth=5, n_estimators=5;, score=0.748 total time=   0.0s\n",
      "[CV 1/20; 5/36] START learning_rate=0.1, max_depth=5, n_estimators=50...........\n",
      "[CV 1/20; 5/36] END learning_rate=0.1, max_depth=5, n_estimators=50;, score=0.749 total time=   0.6s\n",
      "[CV 2/20; 5/36] START learning_rate=0.1, max_depth=5, n_estimators=50...........\n",
      "[CV 2/20; 5/36] END learning_rate=0.1, max_depth=5, n_estimators=50;, score=0.746 total time=   0.6s\n",
      "[CV 3/20; 5/36] START learning_rate=0.1, max_depth=5, n_estimators=50...........\n",
      "[CV 3/20; 5/36] END learning_rate=0.1, max_depth=5, n_estimators=50;, score=0.750 total time=   0.6s\n",
      "[CV 4/20; 5/36] START learning_rate=0.1, max_depth=5, n_estimators=50...........\n",
      "[CV 4/20; 5/36] END learning_rate=0.1, max_depth=5, n_estimators=50;, score=0.748 total time=   0.6s\n",
      "[CV 5/20; 5/36] START learning_rate=0.1, max_depth=5, n_estimators=50...........\n",
      "[CV 5/20; 5/36] END learning_rate=0.1, max_depth=5, n_estimators=50;, score=0.748 total time=   0.6s\n",
      "[CV 6/20; 5/36] START learning_rate=0.1, max_depth=5, n_estimators=50...........\n",
      "[CV 6/20; 5/36] END learning_rate=0.1, max_depth=5, n_estimators=50;, score=0.750 total time=   0.6s\n",
      "[CV 7/20; 5/36] START learning_rate=0.1, max_depth=5, n_estimators=50...........\n",
      "[CV 7/20; 5/36] END learning_rate=0.1, max_depth=5, n_estimators=50;, score=0.747 total time=   0.7s\n",
      "[CV 8/20; 5/36] START learning_rate=0.1, max_depth=5, n_estimators=50...........\n",
      "[CV 8/20; 5/36] END learning_rate=0.1, max_depth=5, n_estimators=50;, score=0.754 total time=   0.7s\n",
      "[CV 9/20; 5/36] START learning_rate=0.1, max_depth=5, n_estimators=50...........\n",
      "[CV 9/20; 5/36] END learning_rate=0.1, max_depth=5, n_estimators=50;, score=0.748 total time=   0.7s\n",
      "[CV 10/20; 5/36] START learning_rate=0.1, max_depth=5, n_estimators=50..........\n",
      "[CV 10/20; 5/36] END learning_rate=0.1, max_depth=5, n_estimators=50;, score=0.737 total time=   0.5s\n",
      "[CV 11/20; 5/36] START learning_rate=0.1, max_depth=5, n_estimators=50..........\n",
      "[CV 11/20; 5/36] END learning_rate=0.1, max_depth=5, n_estimators=50;, score=0.747 total time=   0.6s\n",
      "[CV 12/20; 5/36] START learning_rate=0.1, max_depth=5, n_estimators=50..........\n",
      "[CV 12/20; 5/36] END learning_rate=0.1, max_depth=5, n_estimators=50;, score=0.746 total time=   0.6s\n",
      "[CV 13/20; 5/36] START learning_rate=0.1, max_depth=5, n_estimators=50..........\n",
      "[CV 13/20; 5/36] END learning_rate=0.1, max_depth=5, n_estimators=50;, score=0.750 total time=   0.7s\n",
      "[CV 14/20; 5/36] START learning_rate=0.1, max_depth=5, n_estimators=50..........\n",
      "[CV 14/20; 5/36] END learning_rate=0.1, max_depth=5, n_estimators=50;, score=0.748 total time=   0.6s\n",
      "[CV 15/20; 5/36] START learning_rate=0.1, max_depth=5, n_estimators=50..........\n",
      "[CV 15/20; 5/36] END learning_rate=0.1, max_depth=5, n_estimators=50;, score=0.750 total time=   0.6s\n",
      "[CV 16/20; 5/36] START learning_rate=0.1, max_depth=5, n_estimators=50..........\n",
      "[CV 16/20; 5/36] END learning_rate=0.1, max_depth=5, n_estimators=50;, score=0.749 total time=   0.6s\n",
      "[CV 17/20; 5/36] START learning_rate=0.1, max_depth=5, n_estimators=50..........\n",
      "[CV 17/20; 5/36] END learning_rate=0.1, max_depth=5, n_estimators=50;, score=0.750 total time=   0.6s\n",
      "[CV 18/20; 5/36] START learning_rate=0.1, max_depth=5, n_estimators=50..........\n",
      "[CV 18/20; 5/36] END learning_rate=0.1, max_depth=5, n_estimators=50;, score=0.747 total time=   0.6s\n",
      "[CV 19/20; 5/36] START learning_rate=0.1, max_depth=5, n_estimators=50..........\n",
      "[CV 19/20; 5/36] END learning_rate=0.1, max_depth=5, n_estimators=50;, score=0.747 total time=   0.6s\n",
      "[CV 20/20; 5/36] START learning_rate=0.1, max_depth=5, n_estimators=50..........\n",
      "[CV 20/20; 5/36] END learning_rate=0.1, max_depth=5, n_estimators=50;, score=0.748 total time=   0.6s\n",
      "[CV 1/20; 6/36] START learning_rate=0.1, max_depth=5, n_estimators=120..........\n",
      "[CV 1/20; 6/36] END learning_rate=0.1, max_depth=5, n_estimators=120;, score=0.749 total time=   1.4s\n",
      "[CV 2/20; 6/36] START learning_rate=0.1, max_depth=5, n_estimators=120..........\n",
      "[CV 2/20; 6/36] END learning_rate=0.1, max_depth=5, n_estimators=120;, score=0.746 total time=   1.4s\n",
      "[CV 3/20; 6/36] START learning_rate=0.1, max_depth=5, n_estimators=120..........\n",
      "[CV 3/20; 6/36] END learning_rate=0.1, max_depth=5, n_estimators=120;, score=0.750 total time=   1.4s\n",
      "[CV 4/20; 6/36] START learning_rate=0.1, max_depth=5, n_estimators=120..........\n",
      "[CV 4/20; 6/36] END learning_rate=0.1, max_depth=5, n_estimators=120;, score=0.748 total time=   1.5s\n",
      "[CV 5/20; 6/36] START learning_rate=0.1, max_depth=5, n_estimators=120..........\n",
      "[CV 5/20; 6/36] END learning_rate=0.1, max_depth=5, n_estimators=120;, score=0.748 total time=   1.4s\n",
      "[CV 6/20; 6/36] START learning_rate=0.1, max_depth=5, n_estimators=120..........\n",
      "[CV 6/20; 6/36] END learning_rate=0.1, max_depth=5, n_estimators=120;, score=0.750 total time=   1.4s\n",
      "[CV 7/20; 6/36] START learning_rate=0.1, max_depth=5, n_estimators=120..........\n",
      "[CV 7/20; 6/36] END learning_rate=0.1, max_depth=5, n_estimators=120;, score=0.747 total time=   1.5s\n",
      "[CV 8/20; 6/36] START learning_rate=0.1, max_depth=5, n_estimators=120..........\n",
      "[CV 8/20; 6/36] END learning_rate=0.1, max_depth=5, n_estimators=120;, score=0.754 total time=   1.4s\n",
      "[CV 9/20; 6/36] START learning_rate=0.1, max_depth=5, n_estimators=120..........\n",
      "[CV 9/20; 6/36] END learning_rate=0.1, max_depth=5, n_estimators=120;, score=0.748 total time=   1.5s\n",
      "[CV 10/20; 6/36] START learning_rate=0.1, max_depth=5, n_estimators=120.........\n",
      "[CV 10/20; 6/36] END learning_rate=0.1, max_depth=5, n_estimators=120;, score=0.741 total time=   1.4s\n",
      "[CV 11/20; 6/36] START learning_rate=0.1, max_depth=5, n_estimators=120.........\n",
      "[CV 11/20; 6/36] END learning_rate=0.1, max_depth=5, n_estimators=120;, score=0.747 total time=   1.4s\n",
      "[CV 12/20; 6/36] START learning_rate=0.1, max_depth=5, n_estimators=120.........\n",
      "[CV 12/20; 6/36] END learning_rate=0.1, max_depth=5, n_estimators=120;, score=0.746 total time=   1.4s\n",
      "[CV 13/20; 6/36] START learning_rate=0.1, max_depth=5, n_estimators=120.........\n",
      "[CV 13/20; 6/36] END learning_rate=0.1, max_depth=5, n_estimators=120;, score=0.750 total time=   1.5s\n",
      "[CV 14/20; 6/36] START learning_rate=0.1, max_depth=5, n_estimators=120.........\n",
      "[CV 14/20; 6/36] END learning_rate=0.1, max_depth=5, n_estimators=120;, score=0.748 total time=   1.4s\n",
      "[CV 15/20; 6/36] START learning_rate=0.1, max_depth=5, n_estimators=120.........\n",
      "[CV 15/20; 6/36] END learning_rate=0.1, max_depth=5, n_estimators=120;, score=0.750 total time=   1.5s\n",
      "[CV 16/20; 6/36] START learning_rate=0.1, max_depth=5, n_estimators=120.........\n",
      "[CV 16/20; 6/36] END learning_rate=0.1, max_depth=5, n_estimators=120;, score=0.749 total time=   1.4s\n",
      "[CV 17/20; 6/36] START learning_rate=0.1, max_depth=5, n_estimators=120.........\n",
      "[CV 17/20; 6/36] END learning_rate=0.1, max_depth=5, n_estimators=120;, score=0.750 total time=   1.4s\n",
      "[CV 18/20; 6/36] START learning_rate=0.1, max_depth=5, n_estimators=120.........\n",
      "[CV 18/20; 6/36] END learning_rate=0.1, max_depth=5, n_estimators=120;, score=0.747 total time=   1.4s\n",
      "[CV 19/20; 6/36] START learning_rate=0.1, max_depth=5, n_estimators=120.........\n",
      "[CV 19/20; 6/36] END learning_rate=0.1, max_depth=5, n_estimators=120;, score=0.747 total time=   1.4s\n",
      "[CV 20/20; 6/36] START learning_rate=0.1, max_depth=5, n_estimators=120.........\n",
      "[CV 20/20; 6/36] END learning_rate=0.1, max_depth=5, n_estimators=120;, score=0.748 total time=   1.4s\n",
      "[CV 1/20; 7/36] START learning_rate=0.1, max_depth=6, n_estimators=5............\n",
      "[CV 1/20; 7/36] END learning_rate=0.1, max_depth=6, n_estimators=5;, score=0.749 total time=   0.1s\n",
      "[CV 2/20; 7/36] START learning_rate=0.1, max_depth=6, n_estimators=5............\n",
      "[CV 2/20; 7/36] END learning_rate=0.1, max_depth=6, n_estimators=5;, score=0.746 total time=   0.1s\n",
      "[CV 3/20; 7/36] START learning_rate=0.1, max_depth=6, n_estimators=5............\n",
      "[CV 3/20; 7/36] END learning_rate=0.1, max_depth=6, n_estimators=5;, score=0.750 total time=   0.0s\n",
      "[CV 4/20; 7/36] START learning_rate=0.1, max_depth=6, n_estimators=5............\n",
      "[CV 4/20; 7/36] END learning_rate=0.1, max_depth=6, n_estimators=5;, score=0.748 total time=   0.1s\n",
      "[CV 5/20; 7/36] START learning_rate=0.1, max_depth=6, n_estimators=5............\n",
      "[CV 5/20; 7/36] END learning_rate=0.1, max_depth=6, n_estimators=5;, score=0.748 total time=   0.1s\n",
      "[CV 6/20; 7/36] START learning_rate=0.1, max_depth=6, n_estimators=5............\n",
      "[CV 6/20; 7/36] END learning_rate=0.1, max_depth=6, n_estimators=5;, score=0.750 total time=   0.0s\n",
      "[CV 7/20; 7/36] START learning_rate=0.1, max_depth=6, n_estimators=5............\n",
      "[CV 7/20; 7/36] END learning_rate=0.1, max_depth=6, n_estimators=5;, score=0.747 total time=   0.1s\n",
      "[CV 8/20; 7/36] START learning_rate=0.1, max_depth=6, n_estimators=5............\n",
      "[CV 8/20; 7/36] END learning_rate=0.1, max_depth=6, n_estimators=5;, score=0.754 total time=   0.0s\n",
      "[CV 9/20; 7/36] START learning_rate=0.1, max_depth=6, n_estimators=5............\n",
      "[CV 9/20; 7/36] END learning_rate=0.1, max_depth=6, n_estimators=5;, score=0.748 total time=   0.1s\n",
      "[CV 10/20; 7/36] START learning_rate=0.1, max_depth=6, n_estimators=5...........\n",
      "[CV 10/20; 7/36] END learning_rate=0.1, max_depth=6, n_estimators=5;, score=0.737 total time=   0.0s\n",
      "[CV 11/20; 7/36] START learning_rate=0.1, max_depth=6, n_estimators=5...........\n",
      "[CV 11/20; 7/36] END learning_rate=0.1, max_depth=6, n_estimators=5;, score=0.747 total time=   0.0s\n",
      "[CV 12/20; 7/36] START learning_rate=0.1, max_depth=6, n_estimators=5...........\n",
      "[CV 12/20; 7/36] END learning_rate=0.1, max_depth=6, n_estimators=5;, score=0.746 total time=   0.0s\n",
      "[CV 13/20; 7/36] START learning_rate=0.1, max_depth=6, n_estimators=5...........\n",
      "[CV 13/20; 7/36] END learning_rate=0.1, max_depth=6, n_estimators=5;, score=0.750 total time=   0.1s\n",
      "[CV 14/20; 7/36] START learning_rate=0.1, max_depth=6, n_estimators=5...........\n",
      "[CV 14/20; 7/36] END learning_rate=0.1, max_depth=6, n_estimators=5;, score=0.748 total time=   0.0s\n",
      "[CV 15/20; 7/36] START learning_rate=0.1, max_depth=6, n_estimators=5...........\n",
      "[CV 15/20; 7/36] END learning_rate=0.1, max_depth=6, n_estimators=5;, score=0.749 total time=   0.0s\n",
      "[CV 16/20; 7/36] START learning_rate=0.1, max_depth=6, n_estimators=5...........\n",
      "[CV 16/20; 7/36] END learning_rate=0.1, max_depth=6, n_estimators=5;, score=0.749 total time=   0.1s\n",
      "[CV 17/20; 7/36] START learning_rate=0.1, max_depth=6, n_estimators=5...........\n",
      "[CV 17/20; 7/36] END learning_rate=0.1, max_depth=6, n_estimators=5;, score=0.750 total time=   0.0s\n",
      "[CV 18/20; 7/36] START learning_rate=0.1, max_depth=6, n_estimators=5...........\n",
      "[CV 18/20; 7/36] END learning_rate=0.1, max_depth=6, n_estimators=5;, score=0.747 total time=   0.0s\n",
      "[CV 19/20; 7/36] START learning_rate=0.1, max_depth=6, n_estimators=5...........\n",
      "[CV 19/20; 7/36] END learning_rate=0.1, max_depth=6, n_estimators=5;, score=0.747 total time=   0.0s\n",
      "[CV 20/20; 7/36] START learning_rate=0.1, max_depth=6, n_estimators=5...........\n",
      "[CV 20/20; 7/36] END learning_rate=0.1, max_depth=6, n_estimators=5;, score=0.748 total time=   0.0s\n",
      "[CV 1/20; 8/36] START learning_rate=0.1, max_depth=6, n_estimators=50...........\n",
      "[CV 1/20; 8/36] END learning_rate=0.1, max_depth=6, n_estimators=50;, score=0.749 total time=   0.7s\n",
      "[CV 2/20; 8/36] START learning_rate=0.1, max_depth=6, n_estimators=50...........\n",
      "[CV 2/20; 8/36] END learning_rate=0.1, max_depth=6, n_estimators=50;, score=0.746 total time=   0.7s\n",
      "[CV 3/20; 8/36] START learning_rate=0.1, max_depth=6, n_estimators=50...........\n",
      "[CV 3/20; 8/36] END learning_rate=0.1, max_depth=6, n_estimators=50;, score=0.750 total time=   0.7s\n",
      "[CV 4/20; 8/36] START learning_rate=0.1, max_depth=6, n_estimators=50...........\n",
      "[CV 4/20; 8/36] END learning_rate=0.1, max_depth=6, n_estimators=50;, score=0.748 total time=   0.8s\n",
      "[CV 5/20; 8/36] START learning_rate=0.1, max_depth=6, n_estimators=50...........\n",
      "[CV 5/20; 8/36] END learning_rate=0.1, max_depth=6, n_estimators=50;, score=0.748 total time=   0.7s\n",
      "[CV 6/20; 8/36] START learning_rate=0.1, max_depth=6, n_estimators=50...........\n",
      "[CV 6/20; 8/36] END learning_rate=0.1, max_depth=6, n_estimators=50;, score=0.750 total time=   0.7s\n",
      "[CV 7/20; 8/36] START learning_rate=0.1, max_depth=6, n_estimators=50...........\n",
      "[CV 7/20; 8/36] END learning_rate=0.1, max_depth=6, n_estimators=50;, score=0.747 total time=   0.7s\n",
      "[CV 8/20; 8/36] START learning_rate=0.1, max_depth=6, n_estimators=50...........\n",
      "[CV 8/20; 8/36] END learning_rate=0.1, max_depth=6, n_estimators=50;, score=0.754 total time=   0.8s\n",
      "[CV 9/20; 8/36] START learning_rate=0.1, max_depth=6, n_estimators=50...........\n",
      "[CV 9/20; 8/36] END learning_rate=0.1, max_depth=6, n_estimators=50;, score=0.748 total time=   0.8s\n",
      "[CV 10/20; 8/36] START learning_rate=0.1, max_depth=6, n_estimators=50..........\n",
      "[CV 10/20; 8/36] END learning_rate=0.1, max_depth=6, n_estimators=50;, score=0.737 total time=   0.8s\n",
      "[CV 11/20; 8/36] START learning_rate=0.1, max_depth=6, n_estimators=50..........\n",
      "[CV 11/20; 8/36] END learning_rate=0.1, max_depth=6, n_estimators=50;, score=0.747 total time=   0.8s\n",
      "[CV 12/20; 8/36] START learning_rate=0.1, max_depth=6, n_estimators=50..........\n",
      "[CV 12/20; 8/36] END learning_rate=0.1, max_depth=6, n_estimators=50;, score=0.746 total time=   0.7s\n",
      "[CV 13/20; 8/36] START learning_rate=0.1, max_depth=6, n_estimators=50..........\n",
      "[CV 13/20; 8/36] END learning_rate=0.1, max_depth=6, n_estimators=50;, score=0.750 total time=   0.8s\n",
      "[CV 14/20; 8/36] START learning_rate=0.1, max_depth=6, n_estimators=50..........\n",
      "[CV 14/20; 8/36] END learning_rate=0.1, max_depth=6, n_estimators=50;, score=0.748 total time=   0.7s\n",
      "[CV 15/20; 8/36] START learning_rate=0.1, max_depth=6, n_estimators=50..........\n",
      "[CV 15/20; 8/36] END learning_rate=0.1, max_depth=6, n_estimators=50;, score=0.750 total time=   0.7s\n",
      "[CV 16/20; 8/36] START learning_rate=0.1, max_depth=6, n_estimators=50..........\n",
      "[CV 16/20; 8/36] END learning_rate=0.1, max_depth=6, n_estimators=50;, score=0.749 total time=   0.7s\n",
      "[CV 17/20; 8/36] START learning_rate=0.1, max_depth=6, n_estimators=50..........\n",
      "[CV 17/20; 8/36] END learning_rate=0.1, max_depth=6, n_estimators=50;, score=0.750 total time=   0.8s\n",
      "[CV 18/20; 8/36] START learning_rate=0.1, max_depth=6, n_estimators=50..........\n",
      "[CV 18/20; 8/36] END learning_rate=0.1, max_depth=6, n_estimators=50;, score=0.747 total time=   0.7s\n",
      "[CV 19/20; 8/36] START learning_rate=0.1, max_depth=6, n_estimators=50..........\n",
      "[CV 19/20; 8/36] END learning_rate=0.1, max_depth=6, n_estimators=50;, score=0.747 total time=   0.7s\n",
      "[CV 20/20; 8/36] START learning_rate=0.1, max_depth=6, n_estimators=50..........\n",
      "[CV 20/20; 8/36] END learning_rate=0.1, max_depth=6, n_estimators=50;, score=0.748 total time=   0.7s\n",
      "[CV 1/20; 9/36] START learning_rate=0.1, max_depth=6, n_estimators=120..........\n",
      "[CV 1/20; 9/36] END learning_rate=0.1, max_depth=6, n_estimators=120;, score=0.749 total time=   1.7s\n",
      "[CV 2/20; 9/36] START learning_rate=0.1, max_depth=6, n_estimators=120..........\n",
      "[CV 2/20; 9/36] END learning_rate=0.1, max_depth=6, n_estimators=120;, score=0.746 total time=   1.7s\n",
      "[CV 3/20; 9/36] START learning_rate=0.1, max_depth=6, n_estimators=120..........\n",
      "[CV 3/20; 9/36] END learning_rate=0.1, max_depth=6, n_estimators=120;, score=0.750 total time=   1.7s\n",
      "[CV 4/20; 9/36] START learning_rate=0.1, max_depth=6, n_estimators=120..........\n",
      "[CV 4/20; 9/36] END learning_rate=0.1, max_depth=6, n_estimators=120;, score=0.748 total time=   1.8s\n",
      "[CV 5/20; 9/36] START learning_rate=0.1, max_depth=6, n_estimators=120..........\n",
      "[CV 5/20; 9/36] END learning_rate=0.1, max_depth=6, n_estimators=120;, score=0.748 total time=   1.7s\n",
      "[CV 6/20; 9/36] START learning_rate=0.1, max_depth=6, n_estimators=120..........\n",
      "[CV 6/20; 9/36] END learning_rate=0.1, max_depth=6, n_estimators=120;, score=0.750 total time=   1.8s\n",
      "[CV 7/20; 9/36] START learning_rate=0.1, max_depth=6, n_estimators=120..........\n",
      "[CV 7/20; 9/36] END learning_rate=0.1, max_depth=6, n_estimators=120;, score=0.747 total time=   1.8s\n",
      "[CV 8/20; 9/36] START learning_rate=0.1, max_depth=6, n_estimators=120..........\n",
      "[CV 8/20; 9/36] END learning_rate=0.1, max_depth=6, n_estimators=120;, score=0.754 total time=   1.8s\n",
      "[CV 9/20; 9/36] START learning_rate=0.1, max_depth=6, n_estimators=120..........\n",
      "[CV 9/20; 9/36] END learning_rate=0.1, max_depth=6, n_estimators=120;, score=0.748 total time=   1.8s\n",
      "[CV 10/20; 9/36] START learning_rate=0.1, max_depth=6, n_estimators=120.........\n",
      "[CV 10/20; 9/36] END learning_rate=0.1, max_depth=6, n_estimators=120;, score=0.737 total time=   1.6s\n",
      "[CV 11/20; 9/36] START learning_rate=0.1, max_depth=6, n_estimators=120.........\n",
      "[CV 11/20; 9/36] END learning_rate=0.1, max_depth=6, n_estimators=120;, score=0.747 total time=   1.8s\n",
      "[CV 12/20; 9/36] START learning_rate=0.1, max_depth=6, n_estimators=120.........\n",
      "[CV 12/20; 9/36] END learning_rate=0.1, max_depth=6, n_estimators=120;, score=0.746 total time=   1.8s\n",
      "[CV 13/20; 9/36] START learning_rate=0.1, max_depth=6, n_estimators=120.........\n",
      "[CV 13/20; 9/36] END learning_rate=0.1, max_depth=6, n_estimators=120;, score=0.750 total time=   1.9s\n",
      "[CV 14/20; 9/36] START learning_rate=0.1, max_depth=6, n_estimators=120.........\n",
      "[CV 14/20; 9/36] END learning_rate=0.1, max_depth=6, n_estimators=120;, score=0.748 total time=   1.8s\n",
      "[CV 15/20; 9/36] START learning_rate=0.1, max_depth=6, n_estimators=120.........\n",
      "[CV 15/20; 9/36] END learning_rate=0.1, max_depth=6, n_estimators=120;, score=0.750 total time=   1.8s\n",
      "[CV 16/20; 9/36] START learning_rate=0.1, max_depth=6, n_estimators=120.........\n",
      "[CV 16/20; 9/36] END learning_rate=0.1, max_depth=6, n_estimators=120;, score=0.749 total time=   1.7s\n",
      "[CV 17/20; 9/36] START learning_rate=0.1, max_depth=6, n_estimators=120.........\n",
      "[CV 17/20; 9/36] END learning_rate=0.1, max_depth=6, n_estimators=120;, score=0.750 total time=   1.8s\n",
      "[CV 18/20; 9/36] START learning_rate=0.1, max_depth=6, n_estimators=120.........\n",
      "[CV 18/20; 9/36] END learning_rate=0.1, max_depth=6, n_estimators=120;, score=0.747 total time=   1.8s\n",
      "[CV 19/20; 9/36] START learning_rate=0.1, max_depth=6, n_estimators=120.........\n",
      "[CV 19/20; 9/36] END learning_rate=0.1, max_depth=6, n_estimators=120;, score=0.747 total time=   1.7s\n",
      "[CV 20/20; 9/36] START learning_rate=0.1, max_depth=6, n_estimators=120.........\n",
      "[CV 20/20; 9/36] END learning_rate=0.1, max_depth=6, n_estimators=120;, score=0.748 total time=   1.7s\n",
      "[CV 1/20; 10/36] START learning_rate=0.1, max_depth=7, n_estimators=5...........\n",
      "[CV 1/20; 10/36] END learning_rate=0.1, max_depth=7, n_estimators=5;, score=0.749 total time=   0.1s\n",
      "[CV 2/20; 10/36] START learning_rate=0.1, max_depth=7, n_estimators=5...........\n",
      "[CV 2/20; 10/36] END learning_rate=0.1, max_depth=7, n_estimators=5;, score=0.746 total time=   0.1s\n",
      "[CV 3/20; 10/36] START learning_rate=0.1, max_depth=7, n_estimators=5...........\n",
      "[CV 3/20; 10/36] END learning_rate=0.1, max_depth=7, n_estimators=5;, score=0.750 total time=   0.1s\n",
      "[CV 4/20; 10/36] START learning_rate=0.1, max_depth=7, n_estimators=5...........\n",
      "[CV 4/20; 10/36] END learning_rate=0.1, max_depth=7, n_estimators=5;, score=0.748 total time=   0.1s\n",
      "[CV 5/20; 10/36] START learning_rate=0.1, max_depth=7, n_estimators=5...........\n",
      "[CV 5/20; 10/36] END learning_rate=0.1, max_depth=7, n_estimators=5;, score=0.748 total time=   0.1s\n",
      "[CV 6/20; 10/36] START learning_rate=0.1, max_depth=7, n_estimators=5...........\n",
      "[CV 6/20; 10/36] END learning_rate=0.1, max_depth=7, n_estimators=5;, score=0.750 total time=   0.1s\n",
      "[CV 7/20; 10/36] START learning_rate=0.1, max_depth=7, n_estimators=5...........\n",
      "[CV 7/20; 10/36] END learning_rate=0.1, max_depth=7, n_estimators=5;, score=0.747 total time=   0.1s\n",
      "[CV 8/20; 10/36] START learning_rate=0.1, max_depth=7, n_estimators=5...........\n",
      "[CV 8/20; 10/36] END learning_rate=0.1, max_depth=7, n_estimators=5;, score=0.754 total time=   0.1s\n",
      "[CV 9/20; 10/36] START learning_rate=0.1, max_depth=7, n_estimators=5...........\n",
      "[CV 9/20; 10/36] END learning_rate=0.1, max_depth=7, n_estimators=5;, score=0.748 total time=   0.1s\n",
      "[CV 10/20; 10/36] START learning_rate=0.1, max_depth=7, n_estimators=5..........\n",
      "[CV 10/20; 10/36] END learning_rate=0.1, max_depth=7, n_estimators=5;, score=0.737 total time=   0.1s\n",
      "[CV 11/20; 10/36] START learning_rate=0.1, max_depth=7, n_estimators=5..........\n",
      "[CV 11/20; 10/36] END learning_rate=0.1, max_depth=7, n_estimators=5;, score=0.747 total time=   0.1s\n",
      "[CV 12/20; 10/36] START learning_rate=0.1, max_depth=7, n_estimators=5..........\n",
      "[CV 12/20; 10/36] END learning_rate=0.1, max_depth=7, n_estimators=5;, score=0.746 total time=   0.1s\n",
      "[CV 13/20; 10/36] START learning_rate=0.1, max_depth=7, n_estimators=5..........\n",
      "[CV 13/20; 10/36] END learning_rate=0.1, max_depth=7, n_estimators=5;, score=0.750 total time=   0.1s\n",
      "[CV 14/20; 10/36] START learning_rate=0.1, max_depth=7, n_estimators=5..........\n",
      "[CV 14/20; 10/36] END learning_rate=0.1, max_depth=7, n_estimators=5;, score=0.748 total time=   0.1s\n",
      "[CV 15/20; 10/36] START learning_rate=0.1, max_depth=7, n_estimators=5..........\n",
      "[CV 15/20; 10/36] END learning_rate=0.1, max_depth=7, n_estimators=5;, score=0.749 total time=   0.1s\n",
      "[CV 16/20; 10/36] START learning_rate=0.1, max_depth=7, n_estimators=5..........\n",
      "[CV 16/20; 10/36] END learning_rate=0.1, max_depth=7, n_estimators=5;, score=0.749 total time=   0.1s\n",
      "[CV 17/20; 10/36] START learning_rate=0.1, max_depth=7, n_estimators=5..........\n",
      "[CV 17/20; 10/36] END learning_rate=0.1, max_depth=7, n_estimators=5;, score=0.750 total time=   0.1s\n",
      "[CV 18/20; 10/36] START learning_rate=0.1, max_depth=7, n_estimators=5..........\n",
      "[CV 18/20; 10/36] END learning_rate=0.1, max_depth=7, n_estimators=5;, score=0.747 total time=   0.1s\n",
      "[CV 19/20; 10/36] START learning_rate=0.1, max_depth=7, n_estimators=5..........\n",
      "[CV 19/20; 10/36] END learning_rate=0.1, max_depth=7, n_estimators=5;, score=0.747 total time=   0.1s\n",
      "[CV 20/20; 10/36] START learning_rate=0.1, max_depth=7, n_estimators=5..........\n",
      "[CV 20/20; 10/36] END learning_rate=0.1, max_depth=7, n_estimators=5;, score=0.748 total time=   0.1s\n",
      "[CV 1/20; 11/36] START learning_rate=0.1, max_depth=7, n_estimators=50..........\n",
      "[CV 1/20; 11/36] END learning_rate=0.1, max_depth=7, n_estimators=50;, score=0.749 total time=   0.9s\n",
      "[CV 2/20; 11/36] START learning_rate=0.1, max_depth=7, n_estimators=50..........\n",
      "[CV 2/20; 11/36] END learning_rate=0.1, max_depth=7, n_estimators=50;, score=0.746 total time=   0.8s\n",
      "[CV 3/20; 11/36] START learning_rate=0.1, max_depth=7, n_estimators=50..........\n",
      "[CV 3/20; 11/36] END learning_rate=0.1, max_depth=7, n_estimators=50;, score=0.750 total time=   0.8s\n",
      "[CV 4/20; 11/36] START learning_rate=0.1, max_depth=7, n_estimators=50..........\n",
      "[CV 4/20; 11/36] END learning_rate=0.1, max_depth=7, n_estimators=50;, score=0.748 total time=   0.8s\n",
      "[CV 5/20; 11/36] START learning_rate=0.1, max_depth=7, n_estimators=50..........\n",
      "[CV 5/20; 11/36] END learning_rate=0.1, max_depth=7, n_estimators=50;, score=0.748 total time=   0.9s\n",
      "[CV 6/20; 11/36] START learning_rate=0.1, max_depth=7, n_estimators=50..........\n",
      "[CV 6/20; 11/36] END learning_rate=0.1, max_depth=7, n_estimators=50;, score=0.750 total time=   0.9s\n",
      "[CV 7/20; 11/36] START learning_rate=0.1, max_depth=7, n_estimators=50..........\n",
      "[CV 7/20; 11/36] END learning_rate=0.1, max_depth=7, n_estimators=50;, score=0.747 total time=   0.8s\n",
      "[CV 8/20; 11/36] START learning_rate=0.1, max_depth=7, n_estimators=50..........\n",
      "[CV 8/20; 11/36] END learning_rate=0.1, max_depth=7, n_estimators=50;, score=0.754 total time=   0.9s\n",
      "[CV 9/20; 11/36] START learning_rate=0.1, max_depth=7, n_estimators=50..........\n",
      "[CV 9/20; 11/36] END learning_rate=0.1, max_depth=7, n_estimators=50;, score=0.748 total time=   0.9s\n",
      "[CV 10/20; 11/36] START learning_rate=0.1, max_depth=7, n_estimators=50.........\n",
      "[CV 10/20; 11/36] END learning_rate=0.1, max_depth=7, n_estimators=50;, score=0.737 total time=   0.8s\n",
      "[CV 11/20; 11/36] START learning_rate=0.1, max_depth=7, n_estimators=50.........\n",
      "[CV 11/20; 11/36] END learning_rate=0.1, max_depth=7, n_estimators=50;, score=0.747 total time=   0.8s\n",
      "[CV 12/20; 11/36] START learning_rate=0.1, max_depth=7, n_estimators=50.........\n",
      "[CV 12/20; 11/36] END learning_rate=0.1, max_depth=7, n_estimators=50;, score=0.746 total time=   0.8s\n",
      "[CV 13/20; 11/36] START learning_rate=0.1, max_depth=7, n_estimators=50.........\n",
      "[CV 13/20; 11/36] END learning_rate=0.1, max_depth=7, n_estimators=50;, score=0.750 total time=   0.9s\n",
      "[CV 14/20; 11/36] START learning_rate=0.1, max_depth=7, n_estimators=50.........\n",
      "[CV 14/20; 11/36] END learning_rate=0.1, max_depth=7, n_estimators=50;, score=0.748 total time=   0.8s\n",
      "[CV 15/20; 11/36] START learning_rate=0.1, max_depth=7, n_estimators=50.........\n",
      "[CV 15/20; 11/36] END learning_rate=0.1, max_depth=7, n_estimators=50;, score=0.750 total time=   0.8s\n",
      "[CV 16/20; 11/36] START learning_rate=0.1, max_depth=7, n_estimators=50.........\n",
      "[CV 16/20; 11/36] END learning_rate=0.1, max_depth=7, n_estimators=50;, score=0.749 total time=   0.8s\n",
      "[CV 17/20; 11/36] START learning_rate=0.1, max_depth=7, n_estimators=50.........\n",
      "[CV 17/20; 11/36] END learning_rate=0.1, max_depth=7, n_estimators=50;, score=0.750 total time=   0.9s\n",
      "[CV 18/20; 11/36] START learning_rate=0.1, max_depth=7, n_estimators=50.........\n",
      "[CV 18/20; 11/36] END learning_rate=0.1, max_depth=7, n_estimators=50;, score=0.747 total time=   0.8s\n",
      "[CV 19/20; 11/36] START learning_rate=0.1, max_depth=7, n_estimators=50.........\n",
      "[CV 19/20; 11/36] END learning_rate=0.1, max_depth=7, n_estimators=50;, score=0.743 total time=   0.8s\n",
      "[CV 20/20; 11/36] START learning_rate=0.1, max_depth=7, n_estimators=50.........\n",
      "[CV 20/20; 11/36] END learning_rate=0.1, max_depth=7, n_estimators=50;, score=0.748 total time=   0.8s\n",
      "[CV 1/20; 12/36] START learning_rate=0.1, max_depth=7, n_estimators=120.........\n",
      "[CV 1/20; 12/36] END learning_rate=0.1, max_depth=7, n_estimators=120;, score=0.749 total time=   2.0s\n",
      "[CV 2/20; 12/36] START learning_rate=0.1, max_depth=7, n_estimators=120.........\n",
      "[CV 2/20; 12/36] END learning_rate=0.1, max_depth=7, n_estimators=120;, score=0.746 total time=   1.9s\n",
      "[CV 3/20; 12/36] START learning_rate=0.1, max_depth=7, n_estimators=120.........\n",
      "[CV 3/20; 12/36] END learning_rate=0.1, max_depth=7, n_estimators=120;, score=0.750 total time=   2.0s\n",
      "[CV 4/20; 12/36] START learning_rate=0.1, max_depth=7, n_estimators=120.........\n",
      "[CV 4/20; 12/36] END learning_rate=0.1, max_depth=7, n_estimators=120;, score=0.748 total time=   2.0s\n",
      "[CV 5/20; 12/36] START learning_rate=0.1, max_depth=7, n_estimators=120.........\n",
      "[CV 5/20; 12/36] END learning_rate=0.1, max_depth=7, n_estimators=120;, score=0.748 total time=   2.1s\n",
      "[CV 6/20; 12/36] START learning_rate=0.1, max_depth=7, n_estimators=120.........\n",
      "[CV 6/20; 12/36] END learning_rate=0.1, max_depth=7, n_estimators=120;, score=0.750 total time=   2.0s\n",
      "[CV 7/20; 12/36] START learning_rate=0.1, max_depth=7, n_estimators=120.........\n",
      "[CV 7/20; 12/36] END learning_rate=0.1, max_depth=7, n_estimators=120;, score=0.747 total time=   2.0s\n",
      "[CV 8/20; 12/36] START learning_rate=0.1, max_depth=7, n_estimators=120.........\n",
      "[CV 8/20; 12/36] END learning_rate=0.1, max_depth=7, n_estimators=120;, score=0.754 total time=   2.0s\n",
      "[CV 9/20; 12/36] START learning_rate=0.1, max_depth=7, n_estimators=120.........\n",
      "[CV 9/20; 12/36] END learning_rate=0.1, max_depth=7, n_estimators=120;, score=0.748 total time=   2.1s\n",
      "[CV 10/20; 12/36] START learning_rate=0.1, max_depth=7, n_estimators=120........\n",
      "[CV 10/20; 12/36] END learning_rate=0.1, max_depth=7, n_estimators=120;, score=0.737 total time=   2.0s\n",
      "[CV 11/20; 12/36] START learning_rate=0.1, max_depth=7, n_estimators=120........\n",
      "[CV 11/20; 12/36] END learning_rate=0.1, max_depth=7, n_estimators=120;, score=0.747 total time=   2.0s\n",
      "[CV 12/20; 12/36] START learning_rate=0.1, max_depth=7, n_estimators=120........\n",
      "[CV 12/20; 12/36] END learning_rate=0.1, max_depth=7, n_estimators=120;, score=0.746 total time=   2.0s\n",
      "[CV 13/20; 12/36] START learning_rate=0.1, max_depth=7, n_estimators=120........\n",
      "[CV 13/20; 12/36] END learning_rate=0.1, max_depth=7, n_estimators=120;, score=0.750 total time=   2.1s\n",
      "[CV 14/20; 12/36] START learning_rate=0.1, max_depth=7, n_estimators=120........\n",
      "[CV 14/20; 12/36] END learning_rate=0.1, max_depth=7, n_estimators=120;, score=0.748 total time=   2.0s\n",
      "[CV 15/20; 12/36] START learning_rate=0.1, max_depth=7, n_estimators=120........\n",
      "[CV 15/20; 12/36] END learning_rate=0.1, max_depth=7, n_estimators=120;, score=0.750 total time=   2.0s\n",
      "[CV 16/20; 12/36] START learning_rate=0.1, max_depth=7, n_estimators=120........\n",
      "[CV 16/20; 12/36] END learning_rate=0.1, max_depth=7, n_estimators=120;, score=0.749 total time=   2.0s\n",
      "[CV 17/20; 12/36] START learning_rate=0.1, max_depth=7, n_estimators=120........\n",
      "[CV 17/20; 12/36] END learning_rate=0.1, max_depth=7, n_estimators=120;, score=0.750 total time=   2.0s\n",
      "[CV 18/20; 12/36] START learning_rate=0.1, max_depth=7, n_estimators=120........\n",
      "[CV 18/20; 12/36] END learning_rate=0.1, max_depth=7, n_estimators=120;, score=0.747 total time=   2.0s\n",
      "[CV 19/20; 12/36] START learning_rate=0.1, max_depth=7, n_estimators=120........\n",
      "[CV 19/20; 12/36] END learning_rate=0.1, max_depth=7, n_estimators=120;, score=0.743 total time=   1.9s\n",
      "[CV 20/20; 12/36] START learning_rate=0.1, max_depth=7, n_estimators=120........\n",
      "[CV 20/20; 12/36] END learning_rate=0.1, max_depth=7, n_estimators=120;, score=0.748 total time=   2.0s\n",
      "[CV 1/20; 13/36] START learning_rate=0.3, max_depth=3, n_estimators=5...........\n",
      "[CV 1/20; 13/36] END learning_rate=0.3, max_depth=3, n_estimators=5;, score=0.749 total time=   0.0s\n",
      "[CV 2/20; 13/36] START learning_rate=0.3, max_depth=3, n_estimators=5...........\n",
      "[CV 2/20; 13/36] END learning_rate=0.3, max_depth=3, n_estimators=5;, score=0.746 total time=   0.0s\n",
      "[CV 3/20; 13/36] START learning_rate=0.3, max_depth=3, n_estimators=5...........\n",
      "[CV 3/20; 13/36] END learning_rate=0.3, max_depth=3, n_estimators=5;, score=0.752 total time=   0.0s\n",
      "[CV 4/20; 13/36] START learning_rate=0.3, max_depth=3, n_estimators=5...........\n",
      "[CV 4/20; 13/36] END learning_rate=0.3, max_depth=3, n_estimators=5;, score=0.748 total time=   0.0s\n",
      "[CV 5/20; 13/36] START learning_rate=0.3, max_depth=3, n_estimators=5...........\n",
      "[CV 5/20; 13/36] END learning_rate=0.3, max_depth=3, n_estimators=5;, score=0.748 total time=   0.0s\n",
      "[CV 6/20; 13/36] START learning_rate=0.3, max_depth=3, n_estimators=5...........\n",
      "[CV 6/20; 13/36] END learning_rate=0.3, max_depth=3, n_estimators=5;, score=0.750 total time=   0.0s\n",
      "[CV 7/20; 13/36] START learning_rate=0.3, max_depth=3, n_estimators=5...........\n",
      "[CV 7/20; 13/36] END learning_rate=0.3, max_depth=3, n_estimators=5;, score=0.747 total time=   0.0s\n",
      "[CV 8/20; 13/36] START learning_rate=0.3, max_depth=3, n_estimators=5...........\n",
      "[CV 8/20; 13/36] END learning_rate=0.3, max_depth=3, n_estimators=5;, score=0.751 total time=   0.0s\n",
      "[CV 9/20; 13/36] START learning_rate=0.3, max_depth=3, n_estimators=5...........\n",
      "[CV 9/20; 13/36] END learning_rate=0.3, max_depth=3, n_estimators=5;, score=0.751 total time=   0.0s\n",
      "[CV 10/20; 13/36] START learning_rate=0.3, max_depth=3, n_estimators=5..........\n",
      "[CV 10/20; 13/36] END learning_rate=0.3, max_depth=3, n_estimators=5;, score=0.741 total time=   0.0s\n",
      "[CV 11/20; 13/36] START learning_rate=0.3, max_depth=3, n_estimators=5..........\n",
      "[CV 11/20; 13/36] END learning_rate=0.3, max_depth=3, n_estimators=5;, score=0.747 total time=   0.0s\n",
      "[CV 12/20; 13/36] START learning_rate=0.3, max_depth=3, n_estimators=5..........\n",
      "[CV 12/20; 13/36] END learning_rate=0.3, max_depth=3, n_estimators=5;, score=0.746 total time=   0.0s\n",
      "[CV 13/20; 13/36] START learning_rate=0.3, max_depth=3, n_estimators=5..........\n",
      "[CV 13/20; 13/36] END learning_rate=0.3, max_depth=3, n_estimators=5;, score=0.750 total time=   0.0s\n",
      "[CV 14/20; 13/36] START learning_rate=0.3, max_depth=3, n_estimators=5..........\n",
      "[CV 14/20; 13/36] END learning_rate=0.3, max_depth=3, n_estimators=5;, score=0.748 total time=   0.0s\n",
      "[CV 15/20; 13/36] START learning_rate=0.3, max_depth=3, n_estimators=5..........\n",
      "[CV 15/20; 13/36] END learning_rate=0.3, max_depth=3, n_estimators=5;, score=0.749 total time=   0.0s\n",
      "[CV 16/20; 13/36] START learning_rate=0.3, max_depth=3, n_estimators=5..........\n",
      "[CV 16/20; 13/36] END learning_rate=0.3, max_depth=3, n_estimators=5;, score=0.750 total time=   0.0s\n",
      "[CV 17/20; 13/36] START learning_rate=0.3, max_depth=3, n_estimators=5..........\n",
      "[CV 17/20; 13/36] END learning_rate=0.3, max_depth=3, n_estimators=5;, score=0.750 total time=   0.0s\n",
      "[CV 18/20; 13/36] START learning_rate=0.3, max_depth=3, n_estimators=5..........\n",
      "[CV 18/20; 13/36] END learning_rate=0.3, max_depth=3, n_estimators=5;, score=0.747 total time=   0.0s\n",
      "[CV 19/20; 13/36] START learning_rate=0.3, max_depth=3, n_estimators=5..........\n",
      "[CV 19/20; 13/36] END learning_rate=0.3, max_depth=3, n_estimators=5;, score=0.747 total time=   0.0s\n",
      "[CV 20/20; 13/36] START learning_rate=0.3, max_depth=3, n_estimators=5..........\n",
      "[CV 20/20; 13/36] END learning_rate=0.3, max_depth=3, n_estimators=5;, score=0.748 total time=   0.0s\n",
      "[CV 1/20; 14/36] START learning_rate=0.3, max_depth=3, n_estimators=50..........\n",
      "[CV 1/20; 14/36] END learning_rate=0.3, max_depth=3, n_estimators=50;, score=0.749 total time=   0.4s\n",
      "[CV 2/20; 14/36] START learning_rate=0.3, max_depth=3, n_estimators=50..........\n",
      "[CV 2/20; 14/36] END learning_rate=0.3, max_depth=3, n_estimators=50;, score=0.746 total time=   0.3s\n",
      "[CV 3/20; 14/36] START learning_rate=0.3, max_depth=3, n_estimators=50..........\n",
      "[CV 3/20; 14/36] END learning_rate=0.3, max_depth=3, n_estimators=50;, score=0.750 total time=   0.3s\n",
      "[CV 4/20; 14/36] START learning_rate=0.3, max_depth=3, n_estimators=50..........\n",
      "[CV 4/20; 14/36] END learning_rate=0.3, max_depth=3, n_estimators=50;, score=0.748 total time=   0.4s\n",
      "[CV 5/20; 14/36] START learning_rate=0.3, max_depth=3, n_estimators=50..........\n",
      "[CV 5/20; 14/36] END learning_rate=0.3, max_depth=3, n_estimators=50;, score=0.748 total time=   0.3s\n",
      "[CV 6/20; 14/36] START learning_rate=0.3, max_depth=3, n_estimators=50..........\n",
      "[CV 6/20; 14/36] END learning_rate=0.3, max_depth=3, n_estimators=50;, score=0.750 total time=   0.3s\n",
      "[CV 7/20; 14/36] START learning_rate=0.3, max_depth=3, n_estimators=50..........\n",
      "[CV 7/20; 14/36] END learning_rate=0.3, max_depth=3, n_estimators=50;, score=0.747 total time=   0.4s\n",
      "[CV 8/20; 14/36] START learning_rate=0.3, max_depth=3, n_estimators=50..........\n",
      "[CV 8/20; 14/36] END learning_rate=0.3, max_depth=3, n_estimators=50;, score=0.754 total time=   0.3s\n",
      "[CV 9/20; 14/36] START learning_rate=0.3, max_depth=3, n_estimators=50..........\n",
      "[CV 9/20; 14/36] END learning_rate=0.3, max_depth=3, n_estimators=50;, score=0.748 total time=   0.4s\n",
      "[CV 10/20; 14/36] START learning_rate=0.3, max_depth=3, n_estimators=50.........\n",
      "[CV 10/20; 14/36] END learning_rate=0.3, max_depth=3, n_estimators=50;, score=0.741 total time=   0.3s\n",
      "[CV 11/20; 14/36] START learning_rate=0.3, max_depth=3, n_estimators=50.........\n",
      "[CV 11/20; 14/36] END learning_rate=0.3, max_depth=3, n_estimators=50;, score=0.747 total time=   0.4s\n",
      "[CV 12/20; 14/36] START learning_rate=0.3, max_depth=3, n_estimators=50.........\n",
      "[CV 12/20; 14/36] END learning_rate=0.3, max_depth=3, n_estimators=50;, score=0.746 total time=   0.4s\n",
      "[CV 13/20; 14/36] START learning_rate=0.3, max_depth=3, n_estimators=50.........\n",
      "[CV 13/20; 14/36] END learning_rate=0.3, max_depth=3, n_estimators=50;, score=0.750 total time=   0.4s\n",
      "[CV 14/20; 14/36] START learning_rate=0.3, max_depth=3, n_estimators=50.........\n",
      "[CV 14/20; 14/36] END learning_rate=0.3, max_depth=3, n_estimators=50;, score=0.748 total time=   0.4s\n",
      "[CV 15/20; 14/36] START learning_rate=0.3, max_depth=3, n_estimators=50.........\n",
      "[CV 15/20; 14/36] END learning_rate=0.3, max_depth=3, n_estimators=50;, score=0.750 total time=   0.4s\n",
      "[CV 16/20; 14/36] START learning_rate=0.3, max_depth=3, n_estimators=50.........\n",
      "[CV 16/20; 14/36] END learning_rate=0.3, max_depth=3, n_estimators=50;, score=0.749 total time=   0.3s\n",
      "[CV 17/20; 14/36] START learning_rate=0.3, max_depth=3, n_estimators=50.........\n",
      "[CV 17/20; 14/36] END learning_rate=0.3, max_depth=3, n_estimators=50;, score=0.750 total time=   0.4s\n",
      "[CV 18/20; 14/36] START learning_rate=0.3, max_depth=3, n_estimators=50.........\n",
      "[CV 18/20; 14/36] END learning_rate=0.3, max_depth=3, n_estimators=50;, score=0.747 total time=   0.4s\n",
      "[CV 19/20; 14/36] START learning_rate=0.3, max_depth=3, n_estimators=50.........\n",
      "[CV 19/20; 14/36] END learning_rate=0.3, max_depth=3, n_estimators=50;, score=0.747 total time=   0.4s\n",
      "[CV 20/20; 14/36] START learning_rate=0.3, max_depth=3, n_estimators=50.........\n",
      "[CV 20/20; 14/36] END learning_rate=0.3, max_depth=3, n_estimators=50;, score=0.748 total time=   0.4s\n",
      "[CV 1/20; 15/36] START learning_rate=0.3, max_depth=3, n_estimators=120.........\n",
      "[CV 1/20; 15/36] END learning_rate=0.3, max_depth=3, n_estimators=120;, score=0.749 total time=   0.9s\n",
      "[CV 2/20; 15/36] START learning_rate=0.3, max_depth=3, n_estimators=120.........\n",
      "[CV 2/20; 15/36] END learning_rate=0.3, max_depth=3, n_estimators=120;, score=0.746 total time=   0.9s\n",
      "[CV 3/20; 15/36] START learning_rate=0.3, max_depth=3, n_estimators=120.........\n",
      "[CV 3/20; 15/36] END learning_rate=0.3, max_depth=3, n_estimators=120;, score=0.750 total time=   0.9s\n",
      "[CV 4/20; 15/36] START learning_rate=0.3, max_depth=3, n_estimators=120.........\n",
      "[CV 4/20; 15/36] END learning_rate=0.3, max_depth=3, n_estimators=120;, score=0.748 total time=   0.9s\n",
      "[CV 5/20; 15/36] START learning_rate=0.3, max_depth=3, n_estimators=120.........\n",
      "[CV 5/20; 15/36] END learning_rate=0.3, max_depth=3, n_estimators=120;, score=0.748 total time=   0.9s\n",
      "[CV 6/20; 15/36] START learning_rate=0.3, max_depth=3, n_estimators=120.........\n",
      "[CV 6/20; 15/36] END learning_rate=0.3, max_depth=3, n_estimators=120;, score=0.750 total time=   0.9s\n",
      "[CV 7/20; 15/36] START learning_rate=0.3, max_depth=3, n_estimators=120.........\n",
      "[CV 7/20; 15/36] END learning_rate=0.3, max_depth=3, n_estimators=120;, score=0.747 total time=   0.9s\n",
      "[CV 8/20; 15/36] START learning_rate=0.3, max_depth=3, n_estimators=120.........\n",
      "[CV 8/20; 15/36] END learning_rate=0.3, max_depth=3, n_estimators=120;, score=0.754 total time=   0.9s\n",
      "[CV 9/20; 15/36] START learning_rate=0.3, max_depth=3, n_estimators=120.........\n",
      "[CV 9/20; 15/36] END learning_rate=0.3, max_depth=3, n_estimators=120;, score=0.748 total time=   0.9s\n",
      "[CV 10/20; 15/36] START learning_rate=0.3, max_depth=3, n_estimators=120........\n",
      "[CV 10/20; 15/36] END learning_rate=0.3, max_depth=3, n_estimators=120;, score=0.741 total time=   0.9s\n",
      "[CV 11/20; 15/36] START learning_rate=0.3, max_depth=3, n_estimators=120........\n",
      "[CV 11/20; 15/36] END learning_rate=0.3, max_depth=3, n_estimators=120;, score=0.747 total time=   0.9s\n",
      "[CV 12/20; 15/36] START learning_rate=0.3, max_depth=3, n_estimators=120........\n",
      "[CV 12/20; 15/36] END learning_rate=0.3, max_depth=3, n_estimators=120;, score=0.746 total time=   0.9s\n",
      "[CV 13/20; 15/36] START learning_rate=0.3, max_depth=3, n_estimators=120........\n",
      "[CV 13/20; 15/36] END learning_rate=0.3, max_depth=3, n_estimators=120;, score=0.750 total time=   0.9s\n",
      "[CV 14/20; 15/36] START learning_rate=0.3, max_depth=3, n_estimators=120........\n",
      "[CV 14/20; 15/36] END learning_rate=0.3, max_depth=3, n_estimators=120;, score=0.748 total time=   0.9s\n",
      "[CV 15/20; 15/36] START learning_rate=0.3, max_depth=3, n_estimators=120........\n",
      "[CV 15/20; 15/36] END learning_rate=0.3, max_depth=3, n_estimators=120;, score=0.750 total time=   0.9s\n",
      "[CV 16/20; 15/36] START learning_rate=0.3, max_depth=3, n_estimators=120........\n",
      "[CV 16/20; 15/36] END learning_rate=0.3, max_depth=3, n_estimators=120;, score=0.749 total time=   0.9s\n",
      "[CV 17/20; 15/36] START learning_rate=0.3, max_depth=3, n_estimators=120........\n",
      "[CV 17/20; 15/36] END learning_rate=0.3, max_depth=3, n_estimators=120;, score=0.750 total time=   0.9s\n",
      "[CV 18/20; 15/36] START learning_rate=0.3, max_depth=3, n_estimators=120........\n",
      "[CV 18/20; 15/36] END learning_rate=0.3, max_depth=3, n_estimators=120;, score=0.747 total time=   0.9s\n",
      "[CV 19/20; 15/36] START learning_rate=0.3, max_depth=3, n_estimators=120........\n",
      "[CV 19/20; 15/36] END learning_rate=0.3, max_depth=3, n_estimators=120;, score=0.747 total time=   0.9s\n",
      "[CV 20/20; 15/36] START learning_rate=0.3, max_depth=3, n_estimators=120........\n",
      "[CV 20/20; 15/36] END learning_rate=0.3, max_depth=3, n_estimators=120;, score=0.748 total time=   0.9s\n",
      "[CV 1/20; 16/36] START learning_rate=0.3, max_depth=5, n_estimators=5...........\n",
      "[CV 1/20; 16/36] END learning_rate=0.3, max_depth=5, n_estimators=5;, score=0.749 total time=   0.0s\n",
      "[CV 2/20; 16/36] START learning_rate=0.3, max_depth=5, n_estimators=5...........\n",
      "[CV 2/20; 16/36] END learning_rate=0.3, max_depth=5, n_estimators=5;, score=0.746 total time=   0.0s\n",
      "[CV 3/20; 16/36] START learning_rate=0.3, max_depth=5, n_estimators=5...........\n",
      "[CV 3/20; 16/36] END learning_rate=0.3, max_depth=5, n_estimators=5;, score=0.750 total time=   0.0s\n",
      "[CV 4/20; 16/36] START learning_rate=0.3, max_depth=5, n_estimators=5...........\n",
      "[CV 4/20; 16/36] END learning_rate=0.3, max_depth=5, n_estimators=5;, score=0.748 total time=   0.1s\n",
      "[CV 5/20; 16/36] START learning_rate=0.3, max_depth=5, n_estimators=5...........\n",
      "[CV 5/20; 16/36] END learning_rate=0.3, max_depth=5, n_estimators=5;, score=0.748 total time=   0.0s\n",
      "[CV 6/20; 16/36] START learning_rate=0.3, max_depth=5, n_estimators=5...........\n",
      "[CV 6/20; 16/36] END learning_rate=0.3, max_depth=5, n_estimators=5;, score=0.750 total time=   0.0s\n",
      "[CV 7/20; 16/36] START learning_rate=0.3, max_depth=5, n_estimators=5...........\n",
      "[CV 7/20; 16/36] END learning_rate=0.3, max_depth=5, n_estimators=5;, score=0.747 total time=   0.0s\n",
      "[CV 8/20; 16/36] START learning_rate=0.3, max_depth=5, n_estimators=5...........\n",
      "[CV 8/20; 16/36] END learning_rate=0.3, max_depth=5, n_estimators=5;, score=0.754 total time=   0.0s\n",
      "[CV 9/20; 16/36] START learning_rate=0.3, max_depth=5, n_estimators=5...........\n",
      "[CV 9/20; 16/36] END learning_rate=0.3, max_depth=5, n_estimators=5;, score=0.748 total time=   0.1s\n",
      "[CV 10/20; 16/36] START learning_rate=0.3, max_depth=5, n_estimators=5..........\n",
      "[CV 10/20; 16/36] END learning_rate=0.3, max_depth=5, n_estimators=5;, score=0.741 total time=   0.0s\n",
      "[CV 11/20; 16/36] START learning_rate=0.3, max_depth=5, n_estimators=5..........\n",
      "[CV 11/20; 16/36] END learning_rate=0.3, max_depth=5, n_estimators=5;, score=0.747 total time=   0.0s\n",
      "[CV 12/20; 16/36] START learning_rate=0.3, max_depth=5, n_estimators=5..........\n",
      "[CV 12/20; 16/36] END learning_rate=0.3, max_depth=5, n_estimators=5;, score=0.746 total time=   0.0s\n",
      "[CV 13/20; 16/36] START learning_rate=0.3, max_depth=5, n_estimators=5..........\n",
      "[CV 13/20; 16/36] END learning_rate=0.3, max_depth=5, n_estimators=5;, score=0.750 total time=   0.1s\n",
      "[CV 14/20; 16/36] START learning_rate=0.3, max_depth=5, n_estimators=5..........\n",
      "[CV 14/20; 16/36] END learning_rate=0.3, max_depth=5, n_estimators=5;, score=0.748 total time=   0.0s\n",
      "[CV 15/20; 16/36] START learning_rate=0.3, max_depth=5, n_estimators=5..........\n",
      "[CV 15/20; 16/36] END learning_rate=0.3, max_depth=5, n_estimators=5;, score=0.749 total time=   0.0s\n",
      "[CV 16/20; 16/36] START learning_rate=0.3, max_depth=5, n_estimators=5..........\n",
      "[CV 16/20; 16/36] END learning_rate=0.3, max_depth=5, n_estimators=5;, score=0.749 total time=   0.0s\n",
      "[CV 17/20; 16/36] START learning_rate=0.3, max_depth=5, n_estimators=5..........\n",
      "[CV 17/20; 16/36] END learning_rate=0.3, max_depth=5, n_estimators=5;, score=0.750 total time=   0.0s\n",
      "[CV 18/20; 16/36] START learning_rate=0.3, max_depth=5, n_estimators=5..........\n",
      "[CV 18/20; 16/36] END learning_rate=0.3, max_depth=5, n_estimators=5;, score=0.747 total time=   0.0s\n",
      "[CV 19/20; 16/36] START learning_rate=0.3, max_depth=5, n_estimators=5..........\n",
      "[CV 19/20; 16/36] END learning_rate=0.3, max_depth=5, n_estimators=5;, score=0.747 total time=   0.0s\n",
      "[CV 20/20; 16/36] START learning_rate=0.3, max_depth=5, n_estimators=5..........\n",
      "[CV 20/20; 16/36] END learning_rate=0.3, max_depth=5, n_estimators=5;, score=0.748 total time=   0.0s\n",
      "[CV 1/20; 17/36] START learning_rate=0.3, max_depth=5, n_estimators=50..........\n",
      "[CV 1/20; 17/36] END learning_rate=0.3, max_depth=5, n_estimators=50;, score=0.749 total time=   0.6s\n",
      "[CV 2/20; 17/36] START learning_rate=0.3, max_depth=5, n_estimators=50..........\n",
      "[CV 2/20; 17/36] END learning_rate=0.3, max_depth=5, n_estimators=50;, score=0.746 total time=   0.6s\n",
      "[CV 3/20; 17/36] START learning_rate=0.3, max_depth=5, n_estimators=50..........\n",
      "[CV 3/20; 17/36] END learning_rate=0.3, max_depth=5, n_estimators=50;, score=0.750 total time=   0.6s\n",
      "[CV 4/20; 17/36] START learning_rate=0.3, max_depth=5, n_estimators=50..........\n",
      "[CV 4/20; 17/36] END learning_rate=0.3, max_depth=5, n_estimators=50;, score=0.748 total time=   0.6s\n",
      "[CV 5/20; 17/36] START learning_rate=0.3, max_depth=5, n_estimators=50..........\n",
      "[CV 5/20; 17/36] END learning_rate=0.3, max_depth=5, n_estimators=50;, score=0.748 total time=   0.6s\n",
      "[CV 6/20; 17/36] START learning_rate=0.3, max_depth=5, n_estimators=50..........\n",
      "[CV 6/20; 17/36] END learning_rate=0.3, max_depth=5, n_estimators=50;, score=0.750 total time=   0.6s\n",
      "[CV 7/20; 17/36] START learning_rate=0.3, max_depth=5, n_estimators=50..........\n",
      "[CV 7/20; 17/36] END learning_rate=0.3, max_depth=5, n_estimators=50;, score=0.747 total time=   0.6s\n",
      "[CV 8/20; 17/36] START learning_rate=0.3, max_depth=5, n_estimators=50..........\n",
      "[CV 8/20; 17/36] END learning_rate=0.3, max_depth=5, n_estimators=50;, score=0.754 total time=   0.6s\n",
      "[CV 9/20; 17/36] START learning_rate=0.3, max_depth=5, n_estimators=50..........\n",
      "[CV 9/20; 17/36] END learning_rate=0.3, max_depth=5, n_estimators=50;, score=0.748 total time=   0.6s\n",
      "[CV 10/20; 17/36] START learning_rate=0.3, max_depth=5, n_estimators=50.........\n",
      "[CV 10/20; 17/36] END learning_rate=0.3, max_depth=5, n_estimators=50;, score=0.737 total time=   0.6s\n",
      "[CV 11/20; 17/36] START learning_rate=0.3, max_depth=5, n_estimators=50.........\n",
      "[CV 11/20; 17/36] END learning_rate=0.3, max_depth=5, n_estimators=50;, score=0.747 total time=   0.6s\n",
      "[CV 12/20; 17/36] START learning_rate=0.3, max_depth=5, n_estimators=50.........\n",
      "[CV 12/20; 17/36] END learning_rate=0.3, max_depth=5, n_estimators=50;, score=0.746 total time=   0.6s\n",
      "[CV 13/20; 17/36] START learning_rate=0.3, max_depth=5, n_estimators=50.........\n",
      "[CV 13/20; 17/36] END learning_rate=0.3, max_depth=5, n_estimators=50;, score=0.750 total time=   0.6s\n",
      "[CV 14/20; 17/36] START learning_rate=0.3, max_depth=5, n_estimators=50.........\n",
      "[CV 14/20; 17/36] END learning_rate=0.3, max_depth=5, n_estimators=50;, score=0.748 total time=   0.6s\n",
      "[CV 15/20; 17/36] START learning_rate=0.3, max_depth=5, n_estimators=50.........\n",
      "[CV 15/20; 17/36] END learning_rate=0.3, max_depth=5, n_estimators=50;, score=0.750 total time=   0.6s\n",
      "[CV 16/20; 17/36] START learning_rate=0.3, max_depth=5, n_estimators=50.........\n",
      "[CV 16/20; 17/36] END learning_rate=0.3, max_depth=5, n_estimators=50;, score=0.749 total time=   0.6s\n",
      "[CV 17/20; 17/36] START learning_rate=0.3, max_depth=5, n_estimators=50.........\n",
      "[CV 17/20; 17/36] END learning_rate=0.3, max_depth=5, n_estimators=50;, score=0.750 total time=   0.6s\n",
      "[CV 18/20; 17/36] START learning_rate=0.3, max_depth=5, n_estimators=50.........\n",
      "[CV 18/20; 17/36] END learning_rate=0.3, max_depth=5, n_estimators=50;, score=0.747 total time=   0.6s\n",
      "[CV 19/20; 17/36] START learning_rate=0.3, max_depth=5, n_estimators=50.........\n",
      "[CV 19/20; 17/36] END learning_rate=0.3, max_depth=5, n_estimators=50;, score=0.747 total time=   0.6s\n",
      "[CV 20/20; 17/36] START learning_rate=0.3, max_depth=5, n_estimators=50.........\n",
      "[CV 20/20; 17/36] END learning_rate=0.3, max_depth=5, n_estimators=50;, score=0.748 total time=   0.6s\n",
      "[CV 1/20; 18/36] START learning_rate=0.3, max_depth=5, n_estimators=120.........\n",
      "[CV 1/20; 18/36] END learning_rate=0.3, max_depth=5, n_estimators=120;, score=0.749 total time=   1.4s\n",
      "[CV 2/20; 18/36] START learning_rate=0.3, max_depth=5, n_estimators=120.........\n",
      "[CV 2/20; 18/36] END learning_rate=0.3, max_depth=5, n_estimators=120;, score=0.746 total time=   1.5s\n",
      "[CV 3/20; 18/36] START learning_rate=0.3, max_depth=5, n_estimators=120.........\n",
      "[CV 3/20; 18/36] END learning_rate=0.3, max_depth=5, n_estimators=120;, score=0.750 total time=   1.4s\n",
      "[CV 4/20; 18/36] START learning_rate=0.3, max_depth=5, n_estimators=120.........\n",
      "[CV 4/20; 18/36] END learning_rate=0.3, max_depth=5, n_estimators=120;, score=0.748 total time=   1.6s\n",
      "[CV 5/20; 18/36] START learning_rate=0.3, max_depth=5, n_estimators=120.........\n",
      "[CV 5/20; 18/36] END learning_rate=0.3, max_depth=5, n_estimators=120;, score=0.748 total time=   1.5s\n",
      "[CV 6/20; 18/36] START learning_rate=0.3, max_depth=5, n_estimators=120.........\n",
      "[CV 6/20; 18/36] END learning_rate=0.3, max_depth=5, n_estimators=120;, score=0.750 total time=   1.4s\n",
      "[CV 7/20; 18/36] START learning_rate=0.3, max_depth=5, n_estimators=120.........\n",
      "[CV 7/20; 18/36] END learning_rate=0.3, max_depth=5, n_estimators=120;, score=0.747 total time=   1.4s\n",
      "[CV 8/20; 18/36] START learning_rate=0.3, max_depth=5, n_estimators=120.........\n",
      "[CV 8/20; 18/36] END learning_rate=0.3, max_depth=5, n_estimators=120;, score=0.754 total time=   1.4s\n",
      "[CV 9/20; 18/36] START learning_rate=0.3, max_depth=5, n_estimators=120.........\n",
      "[CV 9/20; 18/36] END learning_rate=0.3, max_depth=5, n_estimators=120;, score=0.748 total time=   1.5s\n",
      "[CV 10/20; 18/36] START learning_rate=0.3, max_depth=5, n_estimators=120........\n",
      "[CV 10/20; 18/36] END learning_rate=0.3, max_depth=5, n_estimators=120;, score=0.741 total time=   1.4s\n",
      "[CV 11/20; 18/36] START learning_rate=0.3, max_depth=5, n_estimators=120........\n",
      "[CV 11/20; 18/36] END learning_rate=0.3, max_depth=5, n_estimators=120;, score=0.747 total time=   1.4s\n",
      "[CV 12/20; 18/36] START learning_rate=0.3, max_depth=5, n_estimators=120........\n",
      "[CV 12/20; 18/36] END learning_rate=0.3, max_depth=5, n_estimators=120;, score=0.746 total time=   1.4s\n",
      "[CV 13/20; 18/36] START learning_rate=0.3, max_depth=5, n_estimators=120........\n",
      "[CV 13/20; 18/36] END learning_rate=0.3, max_depth=5, n_estimators=120;, score=0.750 total time=   1.5s\n",
      "[CV 14/20; 18/36] START learning_rate=0.3, max_depth=5, n_estimators=120........\n",
      "[CV 14/20; 18/36] END learning_rate=0.3, max_depth=5, n_estimators=120;, score=0.748 total time=   1.4s\n",
      "[CV 15/20; 18/36] START learning_rate=0.3, max_depth=5, n_estimators=120........\n",
      "[CV 15/20; 18/36] END learning_rate=0.3, max_depth=5, n_estimators=120;, score=0.750 total time=   1.4s\n",
      "[CV 16/20; 18/36] START learning_rate=0.3, max_depth=5, n_estimators=120........\n",
      "[CV 16/20; 18/36] END learning_rate=0.3, max_depth=5, n_estimators=120;, score=0.749 total time=   1.4s\n",
      "[CV 17/20; 18/36] START learning_rate=0.3, max_depth=5, n_estimators=120........\n",
      "[CV 17/20; 18/36] END learning_rate=0.3, max_depth=5, n_estimators=120;, score=0.750 total time=   1.4s\n",
      "[CV 18/20; 18/36] START learning_rate=0.3, max_depth=5, n_estimators=120........\n",
      "[CV 18/20; 18/36] END learning_rate=0.3, max_depth=5, n_estimators=120;, score=0.747 total time=   1.4s\n",
      "[CV 19/20; 18/36] START learning_rate=0.3, max_depth=5, n_estimators=120........\n",
      "[CV 19/20; 18/36] END learning_rate=0.3, max_depth=5, n_estimators=120;, score=0.747 total time=   1.4s\n",
      "[CV 20/20; 18/36] START learning_rate=0.3, max_depth=5, n_estimators=120........\n",
      "[CV 20/20; 18/36] END learning_rate=0.3, max_depth=5, n_estimators=120;, score=0.748 total time=   1.4s\n",
      "[CV 1/20; 19/36] START learning_rate=0.3, max_depth=6, n_estimators=5...........\n",
      "[CV 1/20; 19/36] END learning_rate=0.3, max_depth=6, n_estimators=5;, score=0.749 total time=   0.1s\n",
      "[CV 2/20; 19/36] START learning_rate=0.3, max_depth=6, n_estimators=5...........\n",
      "[CV 2/20; 19/36] END learning_rate=0.3, max_depth=6, n_estimators=5;, score=0.746 total time=   0.1s\n",
      "[CV 3/20; 19/36] START learning_rate=0.3, max_depth=6, n_estimators=5...........\n",
      "[CV 3/20; 19/36] END learning_rate=0.3, max_depth=6, n_estimators=5;, score=0.750 total time=   0.1s\n",
      "[CV 4/20; 19/36] START learning_rate=0.3, max_depth=6, n_estimators=5...........\n",
      "[CV 4/20; 19/36] END learning_rate=0.3, max_depth=6, n_estimators=5;, score=0.748 total time=   0.1s\n",
      "[CV 5/20; 19/36] START learning_rate=0.3, max_depth=6, n_estimators=5...........\n",
      "[CV 5/20; 19/36] END learning_rate=0.3, max_depth=6, n_estimators=5;, score=0.748 total time=   0.1s\n",
      "[CV 6/20; 19/36] START learning_rate=0.3, max_depth=6, n_estimators=5...........\n",
      "[CV 6/20; 19/36] END learning_rate=0.3, max_depth=6, n_estimators=5;, score=0.750 total time=   0.1s\n",
      "[CV 7/20; 19/36] START learning_rate=0.3, max_depth=6, n_estimators=5...........\n",
      "[CV 7/20; 19/36] END learning_rate=0.3, max_depth=6, n_estimators=5;, score=0.747 total time=   0.1s\n",
      "[CV 8/20; 19/36] START learning_rate=0.3, max_depth=6, n_estimators=5...........\n",
      "[CV 8/20; 19/36] END learning_rate=0.3, max_depth=6, n_estimators=5;, score=0.754 total time=   0.1s\n",
      "[CV 9/20; 19/36] START learning_rate=0.3, max_depth=6, n_estimators=5...........\n",
      "[CV 9/20; 19/36] END learning_rate=0.3, max_depth=6, n_estimators=5;, score=0.748 total time=   0.1s\n",
      "[CV 10/20; 19/36] START learning_rate=0.3, max_depth=6, n_estimators=5..........\n",
      "[CV 10/20; 19/36] END learning_rate=0.3, max_depth=6, n_estimators=5;, score=0.737 total time=   0.0s\n",
      "[CV 11/20; 19/36] START learning_rate=0.3, max_depth=6, n_estimators=5..........\n",
      "[CV 11/20; 19/36] END learning_rate=0.3, max_depth=6, n_estimators=5;, score=0.747 total time=   0.0s\n",
      "[CV 12/20; 19/36] START learning_rate=0.3, max_depth=6, n_estimators=5..........\n",
      "[CV 12/20; 19/36] END learning_rate=0.3, max_depth=6, n_estimators=5;, score=0.746 total time=   0.1s\n",
      "[CV 13/20; 19/36] START learning_rate=0.3, max_depth=6, n_estimators=5..........\n",
      "[CV 13/20; 19/36] END learning_rate=0.3, max_depth=6, n_estimators=5;, score=0.750 total time=   0.1s\n",
      "[CV 14/20; 19/36] START learning_rate=0.3, max_depth=6, n_estimators=5..........\n",
      "[CV 14/20; 19/36] END learning_rate=0.3, max_depth=6, n_estimators=5;, score=0.748 total time=   0.1s\n",
      "[CV 15/20; 19/36] START learning_rate=0.3, max_depth=6, n_estimators=5..........\n",
      "[CV 15/20; 19/36] END learning_rate=0.3, max_depth=6, n_estimators=5;, score=0.749 total time=   0.1s\n",
      "[CV 16/20; 19/36] START learning_rate=0.3, max_depth=6, n_estimators=5..........\n",
      "[CV 16/20; 19/36] END learning_rate=0.3, max_depth=6, n_estimators=5;, score=0.749 total time=   0.1s\n",
      "[CV 17/20; 19/36] START learning_rate=0.3, max_depth=6, n_estimators=5..........\n",
      "[CV 17/20; 19/36] END learning_rate=0.3, max_depth=6, n_estimators=5;, score=0.750 total time=   0.1s\n",
      "[CV 18/20; 19/36] START learning_rate=0.3, max_depth=6, n_estimators=5..........\n",
      "[CV 18/20; 19/36] END learning_rate=0.3, max_depth=6, n_estimators=5;, score=0.747 total time=   0.1s\n",
      "[CV 19/20; 19/36] START learning_rate=0.3, max_depth=6, n_estimators=5..........\n",
      "[CV 19/20; 19/36] END learning_rate=0.3, max_depth=6, n_estimators=5;, score=0.743 total time=   0.0s\n",
      "[CV 20/20; 19/36] START learning_rate=0.3, max_depth=6, n_estimators=5..........\n",
      "[CV 20/20; 19/36] END learning_rate=0.3, max_depth=6, n_estimators=5;, score=0.748 total time=   0.1s\n",
      "[CV 1/20; 20/36] START learning_rate=0.3, max_depth=6, n_estimators=50..........\n",
      "[CV 1/20; 20/36] END learning_rate=0.3, max_depth=6, n_estimators=50;, score=0.749 total time=   0.7s\n",
      "[CV 2/20; 20/36] START learning_rate=0.3, max_depth=6, n_estimators=50..........\n",
      "[CV 2/20; 20/36] END learning_rate=0.3, max_depth=6, n_estimators=50;, score=0.746 total time=   0.7s\n",
      "[CV 3/20; 20/36] START learning_rate=0.3, max_depth=6, n_estimators=50..........\n",
      "[CV 3/20; 20/36] END learning_rate=0.3, max_depth=6, n_estimators=50;, score=0.750 total time=   0.7s\n",
      "[CV 4/20; 20/36] START learning_rate=0.3, max_depth=6, n_estimators=50..........\n",
      "[CV 4/20; 20/36] END learning_rate=0.3, max_depth=6, n_estimators=50;, score=0.748 total time=   0.7s\n",
      "[CV 5/20; 20/36] START learning_rate=0.3, max_depth=6, n_estimators=50..........\n",
      "[CV 5/20; 20/36] END learning_rate=0.3, max_depth=6, n_estimators=50;, score=0.748 total time=   0.7s\n",
      "[CV 6/20; 20/36] START learning_rate=0.3, max_depth=6, n_estimators=50..........\n",
      "[CV 6/20; 20/36] END learning_rate=0.3, max_depth=6, n_estimators=50;, score=0.750 total time=   0.7s\n",
      "[CV 7/20; 20/36] START learning_rate=0.3, max_depth=6, n_estimators=50..........\n",
      "[CV 7/20; 20/36] END learning_rate=0.3, max_depth=6, n_estimators=50;, score=0.747 total time=   0.7s\n",
      "[CV 8/20; 20/36] START learning_rate=0.3, max_depth=6, n_estimators=50..........\n",
      "[CV 8/20; 20/36] END learning_rate=0.3, max_depth=6, n_estimators=50;, score=0.754 total time=   0.7s\n",
      "[CV 9/20; 20/36] START learning_rate=0.3, max_depth=6, n_estimators=50..........\n",
      "[CV 9/20; 20/36] END learning_rate=0.3, max_depth=6, n_estimators=50;, score=0.748 total time=   0.7s\n",
      "[CV 10/20; 20/36] START learning_rate=0.3, max_depth=6, n_estimators=50.........\n",
      "[CV 10/20; 20/36] END learning_rate=0.3, max_depth=6, n_estimators=50;, score=0.737 total time=   0.7s\n",
      "[CV 11/20; 20/36] START learning_rate=0.3, max_depth=6, n_estimators=50.........\n",
      "[CV 11/20; 20/36] END learning_rate=0.3, max_depth=6, n_estimators=50;, score=0.747 total time=   0.7s\n",
      "[CV 12/20; 20/36] START learning_rate=0.3, max_depth=6, n_estimators=50.........\n",
      "[CV 12/20; 20/36] END learning_rate=0.3, max_depth=6, n_estimators=50;, score=0.746 total time=   0.7s\n",
      "[CV 13/20; 20/36] START learning_rate=0.3, max_depth=6, n_estimators=50.........\n",
      "[CV 13/20; 20/36] END learning_rate=0.3, max_depth=6, n_estimators=50;, score=0.750 total time=   0.7s\n",
      "[CV 14/20; 20/36] START learning_rate=0.3, max_depth=6, n_estimators=50.........\n",
      "[CV 14/20; 20/36] END learning_rate=0.3, max_depth=6, n_estimators=50;, score=0.748 total time=   0.7s\n",
      "[CV 15/20; 20/36] START learning_rate=0.3, max_depth=6, n_estimators=50.........\n",
      "[CV 15/20; 20/36] END learning_rate=0.3, max_depth=6, n_estimators=50;, score=0.750 total time=   0.7s\n",
      "[CV 16/20; 20/36] START learning_rate=0.3, max_depth=6, n_estimators=50.........\n",
      "[CV 16/20; 20/36] END learning_rate=0.3, max_depth=6, n_estimators=50;, score=0.749 total time=   0.7s\n",
      "[CV 17/20; 20/36] START learning_rate=0.3, max_depth=6, n_estimators=50.........\n",
      "[CV 17/20; 20/36] END learning_rate=0.3, max_depth=6, n_estimators=50;, score=0.750 total time=   0.7s\n",
      "[CV 18/20; 20/36] START learning_rate=0.3, max_depth=6, n_estimators=50.........\n",
      "[CV 18/20; 20/36] END learning_rate=0.3, max_depth=6, n_estimators=50;, score=0.747 total time=   0.7s\n",
      "[CV 19/20; 20/36] START learning_rate=0.3, max_depth=6, n_estimators=50.........\n",
      "[CV 19/20; 20/36] END learning_rate=0.3, max_depth=6, n_estimators=50;, score=0.747 total time=   0.7s\n",
      "[CV 20/20; 20/36] START learning_rate=0.3, max_depth=6, n_estimators=50.........\n",
      "[CV 20/20; 20/36] END learning_rate=0.3, max_depth=6, n_estimators=50;, score=0.748 total time=   0.7s\n",
      "[CV 1/20; 21/36] START learning_rate=0.3, max_depth=6, n_estimators=120.........\n",
      "[CV 1/20; 21/36] END learning_rate=0.3, max_depth=6, n_estimators=120;, score=0.749 total time=   1.7s\n",
      "[CV 2/20; 21/36] START learning_rate=0.3, max_depth=6, n_estimators=120.........\n",
      "[CV 2/20; 21/36] END learning_rate=0.3, max_depth=6, n_estimators=120;, score=0.746 total time=   1.7s\n",
      "[CV 3/20; 21/36] START learning_rate=0.3, max_depth=6, n_estimators=120.........\n",
      "[CV 3/20; 21/36] END learning_rate=0.3, max_depth=6, n_estimators=120;, score=0.750 total time=   1.7s\n",
      "[CV 4/20; 21/36] START learning_rate=0.3, max_depth=6, n_estimators=120.........\n",
      "[CV 4/20; 21/36] END learning_rate=0.3, max_depth=6, n_estimators=120;, score=0.748 total time=   1.7s\n",
      "[CV 5/20; 21/36] START learning_rate=0.3, max_depth=6, n_estimators=120.........\n",
      "[CV 5/20; 21/36] END learning_rate=0.3, max_depth=6, n_estimators=120;, score=0.748 total time=   1.7s\n",
      "[CV 6/20; 21/36] START learning_rate=0.3, max_depth=6, n_estimators=120.........\n",
      "[CV 6/20; 21/36] END learning_rate=0.3, max_depth=6, n_estimators=120;, score=0.750 total time=   1.7s\n",
      "[CV 7/20; 21/36] START learning_rate=0.3, max_depth=6, n_estimators=120.........\n",
      "[CV 7/20; 21/36] END learning_rate=0.3, max_depth=6, n_estimators=120;, score=0.747 total time=   1.7s\n",
      "[CV 8/20; 21/36] START learning_rate=0.3, max_depth=6, n_estimators=120.........\n",
      "[CV 8/20; 21/36] END learning_rate=0.3, max_depth=6, n_estimators=120;, score=0.754 total time=   1.7s\n",
      "[CV 9/20; 21/36] START learning_rate=0.3, max_depth=6, n_estimators=120.........\n",
      "[CV 9/20; 21/36] END learning_rate=0.3, max_depth=6, n_estimators=120;, score=0.748 total time=   1.7s\n",
      "[CV 10/20; 21/36] START learning_rate=0.3, max_depth=6, n_estimators=120........\n",
      "[CV 10/20; 21/36] END learning_rate=0.3, max_depth=6, n_estimators=120;, score=0.737 total time=   1.6s\n",
      "[CV 11/20; 21/36] START learning_rate=0.3, max_depth=6, n_estimators=120........\n",
      "[CV 11/20; 21/36] END learning_rate=0.3, max_depth=6, n_estimators=120;, score=0.747 total time=   1.7s\n",
      "[CV 12/20; 21/36] START learning_rate=0.3, max_depth=6, n_estimators=120........\n",
      "[CV 12/20; 21/36] END learning_rate=0.3, max_depth=6, n_estimators=120;, score=0.746 total time=   1.7s\n",
      "[CV 13/20; 21/36] START learning_rate=0.3, max_depth=6, n_estimators=120........\n",
      "[CV 13/20; 21/36] END learning_rate=0.3, max_depth=6, n_estimators=120;, score=0.750 total time=   1.7s\n",
      "[CV 14/20; 21/36] START learning_rate=0.3, max_depth=6, n_estimators=120........\n",
      "[CV 14/20; 21/36] END learning_rate=0.3, max_depth=6, n_estimators=120;, score=0.748 total time=   1.7s\n",
      "[CV 15/20; 21/36] START learning_rate=0.3, max_depth=6, n_estimators=120........\n",
      "[CV 15/20; 21/36] END learning_rate=0.3, max_depth=6, n_estimators=120;, score=0.750 total time=   1.7s\n",
      "[CV 16/20; 21/36] START learning_rate=0.3, max_depth=6, n_estimators=120........\n",
      "[CV 16/20; 21/36] END learning_rate=0.3, max_depth=6, n_estimators=120;, score=0.749 total time=   1.7s\n",
      "[CV 17/20; 21/36] START learning_rate=0.3, max_depth=6, n_estimators=120........\n",
      "[CV 17/20; 21/36] END learning_rate=0.3, max_depth=6, n_estimators=120;, score=0.750 total time=   1.8s\n",
      "[CV 18/20; 21/36] START learning_rate=0.3, max_depth=6, n_estimators=120........\n",
      "[CV 18/20; 21/36] END learning_rate=0.3, max_depth=6, n_estimators=120;, score=0.747 total time=   1.7s\n",
      "[CV 19/20; 21/36] START learning_rate=0.3, max_depth=6, n_estimators=120........\n",
      "[CV 19/20; 21/36] END learning_rate=0.3, max_depth=6, n_estimators=120;, score=0.747 total time=   1.7s\n",
      "[CV 20/20; 21/36] START learning_rate=0.3, max_depth=6, n_estimators=120........\n",
      "[CV 20/20; 21/36] END learning_rate=0.3, max_depth=6, n_estimators=120;, score=0.748 total time=   1.7s\n",
      "[CV 1/20; 22/36] START learning_rate=0.3, max_depth=7, n_estimators=5...........\n",
      "[CV 1/20; 22/36] END learning_rate=0.3, max_depth=7, n_estimators=5;, score=0.749 total time=   0.1s\n",
      "[CV 2/20; 22/36] START learning_rate=0.3, max_depth=7, n_estimators=5...........\n",
      "[CV 2/20; 22/36] END learning_rate=0.3, max_depth=7, n_estimators=5;, score=0.746 total time=   0.1s\n",
      "[CV 3/20; 22/36] START learning_rate=0.3, max_depth=7, n_estimators=5...........\n",
      "[CV 3/20; 22/36] END learning_rate=0.3, max_depth=7, n_estimators=5;, score=0.750 total time=   0.1s\n",
      "[CV 4/20; 22/36] START learning_rate=0.3, max_depth=7, n_estimators=5...........\n",
      "[CV 4/20; 22/36] END learning_rate=0.3, max_depth=7, n_estimators=5;, score=0.748 total time=   0.1s\n",
      "[CV 5/20; 22/36] START learning_rate=0.3, max_depth=7, n_estimators=5...........\n",
      "[CV 5/20; 22/36] END learning_rate=0.3, max_depth=7, n_estimators=5;, score=0.748 total time=   0.1s\n",
      "[CV 6/20; 22/36] START learning_rate=0.3, max_depth=7, n_estimators=5...........\n",
      "[CV 6/20; 22/36] END learning_rate=0.3, max_depth=7, n_estimators=5;, score=0.750 total time=   0.1s\n",
      "[CV 7/20; 22/36] START learning_rate=0.3, max_depth=7, n_estimators=5...........\n",
      "[CV 7/20; 22/36] END learning_rate=0.3, max_depth=7, n_estimators=5;, score=0.747 total time=   0.1s\n",
      "[CV 8/20; 22/36] START learning_rate=0.3, max_depth=7, n_estimators=5...........\n",
      "[CV 8/20; 22/36] END learning_rate=0.3, max_depth=7, n_estimators=5;, score=0.754 total time=   0.1s\n",
      "[CV 9/20; 22/36] START learning_rate=0.3, max_depth=7, n_estimators=5...........\n",
      "[CV 9/20; 22/36] END learning_rate=0.3, max_depth=7, n_estimators=5;, score=0.748 total time=   0.1s\n",
      "[CV 10/20; 22/36] START learning_rate=0.3, max_depth=7, n_estimators=5..........\n",
      "[CV 10/20; 22/36] END learning_rate=0.3, max_depth=7, n_estimators=5;, score=0.737 total time=   0.1s\n",
      "[CV 11/20; 22/36] START learning_rate=0.3, max_depth=7, n_estimators=5..........\n",
      "[CV 11/20; 22/36] END learning_rate=0.3, max_depth=7, n_estimators=5;, score=0.747 total time=   0.1s\n",
      "[CV 12/20; 22/36] START learning_rate=0.3, max_depth=7, n_estimators=5..........\n",
      "[CV 12/20; 22/36] END learning_rate=0.3, max_depth=7, n_estimators=5;, score=0.746 total time=   0.1s\n",
      "[CV 13/20; 22/36] START learning_rate=0.3, max_depth=7, n_estimators=5..........\n",
      "[CV 13/20; 22/36] END learning_rate=0.3, max_depth=7, n_estimators=5;, score=0.750 total time=   0.1s\n",
      "[CV 14/20; 22/36] START learning_rate=0.3, max_depth=7, n_estimators=5..........\n",
      "[CV 14/20; 22/36] END learning_rate=0.3, max_depth=7, n_estimators=5;, score=0.748 total time=   0.1s\n",
      "[CV 15/20; 22/36] START learning_rate=0.3, max_depth=7, n_estimators=5..........\n",
      "[CV 15/20; 22/36] END learning_rate=0.3, max_depth=7, n_estimators=5;, score=0.749 total time=   0.1s\n",
      "[CV 16/20; 22/36] START learning_rate=0.3, max_depth=7, n_estimators=5..........\n",
      "[CV 16/20; 22/36] END learning_rate=0.3, max_depth=7, n_estimators=5;, score=0.749 total time=   0.1s\n",
      "[CV 17/20; 22/36] START learning_rate=0.3, max_depth=7, n_estimators=5..........\n",
      "[CV 17/20; 22/36] END learning_rate=0.3, max_depth=7, n_estimators=5;, score=0.750 total time=   0.1s\n",
      "[CV 18/20; 22/36] START learning_rate=0.3, max_depth=7, n_estimators=5..........\n",
      "[CV 18/20; 22/36] END learning_rate=0.3, max_depth=7, n_estimators=5;, score=0.747 total time=   0.1s\n",
      "[CV 19/20; 22/36] START learning_rate=0.3, max_depth=7, n_estimators=5..........\n",
      "[CV 19/20; 22/36] END learning_rate=0.3, max_depth=7, n_estimators=5;, score=0.743 total time=   0.1s\n",
      "[CV 20/20; 22/36] START learning_rate=0.3, max_depth=7, n_estimators=5..........\n",
      "[CV 20/20; 22/36] END learning_rate=0.3, max_depth=7, n_estimators=5;, score=0.748 total time=   0.1s\n",
      "[CV 1/20; 23/36] START learning_rate=0.3, max_depth=7, n_estimators=50..........\n",
      "[CV 1/20; 23/36] END learning_rate=0.3, max_depth=7, n_estimators=50;, score=0.749 total time=   0.8s\n",
      "[CV 2/20; 23/36] START learning_rate=0.3, max_depth=7, n_estimators=50..........\n",
      "[CV 2/20; 23/36] END learning_rate=0.3, max_depth=7, n_estimators=50;, score=0.746 total time=   0.8s\n",
      "[CV 3/20; 23/36] START learning_rate=0.3, max_depth=7, n_estimators=50..........\n",
      "[CV 3/20; 23/36] END learning_rate=0.3, max_depth=7, n_estimators=50;, score=0.750 total time=   0.8s\n",
      "[CV 4/20; 23/36] START learning_rate=0.3, max_depth=7, n_estimators=50..........\n",
      "[CV 4/20; 23/36] END learning_rate=0.3, max_depth=7, n_estimators=50;, score=0.748 total time=   0.8s\n",
      "[CV 5/20; 23/36] START learning_rate=0.3, max_depth=7, n_estimators=50..........\n",
      "[CV 5/20; 23/36] END learning_rate=0.3, max_depth=7, n_estimators=50;, score=0.748 total time=   0.8s\n",
      "[CV 6/20; 23/36] START learning_rate=0.3, max_depth=7, n_estimators=50..........\n",
      "[CV 6/20; 23/36] END learning_rate=0.3, max_depth=7, n_estimators=50;, score=0.750 total time=   0.8s\n",
      "[CV 7/20; 23/36] START learning_rate=0.3, max_depth=7, n_estimators=50..........\n",
      "[CV 7/20; 23/36] END learning_rate=0.3, max_depth=7, n_estimators=50;, score=0.747 total time=   0.8s\n",
      "[CV 8/20; 23/36] START learning_rate=0.3, max_depth=7, n_estimators=50..........\n",
      "[CV 8/20; 23/36] END learning_rate=0.3, max_depth=7, n_estimators=50;, score=0.754 total time=   0.8s\n",
      "[CV 9/20; 23/36] START learning_rate=0.3, max_depth=7, n_estimators=50..........\n",
      "[CV 9/20; 23/36] END learning_rate=0.3, max_depth=7, n_estimators=50;, score=0.748 total time=   0.9s\n",
      "[CV 10/20; 23/36] START learning_rate=0.3, max_depth=7, n_estimators=50.........\n",
      "[CV 10/20; 23/36] END learning_rate=0.3, max_depth=7, n_estimators=50;, score=0.737 total time=   0.8s\n",
      "[CV 11/20; 23/36] START learning_rate=0.3, max_depth=7, n_estimators=50.........\n",
      "[CV 11/20; 23/36] END learning_rate=0.3, max_depth=7, n_estimators=50;, score=0.747 total time=   0.8s\n",
      "[CV 12/20; 23/36] START learning_rate=0.3, max_depth=7, n_estimators=50.........\n",
      "[CV 12/20; 23/36] END learning_rate=0.3, max_depth=7, n_estimators=50;, score=0.746 total time=   0.8s\n",
      "[CV 13/20; 23/36] START learning_rate=0.3, max_depth=7, n_estimators=50.........\n",
      "[CV 13/20; 23/36] END learning_rate=0.3, max_depth=7, n_estimators=50;, score=0.750 total time=   0.8s\n",
      "[CV 14/20; 23/36] START learning_rate=0.3, max_depth=7, n_estimators=50.........\n",
      "[CV 14/20; 23/36] END learning_rate=0.3, max_depth=7, n_estimators=50;, score=0.748 total time=   0.8s\n",
      "[CV 15/20; 23/36] START learning_rate=0.3, max_depth=7, n_estimators=50.........\n",
      "[CV 15/20; 23/36] END learning_rate=0.3, max_depth=7, n_estimators=50;, score=0.750 total time=   0.8s\n",
      "[CV 16/20; 23/36] START learning_rate=0.3, max_depth=7, n_estimators=50.........\n",
      "[CV 16/20; 23/36] END learning_rate=0.3, max_depth=7, n_estimators=50;, score=0.749 total time=   0.8s\n",
      "[CV 17/20; 23/36] START learning_rate=0.3, max_depth=7, n_estimators=50.........\n",
      "[CV 17/20; 23/36] END learning_rate=0.3, max_depth=7, n_estimators=50;, score=0.750 total time=   0.8s\n",
      "[CV 18/20; 23/36] START learning_rate=0.3, max_depth=7, n_estimators=50.........\n",
      "[CV 18/20; 23/36] END learning_rate=0.3, max_depth=7, n_estimators=50;, score=0.747 total time=   0.8s\n",
      "[CV 19/20; 23/36] START learning_rate=0.3, max_depth=7, n_estimators=50.........\n",
      "[CV 19/20; 23/36] END learning_rate=0.3, max_depth=7, n_estimators=50;, score=0.743 total time=   0.8s\n",
      "[CV 20/20; 23/36] START learning_rate=0.3, max_depth=7, n_estimators=50.........\n",
      "[CV 20/20; 23/36] END learning_rate=0.3, max_depth=7, n_estimators=50;, score=0.748 total time=   0.8s\n",
      "[CV 1/20; 24/36] START learning_rate=0.3, max_depth=7, n_estimators=120.........\n",
      "[CV 1/20; 24/36] END learning_rate=0.3, max_depth=7, n_estimators=120;, score=0.749 total time=   2.0s\n",
      "[CV 2/20; 24/36] START learning_rate=0.3, max_depth=7, n_estimators=120.........\n",
      "[CV 2/20; 24/36] END learning_rate=0.3, max_depth=7, n_estimators=120;, score=0.746 total time=   1.9s\n",
      "[CV 3/20; 24/36] START learning_rate=0.3, max_depth=7, n_estimators=120.........\n",
      "[CV 3/20; 24/36] END learning_rate=0.3, max_depth=7, n_estimators=120;, score=0.750 total time=   2.0s\n",
      "[CV 4/20; 24/36] START learning_rate=0.3, max_depth=7, n_estimators=120.........\n",
      "[CV 4/20; 24/36] END learning_rate=0.3, max_depth=7, n_estimators=120;, score=0.748 total time=   2.0s\n",
      "[CV 5/20; 24/36] START learning_rate=0.3, max_depth=7, n_estimators=120.........\n",
      "[CV 5/20; 24/36] END learning_rate=0.3, max_depth=7, n_estimators=120;, score=0.748 total time=   2.0s\n",
      "[CV 6/20; 24/36] START learning_rate=0.3, max_depth=7, n_estimators=120.........\n",
      "[CV 6/20; 24/36] END learning_rate=0.3, max_depth=7, n_estimators=120;, score=0.750 total time=   2.0s\n",
      "[CV 7/20; 24/36] START learning_rate=0.3, max_depth=7, n_estimators=120.........\n",
      "[CV 7/20; 24/36] END learning_rate=0.3, max_depth=7, n_estimators=120;, score=0.747 total time=   1.9s\n",
      "[CV 8/20; 24/36] START learning_rate=0.3, max_depth=7, n_estimators=120.........\n",
      "[CV 8/20; 24/36] END learning_rate=0.3, max_depth=7, n_estimators=120;, score=0.754 total time=   2.0s\n",
      "[CV 9/20; 24/36] START learning_rate=0.3, max_depth=7, n_estimators=120.........\n",
      "[CV 9/20; 24/36] END learning_rate=0.3, max_depth=7, n_estimators=120;, score=0.748 total time=   2.0s\n",
      "[CV 10/20; 24/36] START learning_rate=0.3, max_depth=7, n_estimators=120........\n",
      "[CV 10/20; 24/36] END learning_rate=0.3, max_depth=7, n_estimators=120;, score=0.737 total time=   1.9s\n",
      "[CV 11/20; 24/36] START learning_rate=0.3, max_depth=7, n_estimators=120........\n",
      "[CV 11/20; 24/36] END learning_rate=0.3, max_depth=7, n_estimators=120;, score=0.747 total time=   2.0s\n",
      "[CV 12/20; 24/36] START learning_rate=0.3, max_depth=7, n_estimators=120........\n",
      "[CV 12/20; 24/36] END learning_rate=0.3, max_depth=7, n_estimators=120;, score=0.746 total time=   1.9s\n",
      "[CV 13/20; 24/36] START learning_rate=0.3, max_depth=7, n_estimators=120........\n",
      "[CV 13/20; 24/36] END learning_rate=0.3, max_depth=7, n_estimators=120;, score=0.750 total time=   2.0s\n",
      "[CV 14/20; 24/36] START learning_rate=0.3, max_depth=7, n_estimators=120........\n",
      "[CV 14/20; 24/36] END learning_rate=0.3, max_depth=7, n_estimators=120;, score=0.748 total time=   1.9s\n",
      "[CV 15/20; 24/36] START learning_rate=0.3, max_depth=7, n_estimators=120........\n",
      "[CV 15/20; 24/36] END learning_rate=0.3, max_depth=7, n_estimators=120;, score=0.750 total time=   2.0s\n",
      "[CV 16/20; 24/36] START learning_rate=0.3, max_depth=7, n_estimators=120........\n",
      "[CV 16/20; 24/36] END learning_rate=0.3, max_depth=7, n_estimators=120;, score=0.749 total time=   2.0s\n",
      "[CV 17/20; 24/36] START learning_rate=0.3, max_depth=7, n_estimators=120........\n",
      "[CV 17/20; 24/36] END learning_rate=0.3, max_depth=7, n_estimators=120;, score=0.750 total time=   2.0s\n",
      "[CV 18/20; 24/36] START learning_rate=0.3, max_depth=7, n_estimators=120........\n",
      "[CV 18/20; 24/36] END learning_rate=0.3, max_depth=7, n_estimators=120;, score=0.747 total time=   1.9s\n",
      "[CV 19/20; 24/36] START learning_rate=0.3, max_depth=7, n_estimators=120........\n",
      "[CV 19/20; 24/36] END learning_rate=0.3, max_depth=7, n_estimators=120;, score=0.743 total time=   1.9s\n",
      "[CV 20/20; 24/36] START learning_rate=0.3, max_depth=7, n_estimators=120........\n",
      "[CV 20/20; 24/36] END learning_rate=0.3, max_depth=7, n_estimators=120;, score=0.748 total time=   2.0s\n",
      "[CV 1/20; 25/36] START learning_rate=0.5, max_depth=3, n_estimators=5...........\n",
      "[CV 1/20; 25/36] END learning_rate=0.5, max_depth=3, n_estimators=5;, score=0.749 total time=   0.0s\n",
      "[CV 2/20; 25/36] START learning_rate=0.5, max_depth=3, n_estimators=5...........\n",
      "[CV 2/20; 25/36] END learning_rate=0.5, max_depth=3, n_estimators=5;, score=0.746 total time=   0.0s\n",
      "[CV 3/20; 25/36] START learning_rate=0.5, max_depth=3, n_estimators=5...........\n",
      "[CV 3/20; 25/36] END learning_rate=0.5, max_depth=3, n_estimators=5;, score=0.750 total time=   0.0s\n",
      "[CV 4/20; 25/36] START learning_rate=0.5, max_depth=3, n_estimators=5...........\n",
      "[CV 4/20; 25/36] END learning_rate=0.5, max_depth=3, n_estimators=5;, score=0.748 total time=   0.0s\n",
      "[CV 5/20; 25/36] START learning_rate=0.5, max_depth=3, n_estimators=5...........\n",
      "[CV 5/20; 25/36] END learning_rate=0.5, max_depth=3, n_estimators=5;, score=0.748 total time=   0.0s\n",
      "[CV 6/20; 25/36] START learning_rate=0.5, max_depth=3, n_estimators=5...........\n",
      "[CV 6/20; 25/36] END learning_rate=0.5, max_depth=3, n_estimators=5;, score=0.750 total time=   0.0s\n",
      "[CV 7/20; 25/36] START learning_rate=0.5, max_depth=3, n_estimators=5...........\n",
      "[CV 7/20; 25/36] END learning_rate=0.5, max_depth=3, n_estimators=5;, score=0.747 total time=   0.0s\n",
      "[CV 8/20; 25/36] START learning_rate=0.5, max_depth=3, n_estimators=5...........\n",
      "[CV 8/20; 25/36] END learning_rate=0.5, max_depth=3, n_estimators=5;, score=0.754 total time=   0.0s\n",
      "[CV 9/20; 25/36] START learning_rate=0.5, max_depth=3, n_estimators=5...........\n",
      "[CV 9/20; 25/36] END learning_rate=0.5, max_depth=3, n_estimators=5;, score=0.748 total time=   0.0s\n",
      "[CV 10/20; 25/36] START learning_rate=0.5, max_depth=3, n_estimators=5..........\n",
      "[CV 10/20; 25/36] END learning_rate=0.5, max_depth=3, n_estimators=5;, score=0.741 total time=   0.0s\n",
      "[CV 11/20; 25/36] START learning_rate=0.5, max_depth=3, n_estimators=5..........\n",
      "[CV 11/20; 25/36] END learning_rate=0.5, max_depth=3, n_estimators=5;, score=0.747 total time=   0.0s\n",
      "[CV 12/20; 25/36] START learning_rate=0.5, max_depth=3, n_estimators=5..........\n",
      "[CV 12/20; 25/36] END learning_rate=0.5, max_depth=3, n_estimators=5;, score=0.746 total time=   0.0s\n",
      "[CV 13/20; 25/36] START learning_rate=0.5, max_depth=3, n_estimators=5..........\n",
      "[CV 13/20; 25/36] END learning_rate=0.5, max_depth=3, n_estimators=5;, score=0.750 total time=   0.0s\n",
      "[CV 14/20; 25/36] START learning_rate=0.5, max_depth=3, n_estimators=5..........\n",
      "[CV 14/20; 25/36] END learning_rate=0.5, max_depth=3, n_estimators=5;, score=0.748 total time=   0.0s\n",
      "[CV 15/20; 25/36] START learning_rate=0.5, max_depth=3, n_estimators=5..........\n",
      "[CV 15/20; 25/36] END learning_rate=0.5, max_depth=3, n_estimators=5;, score=0.749 total time=   0.0s\n",
      "[CV 16/20; 25/36] START learning_rate=0.5, max_depth=3, n_estimators=5..........\n",
      "[CV 16/20; 25/36] END learning_rate=0.5, max_depth=3, n_estimators=5;, score=0.749 total time=   0.0s\n",
      "[CV 17/20; 25/36] START learning_rate=0.5, max_depth=3, n_estimators=5..........\n",
      "[CV 17/20; 25/36] END learning_rate=0.5, max_depth=3, n_estimators=5;, score=0.750 total time=   0.0s\n",
      "[CV 18/20; 25/36] START learning_rate=0.5, max_depth=3, n_estimators=5..........\n",
      "[CV 18/20; 25/36] END learning_rate=0.5, max_depth=3, n_estimators=5;, score=0.747 total time=   0.0s\n",
      "[CV 19/20; 25/36] START learning_rate=0.5, max_depth=3, n_estimators=5..........\n",
      "[CV 19/20; 25/36] END learning_rate=0.5, max_depth=3, n_estimators=5;, score=0.747 total time=   0.0s\n",
      "[CV 20/20; 25/36] START learning_rate=0.5, max_depth=3, n_estimators=5..........\n",
      "[CV 20/20; 25/36] END learning_rate=0.5, max_depth=3, n_estimators=5;, score=0.748 total time=   0.0s\n",
      "[CV 1/20; 26/36] START learning_rate=0.5, max_depth=3, n_estimators=50..........\n",
      "[CV 1/20; 26/36] END learning_rate=0.5, max_depth=3, n_estimators=50;, score=0.749 total time=   0.3s\n",
      "[CV 2/20; 26/36] START learning_rate=0.5, max_depth=3, n_estimators=50..........\n",
      "[CV 2/20; 26/36] END learning_rate=0.5, max_depth=3, n_estimators=50;, score=0.746 total time=   0.3s\n",
      "[CV 3/20; 26/36] START learning_rate=0.5, max_depth=3, n_estimators=50..........\n",
      "[CV 3/20; 26/36] END learning_rate=0.5, max_depth=3, n_estimators=50;, score=0.750 total time=   0.3s\n",
      "[CV 4/20; 26/36] START learning_rate=0.5, max_depth=3, n_estimators=50..........\n",
      "[CV 4/20; 26/36] END learning_rate=0.5, max_depth=3, n_estimators=50;, score=0.748 total time=   0.3s\n",
      "[CV 5/20; 26/36] START learning_rate=0.5, max_depth=3, n_estimators=50..........\n",
      "[CV 5/20; 26/36] END learning_rate=0.5, max_depth=3, n_estimators=50;, score=0.748 total time=   0.3s\n",
      "[CV 6/20; 26/36] START learning_rate=0.5, max_depth=3, n_estimators=50..........\n",
      "[CV 6/20; 26/36] END learning_rate=0.5, max_depth=3, n_estimators=50;, score=0.750 total time=   0.3s\n",
      "[CV 7/20; 26/36] START learning_rate=0.5, max_depth=3, n_estimators=50..........\n",
      "[CV 7/20; 26/36] END learning_rate=0.5, max_depth=3, n_estimators=50;, score=0.747 total time=   0.4s\n",
      "[CV 8/20; 26/36] START learning_rate=0.5, max_depth=3, n_estimators=50..........\n",
      "[CV 8/20; 26/36] END learning_rate=0.5, max_depth=3, n_estimators=50;, score=0.754 total time=   0.3s\n",
      "[CV 9/20; 26/36] START learning_rate=0.5, max_depth=3, n_estimators=50..........\n",
      "[CV 9/20; 26/36] END learning_rate=0.5, max_depth=3, n_estimators=50;, score=0.748 total time=   0.4s\n",
      "[CV 10/20; 26/36] START learning_rate=0.5, max_depth=3, n_estimators=50.........\n",
      "[CV 10/20; 26/36] END learning_rate=0.5, max_depth=3, n_estimators=50;, score=0.741 total time=   0.3s\n",
      "[CV 11/20; 26/36] START learning_rate=0.5, max_depth=3, n_estimators=50.........\n",
      "[CV 11/20; 26/36] END learning_rate=0.5, max_depth=3, n_estimators=50;, score=0.747 total time=   0.4s\n",
      "[CV 12/20; 26/36] START learning_rate=0.5, max_depth=3, n_estimators=50.........\n",
      "[CV 12/20; 26/36] END learning_rate=0.5, max_depth=3, n_estimators=50;, score=0.746 total time=   0.3s\n",
      "[CV 13/20; 26/36] START learning_rate=0.5, max_depth=3, n_estimators=50.........\n",
      "[CV 13/20; 26/36] END learning_rate=0.5, max_depth=3, n_estimators=50;, score=0.750 total time=   0.3s\n",
      "[CV 14/20; 26/36] START learning_rate=0.5, max_depth=3, n_estimators=50.........\n",
      "[CV 14/20; 26/36] END learning_rate=0.5, max_depth=3, n_estimators=50;, score=0.748 total time=   0.3s\n",
      "[CV 15/20; 26/36] START learning_rate=0.5, max_depth=3, n_estimators=50.........\n",
      "[CV 15/20; 26/36] END learning_rate=0.5, max_depth=3, n_estimators=50;, score=0.750 total time=   0.4s\n",
      "[CV 16/20; 26/36] START learning_rate=0.5, max_depth=3, n_estimators=50.........\n",
      "[CV 16/20; 26/36] END learning_rate=0.5, max_depth=3, n_estimators=50;, score=0.749 total time=   0.3s\n",
      "[CV 17/20; 26/36] START learning_rate=0.5, max_depth=3, n_estimators=50.........\n",
      "[CV 17/20; 26/36] END learning_rate=0.5, max_depth=3, n_estimators=50;, score=0.750 total time=   0.3s\n",
      "[CV 18/20; 26/36] START learning_rate=0.5, max_depth=3, n_estimators=50.........\n",
      "[CV 18/20; 26/36] END learning_rate=0.5, max_depth=3, n_estimators=50;, score=0.747 total time=   0.3s\n",
      "[CV 19/20; 26/36] START learning_rate=0.5, max_depth=3, n_estimators=50.........\n",
      "[CV 19/20; 26/36] END learning_rate=0.5, max_depth=3, n_estimators=50;, score=0.747 total time=   0.3s\n",
      "[CV 20/20; 26/36] START learning_rate=0.5, max_depth=3, n_estimators=50.........\n",
      "[CV 20/20; 26/36] END learning_rate=0.5, max_depth=3, n_estimators=50;, score=0.748 total time=   0.3s\n",
      "[CV 1/20; 27/36] START learning_rate=0.5, max_depth=3, n_estimators=120.........\n",
      "[CV 1/20; 27/36] END learning_rate=0.5, max_depth=3, n_estimators=120;, score=0.749 total time=   0.8s\n",
      "[CV 2/20; 27/36] START learning_rate=0.5, max_depth=3, n_estimators=120.........\n",
      "[CV 2/20; 27/36] END learning_rate=0.5, max_depth=3, n_estimators=120;, score=0.746 total time=   0.9s\n",
      "[CV 3/20; 27/36] START learning_rate=0.5, max_depth=3, n_estimators=120.........\n",
      "[CV 3/20; 27/36] END learning_rate=0.5, max_depth=3, n_estimators=120;, score=0.750 total time=   0.8s\n",
      "[CV 4/20; 27/36] START learning_rate=0.5, max_depth=3, n_estimators=120.........\n",
      "[CV 4/20; 27/36] END learning_rate=0.5, max_depth=3, n_estimators=120;, score=0.748 total time=   0.8s\n",
      "[CV 5/20; 27/36] START learning_rate=0.5, max_depth=3, n_estimators=120.........\n",
      "[CV 5/20; 27/36] END learning_rate=0.5, max_depth=3, n_estimators=120;, score=0.748 total time=   0.9s\n",
      "[CV 6/20; 27/36] START learning_rate=0.5, max_depth=3, n_estimators=120.........\n",
      "[CV 6/20; 27/36] END learning_rate=0.5, max_depth=3, n_estimators=120;, score=0.750 total time=   0.8s\n",
      "[CV 7/20; 27/36] START learning_rate=0.5, max_depth=3, n_estimators=120.........\n",
      "[CV 7/20; 27/36] END learning_rate=0.5, max_depth=3, n_estimators=120;, score=0.747 total time=   0.9s\n",
      "[CV 8/20; 27/36] START learning_rate=0.5, max_depth=3, n_estimators=120.........\n",
      "[CV 8/20; 27/36] END learning_rate=0.5, max_depth=3, n_estimators=120;, score=0.754 total time=   0.8s\n",
      "[CV 9/20; 27/36] START learning_rate=0.5, max_depth=3, n_estimators=120.........\n",
      "[CV 9/20; 27/36] END learning_rate=0.5, max_depth=3, n_estimators=120;, score=0.748 total time=   0.8s\n",
      "[CV 10/20; 27/36] START learning_rate=0.5, max_depth=3, n_estimators=120........\n",
      "[CV 10/20; 27/36] END learning_rate=0.5, max_depth=3, n_estimators=120;, score=0.741 total time=   0.8s\n",
      "[CV 11/20; 27/36] START learning_rate=0.5, max_depth=3, n_estimators=120........\n",
      "[CV 11/20; 27/36] END learning_rate=0.5, max_depth=3, n_estimators=120;, score=0.747 total time=   0.9s\n",
      "[CV 12/20; 27/36] START learning_rate=0.5, max_depth=3, n_estimators=120........\n",
      "[CV 12/20; 27/36] END learning_rate=0.5, max_depth=3, n_estimators=120;, score=0.746 total time=   0.9s\n",
      "[CV 13/20; 27/36] START learning_rate=0.5, max_depth=3, n_estimators=120........\n",
      "[CV 13/20; 27/36] END learning_rate=0.5, max_depth=3, n_estimators=120;, score=0.750 total time=   0.8s\n",
      "[CV 14/20; 27/36] START learning_rate=0.5, max_depth=3, n_estimators=120........\n",
      "[CV 14/20; 27/36] END learning_rate=0.5, max_depth=3, n_estimators=120;, score=0.748 total time=   0.8s\n",
      "[CV 15/20; 27/36] START learning_rate=0.5, max_depth=3, n_estimators=120........\n",
      "[CV 15/20; 27/36] END learning_rate=0.5, max_depth=3, n_estimators=120;, score=0.750 total time=   0.9s\n",
      "[CV 16/20; 27/36] START learning_rate=0.5, max_depth=3, n_estimators=120........\n",
      "[CV 16/20; 27/36] END learning_rate=0.5, max_depth=3, n_estimators=120;, score=0.749 total time=   0.8s\n",
      "[CV 17/20; 27/36] START learning_rate=0.5, max_depth=3, n_estimators=120........\n",
      "[CV 17/20; 27/36] END learning_rate=0.5, max_depth=3, n_estimators=120;, score=0.750 total time=   0.9s\n",
      "[CV 18/20; 27/36] START learning_rate=0.5, max_depth=3, n_estimators=120........\n",
      "[CV 18/20; 27/36] END learning_rate=0.5, max_depth=3, n_estimators=120;, score=0.747 total time=   0.9s\n",
      "[CV 19/20; 27/36] START learning_rate=0.5, max_depth=3, n_estimators=120........\n",
      "[CV 19/20; 27/36] END learning_rate=0.5, max_depth=3, n_estimators=120;, score=0.747 total time=   0.8s\n",
      "[CV 20/20; 27/36] START learning_rate=0.5, max_depth=3, n_estimators=120........\n",
      "[CV 20/20; 27/36] END learning_rate=0.5, max_depth=3, n_estimators=120;, score=0.748 total time=   0.8s\n",
      "[CV 1/20; 28/36] START learning_rate=0.5, max_depth=5, n_estimators=5...........\n",
      "[CV 1/20; 28/36] END learning_rate=0.5, max_depth=5, n_estimators=5;, score=0.749 total time=   0.0s\n",
      "[CV 2/20; 28/36] START learning_rate=0.5, max_depth=5, n_estimators=5...........\n",
      "[CV 2/20; 28/36] END learning_rate=0.5, max_depth=5, n_estimators=5;, score=0.746 total time=   0.0s\n",
      "[CV 3/20; 28/36] START learning_rate=0.5, max_depth=5, n_estimators=5...........\n",
      "[CV 3/20; 28/36] END learning_rate=0.5, max_depth=5, n_estimators=5;, score=0.750 total time=   0.0s\n",
      "[CV 4/20; 28/36] START learning_rate=0.5, max_depth=5, n_estimators=5...........\n",
      "[CV 4/20; 28/36] END learning_rate=0.5, max_depth=5, n_estimators=5;, score=0.748 total time=   0.0s\n",
      "[CV 5/20; 28/36] START learning_rate=0.5, max_depth=5, n_estimators=5...........\n",
      "[CV 5/20; 28/36] END learning_rate=0.5, max_depth=5, n_estimators=5;, score=0.748 total time=   0.0s\n",
      "[CV 6/20; 28/36] START learning_rate=0.5, max_depth=5, n_estimators=5...........\n",
      "[CV 6/20; 28/36] END learning_rate=0.5, max_depth=5, n_estimators=5;, score=0.750 total time=   0.0s\n",
      "[CV 7/20; 28/36] START learning_rate=0.5, max_depth=5, n_estimators=5...........\n",
      "[CV 7/20; 28/36] END learning_rate=0.5, max_depth=5, n_estimators=5;, score=0.747 total time=   0.0s\n",
      "[CV 8/20; 28/36] START learning_rate=0.5, max_depth=5, n_estimators=5...........\n",
      "[CV 8/20; 28/36] END learning_rate=0.5, max_depth=5, n_estimators=5;, score=0.754 total time=   0.0s\n",
      "[CV 9/20; 28/36] START learning_rate=0.5, max_depth=5, n_estimators=5...........\n",
      "[CV 9/20; 28/36] END learning_rate=0.5, max_depth=5, n_estimators=5;, score=0.748 total time=   0.1s\n",
      "[CV 10/20; 28/36] START learning_rate=0.5, max_depth=5, n_estimators=5..........\n",
      "[CV 10/20; 28/36] END learning_rate=0.5, max_depth=5, n_estimators=5;, score=0.741 total time=   0.0s\n",
      "[CV 11/20; 28/36] START learning_rate=0.5, max_depth=5, n_estimators=5..........\n",
      "[CV 11/20; 28/36] END learning_rate=0.5, max_depth=5, n_estimators=5;, score=0.747 total time=   0.0s\n",
      "[CV 12/20; 28/36] START learning_rate=0.5, max_depth=5, n_estimators=5..........\n",
      "[CV 12/20; 28/36] END learning_rate=0.5, max_depth=5, n_estimators=5;, score=0.746 total time=   0.0s\n",
      "[CV 13/20; 28/36] START learning_rate=0.5, max_depth=5, n_estimators=5..........\n",
      "[CV 13/20; 28/36] END learning_rate=0.5, max_depth=5, n_estimators=5;, score=0.750 total time=   0.1s\n",
      "[CV 14/20; 28/36] START learning_rate=0.5, max_depth=5, n_estimators=5..........\n",
      "[CV 14/20; 28/36] END learning_rate=0.5, max_depth=5, n_estimators=5;, score=0.748 total time=   0.0s\n",
      "[CV 15/20; 28/36] START learning_rate=0.5, max_depth=5, n_estimators=5..........\n",
      "[CV 15/20; 28/36] END learning_rate=0.5, max_depth=5, n_estimators=5;, score=0.749 total time=   0.0s\n",
      "[CV 16/20; 28/36] START learning_rate=0.5, max_depth=5, n_estimators=5..........\n",
      "[CV 16/20; 28/36] END learning_rate=0.5, max_depth=5, n_estimators=5;, score=0.749 total time=   0.0s\n",
      "[CV 17/20; 28/36] START learning_rate=0.5, max_depth=5, n_estimators=5..........\n",
      "[CV 17/20; 28/36] END learning_rate=0.5, max_depth=5, n_estimators=5;, score=0.750 total time=   0.0s\n",
      "[CV 18/20; 28/36] START learning_rate=0.5, max_depth=5, n_estimators=5..........\n",
      "[CV 18/20; 28/36] END learning_rate=0.5, max_depth=5, n_estimators=5;, score=0.747 total time=   0.0s\n",
      "[CV 19/20; 28/36] START learning_rate=0.5, max_depth=5, n_estimators=5..........\n",
      "[CV 19/20; 28/36] END learning_rate=0.5, max_depth=5, n_estimators=5;, score=0.747 total time=   0.0s\n",
      "[CV 20/20; 28/36] START learning_rate=0.5, max_depth=5, n_estimators=5..........\n",
      "[CV 20/20; 28/36] END learning_rate=0.5, max_depth=5, n_estimators=5;, score=0.748 total time=   0.0s\n",
      "[CV 1/20; 29/36] START learning_rate=0.5, max_depth=5, n_estimators=50..........\n",
      "[CV 1/20; 29/36] END learning_rate=0.5, max_depth=5, n_estimators=50;, score=0.749 total time=   0.6s\n",
      "[CV 2/20; 29/36] START learning_rate=0.5, max_depth=5, n_estimators=50..........\n",
      "[CV 2/20; 29/36] END learning_rate=0.5, max_depth=5, n_estimators=50;, score=0.746 total time=   0.6s\n",
      "[CV 3/20; 29/36] START learning_rate=0.5, max_depth=5, n_estimators=50..........\n",
      "[CV 3/20; 29/36] END learning_rate=0.5, max_depth=5, n_estimators=50;, score=0.750 total time=   0.6s\n",
      "[CV 4/20; 29/36] START learning_rate=0.5, max_depth=5, n_estimators=50..........\n",
      "[CV 4/20; 29/36] END learning_rate=0.5, max_depth=5, n_estimators=50;, score=0.748 total time=   0.6s\n",
      "[CV 5/20; 29/36] START learning_rate=0.5, max_depth=5, n_estimators=50..........\n",
      "[CV 5/20; 29/36] END learning_rate=0.5, max_depth=5, n_estimators=50;, score=0.748 total time=   0.6s\n",
      "[CV 6/20; 29/36] START learning_rate=0.5, max_depth=5, n_estimators=50..........\n",
      "[CV 6/20; 29/36] END learning_rate=0.5, max_depth=5, n_estimators=50;, score=0.750 total time=   0.6s\n",
      "[CV 7/20; 29/36] START learning_rate=0.5, max_depth=5, n_estimators=50..........\n",
      "[CV 7/20; 29/36] END learning_rate=0.5, max_depth=5, n_estimators=50;, score=0.747 total time=   0.6s\n",
      "[CV 8/20; 29/36] START learning_rate=0.5, max_depth=5, n_estimators=50..........\n",
      "[CV 8/20; 29/36] END learning_rate=0.5, max_depth=5, n_estimators=50;, score=0.754 total time=   0.6s\n",
      "[CV 9/20; 29/36] START learning_rate=0.5, max_depth=5, n_estimators=50..........\n",
      "[CV 9/20; 29/36] END learning_rate=0.5, max_depth=5, n_estimators=50;, score=0.748 total time=   0.6s\n",
      "[CV 10/20; 29/36] START learning_rate=0.5, max_depth=5, n_estimators=50.........\n",
      "[CV 10/20; 29/36] END learning_rate=0.5, max_depth=5, n_estimators=50;, score=0.741 total time=   0.5s\n",
      "[CV 11/20; 29/36] START learning_rate=0.5, max_depth=5, n_estimators=50.........\n",
      "[CV 11/20; 29/36] END learning_rate=0.5, max_depth=5, n_estimators=50;, score=0.747 total time=   0.6s\n",
      "[CV 12/20; 29/36] START learning_rate=0.5, max_depth=5, n_estimators=50.........\n",
      "[CV 12/20; 29/36] END learning_rate=0.5, max_depth=5, n_estimators=50;, score=0.746 total time=   0.6s\n",
      "[CV 13/20; 29/36] START learning_rate=0.5, max_depth=5, n_estimators=50.........\n",
      "[CV 13/20; 29/36] END learning_rate=0.5, max_depth=5, n_estimators=50;, score=0.750 total time=   0.6s\n",
      "[CV 14/20; 29/36] START learning_rate=0.5, max_depth=5, n_estimators=50.........\n",
      "[CV 14/20; 29/36] END learning_rate=0.5, max_depth=5, n_estimators=50;, score=0.748 total time=   0.6s\n",
      "[CV 15/20; 29/36] START learning_rate=0.5, max_depth=5, n_estimators=50.........\n",
      "[CV 15/20; 29/36] END learning_rate=0.5, max_depth=5, n_estimators=50;, score=0.750 total time=   0.6s\n",
      "[CV 16/20; 29/36] START learning_rate=0.5, max_depth=5, n_estimators=50.........\n",
      "[CV 16/20; 29/36] END learning_rate=0.5, max_depth=5, n_estimators=50;, score=0.749 total time=   0.6s\n",
      "[CV 17/20; 29/36] START learning_rate=0.5, max_depth=5, n_estimators=50.........\n",
      "[CV 17/20; 29/36] END learning_rate=0.5, max_depth=5, n_estimators=50;, score=0.750 total time=   0.6s\n",
      "[CV 18/20; 29/36] START learning_rate=0.5, max_depth=5, n_estimators=50.........\n",
      "[CV 18/20; 29/36] END learning_rate=0.5, max_depth=5, n_estimators=50;, score=0.747 total time=   0.6s\n",
      "[CV 19/20; 29/36] START learning_rate=0.5, max_depth=5, n_estimators=50.........\n",
      "[CV 19/20; 29/36] END learning_rate=0.5, max_depth=5, n_estimators=50;, score=0.747 total time=   0.6s\n",
      "[CV 20/20; 29/36] START learning_rate=0.5, max_depth=5, n_estimators=50.........\n",
      "[CV 20/20; 29/36] END learning_rate=0.5, max_depth=5, n_estimators=50;, score=0.748 total time=   0.6s\n",
      "[CV 1/20; 30/36] START learning_rate=0.5, max_depth=5, n_estimators=120.........\n",
      "[CV 1/20; 30/36] END learning_rate=0.5, max_depth=5, n_estimators=120;, score=0.749 total time=   1.4s\n",
      "[CV 2/20; 30/36] START learning_rate=0.5, max_depth=5, n_estimators=120.........\n",
      "[CV 2/20; 30/36] END learning_rate=0.5, max_depth=5, n_estimators=120;, score=0.746 total time=   1.4s\n",
      "[CV 3/20; 30/36] START learning_rate=0.5, max_depth=5, n_estimators=120.........\n",
      "[CV 3/20; 30/36] END learning_rate=0.5, max_depth=5, n_estimators=120;, score=0.750 total time=   1.4s\n",
      "[CV 4/20; 30/36] START learning_rate=0.5, max_depth=5, n_estimators=120.........\n",
      "[CV 4/20; 30/36] END learning_rate=0.5, max_depth=5, n_estimators=120;, score=0.748 total time=   1.4s\n",
      "[CV 5/20; 30/36] START learning_rate=0.5, max_depth=5, n_estimators=120.........\n",
      "[CV 5/20; 30/36] END learning_rate=0.5, max_depth=5, n_estimators=120;, score=0.748 total time=   1.4s\n",
      "[CV 6/20; 30/36] START learning_rate=0.5, max_depth=5, n_estimators=120.........\n",
      "[CV 6/20; 30/36] END learning_rate=0.5, max_depth=5, n_estimators=120;, score=0.750 total time=   1.4s\n",
      "[CV 7/20; 30/36] START learning_rate=0.5, max_depth=5, n_estimators=120.........\n",
      "[CV 7/20; 30/36] END learning_rate=0.5, max_depth=5, n_estimators=120;, score=0.747 total time=   1.4s\n",
      "[CV 8/20; 30/36] START learning_rate=0.5, max_depth=5, n_estimators=120.........\n",
      "[CV 8/20; 30/36] END learning_rate=0.5, max_depth=5, n_estimators=120;, score=0.754 total time=   1.4s\n",
      "[CV 9/20; 30/36] START learning_rate=0.5, max_depth=5, n_estimators=120.........\n",
      "[CV 9/20; 30/36] END learning_rate=0.5, max_depth=5, n_estimators=120;, score=0.748 total time=   1.5s\n",
      "[CV 10/20; 30/36] START learning_rate=0.5, max_depth=5, n_estimators=120........\n",
      "[CV 10/20; 30/36] END learning_rate=0.5, max_depth=5, n_estimators=120;, score=0.741 total time=   1.4s\n",
      "[CV 11/20; 30/36] START learning_rate=0.5, max_depth=5, n_estimators=120........\n",
      "[CV 11/20; 30/36] END learning_rate=0.5, max_depth=5, n_estimators=120;, score=0.747 total time=   1.4s\n",
      "[CV 12/20; 30/36] START learning_rate=0.5, max_depth=5, n_estimators=120........\n",
      "[CV 12/20; 30/36] END learning_rate=0.5, max_depth=5, n_estimators=120;, score=0.746 total time=   1.4s\n",
      "[CV 13/20; 30/36] START learning_rate=0.5, max_depth=5, n_estimators=120........\n",
      "[CV 13/20; 30/36] END learning_rate=0.5, max_depth=5, n_estimators=120;, score=0.750 total time=   1.5s\n",
      "[CV 14/20; 30/36] START learning_rate=0.5, max_depth=5, n_estimators=120........\n",
      "[CV 14/20; 30/36] END learning_rate=0.5, max_depth=5, n_estimators=120;, score=0.748 total time=   1.4s\n",
      "[CV 15/20; 30/36] START learning_rate=0.5, max_depth=5, n_estimators=120........\n",
      "[CV 15/20; 30/36] END learning_rate=0.5, max_depth=5, n_estimators=120;, score=0.750 total time=   1.4s\n",
      "[CV 16/20; 30/36] START learning_rate=0.5, max_depth=5, n_estimators=120........\n",
      "[CV 16/20; 30/36] END learning_rate=0.5, max_depth=5, n_estimators=120;, score=0.749 total time=   1.4s\n",
      "[CV 17/20; 30/36] START learning_rate=0.5, max_depth=5, n_estimators=120........\n",
      "[CV 17/20; 30/36] END learning_rate=0.5, max_depth=5, n_estimators=120;, score=0.750 total time=   1.4s\n",
      "[CV 18/20; 30/36] START learning_rate=0.5, max_depth=5, n_estimators=120........\n",
      "[CV 18/20; 30/36] END learning_rate=0.5, max_depth=5, n_estimators=120;, score=0.747 total time=   1.4s\n",
      "[CV 19/20; 30/36] START learning_rate=0.5, max_depth=5, n_estimators=120........\n",
      "[CV 19/20; 30/36] END learning_rate=0.5, max_depth=5, n_estimators=120;, score=0.747 total time=   1.4s\n",
      "[CV 20/20; 30/36] START learning_rate=0.5, max_depth=5, n_estimators=120........\n",
      "[CV 20/20; 30/36] END learning_rate=0.5, max_depth=5, n_estimators=120;, score=0.748 total time=   1.4s\n",
      "[CV 1/20; 31/36] START learning_rate=0.5, max_depth=6, n_estimators=5...........\n",
      "[CV 1/20; 31/36] END learning_rate=0.5, max_depth=6, n_estimators=5;, score=0.749 total time=   0.0s\n",
      "[CV 2/20; 31/36] START learning_rate=0.5, max_depth=6, n_estimators=5...........\n",
      "[CV 2/20; 31/36] END learning_rate=0.5, max_depth=6, n_estimators=5;, score=0.746 total time=   0.0s\n",
      "[CV 3/20; 31/36] START learning_rate=0.5, max_depth=6, n_estimators=5...........\n",
      "[CV 3/20; 31/36] END learning_rate=0.5, max_depth=6, n_estimators=5;, score=0.750 total time=   0.1s\n",
      "[CV 4/20; 31/36] START learning_rate=0.5, max_depth=6, n_estimators=5...........\n",
      "[CV 4/20; 31/36] END learning_rate=0.5, max_depth=6, n_estimators=5;, score=0.748 total time=   0.1s\n",
      "[CV 5/20; 31/36] START learning_rate=0.5, max_depth=6, n_estimators=5...........\n",
      "[CV 5/20; 31/36] END learning_rate=0.5, max_depth=6, n_estimators=5;, score=0.748 total time=   0.1s\n",
      "[CV 6/20; 31/36] START learning_rate=0.5, max_depth=6, n_estimators=5...........\n",
      "[CV 6/20; 31/36] END learning_rate=0.5, max_depth=6, n_estimators=5;, score=0.750 total time=   0.1s\n",
      "[CV 7/20; 31/36] START learning_rate=0.5, max_depth=6, n_estimators=5...........\n",
      "[CV 7/20; 31/36] END learning_rate=0.5, max_depth=6, n_estimators=5;, score=0.747 total time=   0.1s\n",
      "[CV 8/20; 31/36] START learning_rate=0.5, max_depth=6, n_estimators=5...........\n",
      "[CV 8/20; 31/36] END learning_rate=0.5, max_depth=6, n_estimators=5;, score=0.754 total time=   0.1s\n",
      "[CV 9/20; 31/36] START learning_rate=0.5, max_depth=6, n_estimators=5...........\n",
      "[CV 9/20; 31/36] END learning_rate=0.5, max_depth=6, n_estimators=5;, score=0.748 total time=   0.1s\n",
      "[CV 10/20; 31/36] START learning_rate=0.5, max_depth=6, n_estimators=5..........\n",
      "[CV 10/20; 31/36] END learning_rate=0.5, max_depth=6, n_estimators=5;, score=0.741 total time=   0.0s\n",
      "[CV 11/20; 31/36] START learning_rate=0.5, max_depth=6, n_estimators=5..........\n",
      "[CV 11/20; 31/36] END learning_rate=0.5, max_depth=6, n_estimators=5;, score=0.747 total time=   0.0s\n",
      "[CV 12/20; 31/36] START learning_rate=0.5, max_depth=6, n_estimators=5..........\n",
      "[CV 12/20; 31/36] END learning_rate=0.5, max_depth=6, n_estimators=5;, score=0.746 total time=   0.1s\n",
      "[CV 13/20; 31/36] START learning_rate=0.5, max_depth=6, n_estimators=5..........\n",
      "[CV 13/20; 31/36] END learning_rate=0.5, max_depth=6, n_estimators=5;, score=0.750 total time=   0.1s\n",
      "[CV 14/20; 31/36] START learning_rate=0.5, max_depth=6, n_estimators=5..........\n",
      "[CV 14/20; 31/36] END learning_rate=0.5, max_depth=6, n_estimators=5;, score=0.748 total time=   0.1s\n",
      "[CV 15/20; 31/36] START learning_rate=0.5, max_depth=6, n_estimators=5..........\n",
      "[CV 15/20; 31/36] END learning_rate=0.5, max_depth=6, n_estimators=5;, score=0.749 total time=   0.1s\n",
      "[CV 16/20; 31/36] START learning_rate=0.5, max_depth=6, n_estimators=5..........\n",
      "[CV 16/20; 31/36] END learning_rate=0.5, max_depth=6, n_estimators=5;, score=0.749 total time=   0.1s\n",
      "[CV 17/20; 31/36] START learning_rate=0.5, max_depth=6, n_estimators=5..........\n",
      "[CV 17/20; 31/36] END learning_rate=0.5, max_depth=6, n_estimators=5;, score=0.750 total time=   0.1s\n",
      "[CV 18/20; 31/36] START learning_rate=0.5, max_depth=6, n_estimators=5..........\n",
      "[CV 18/20; 31/36] END learning_rate=0.5, max_depth=6, n_estimators=5;, score=0.747 total time=   0.1s\n",
      "[CV 19/20; 31/36] START learning_rate=0.5, max_depth=6, n_estimators=5..........\n",
      "[CV 19/20; 31/36] END learning_rate=0.5, max_depth=6, n_estimators=5;, score=0.747 total time=   0.0s\n",
      "[CV 20/20; 31/36] START learning_rate=0.5, max_depth=6, n_estimators=5..........\n",
      "[CV 20/20; 31/36] END learning_rate=0.5, max_depth=6, n_estimators=5;, score=0.748 total time=   0.1s\n",
      "[CV 1/20; 32/36] START learning_rate=0.5, max_depth=6, n_estimators=50..........\n",
      "[CV 1/20; 32/36] END learning_rate=0.5, max_depth=6, n_estimators=50;, score=0.749 total time=   0.7s\n",
      "[CV 2/20; 32/36] START learning_rate=0.5, max_depth=6, n_estimators=50..........\n",
      "[CV 2/20; 32/36] END learning_rate=0.5, max_depth=6, n_estimators=50;, score=0.746 total time=   0.7s\n",
      "[CV 3/20; 32/36] START learning_rate=0.5, max_depth=6, n_estimators=50..........\n",
      "[CV 3/20; 32/36] END learning_rate=0.5, max_depth=6, n_estimators=50;, score=0.750 total time=   0.7s\n",
      "[CV 4/20; 32/36] START learning_rate=0.5, max_depth=6, n_estimators=50..........\n",
      "[CV 4/20; 32/36] END learning_rate=0.5, max_depth=6, n_estimators=50;, score=0.748 total time=   0.7s\n",
      "[CV 5/20; 32/36] START learning_rate=0.5, max_depth=6, n_estimators=50..........\n",
      "[CV 5/20; 32/36] END learning_rate=0.5, max_depth=6, n_estimators=50;, score=0.748 total time=   0.7s\n",
      "[CV 6/20; 32/36] START learning_rate=0.5, max_depth=6, n_estimators=50..........\n",
      "[CV 6/20; 32/36] END learning_rate=0.5, max_depth=6, n_estimators=50;, score=0.750 total time=   0.7s\n",
      "[CV 7/20; 32/36] START learning_rate=0.5, max_depth=6, n_estimators=50..........\n",
      "[CV 7/20; 32/36] END learning_rate=0.5, max_depth=6, n_estimators=50;, score=0.747 total time=   0.7s\n",
      "[CV 8/20; 32/36] START learning_rate=0.5, max_depth=6, n_estimators=50..........\n",
      "[CV 8/20; 32/36] END learning_rate=0.5, max_depth=6, n_estimators=50;, score=0.754 total time=   0.7s\n",
      "[CV 9/20; 32/36] START learning_rate=0.5, max_depth=6, n_estimators=50..........\n",
      "[CV 9/20; 32/36] END learning_rate=0.5, max_depth=6, n_estimators=50;, score=0.748 total time=   0.7s\n",
      "[CV 10/20; 32/36] START learning_rate=0.5, max_depth=6, n_estimators=50.........\n",
      "[CV 10/20; 32/36] END learning_rate=0.5, max_depth=6, n_estimators=50;, score=0.741 total time=   0.7s\n",
      "[CV 11/20; 32/36] START learning_rate=0.5, max_depth=6, n_estimators=50.........\n",
      "[CV 11/20; 32/36] END learning_rate=0.5, max_depth=6, n_estimators=50;, score=0.747 total time=   0.7s\n",
      "[CV 12/20; 32/36] START learning_rate=0.5, max_depth=6, n_estimators=50.........\n",
      "[CV 12/20; 32/36] END learning_rate=0.5, max_depth=6, n_estimators=50;, score=0.746 total time=   0.7s\n",
      "[CV 13/20; 32/36] START learning_rate=0.5, max_depth=6, n_estimators=50.........\n",
      "[CV 13/20; 32/36] END learning_rate=0.5, max_depth=6, n_estimators=50;, score=0.750 total time=   0.7s\n",
      "[CV 14/20; 32/36] START learning_rate=0.5, max_depth=6, n_estimators=50.........\n",
      "[CV 14/20; 32/36] END learning_rate=0.5, max_depth=6, n_estimators=50;, score=0.748 total time=   0.7s\n",
      "[CV 15/20; 32/36] START learning_rate=0.5, max_depth=6, n_estimators=50.........\n",
      "[CV 15/20; 32/36] END learning_rate=0.5, max_depth=6, n_estimators=50;, score=0.750 total time=   0.7s\n",
      "[CV 16/20; 32/36] START learning_rate=0.5, max_depth=6, n_estimators=50.........\n",
      "[CV 16/20; 32/36] END learning_rate=0.5, max_depth=6, n_estimators=50;, score=0.749 total time=   0.7s\n",
      "[CV 17/20; 32/36] START learning_rate=0.5, max_depth=6, n_estimators=50.........\n",
      "[CV 17/20; 32/36] END learning_rate=0.5, max_depth=6, n_estimators=50;, score=0.750 total time=   0.8s\n",
      "[CV 18/20; 32/36] START learning_rate=0.5, max_depth=6, n_estimators=50.........\n",
      "[CV 18/20; 32/36] END learning_rate=0.5, max_depth=6, n_estimators=50;, score=0.747 total time=   0.7s\n",
      "[CV 19/20; 32/36] START learning_rate=0.5, max_depth=6, n_estimators=50.........\n",
      "[CV 19/20; 32/36] END learning_rate=0.5, max_depth=6, n_estimators=50;, score=0.747 total time=   0.7s\n",
      "[CV 20/20; 32/36] START learning_rate=0.5, max_depth=6, n_estimators=50.........\n",
      "[CV 20/20; 32/36] END learning_rate=0.5, max_depth=6, n_estimators=50;, score=0.748 total time=   0.7s\n",
      "[CV 1/20; 33/36] START learning_rate=0.5, max_depth=6, n_estimators=120.........\n",
      "[CV 1/20; 33/36] END learning_rate=0.5, max_depth=6, n_estimators=120;, score=0.749 total time=   1.7s\n",
      "[CV 2/20; 33/36] START learning_rate=0.5, max_depth=6, n_estimators=120.........\n",
      "[CV 2/20; 33/36] END learning_rate=0.5, max_depth=6, n_estimators=120;, score=0.746 total time=   1.7s\n",
      "[CV 3/20; 33/36] START learning_rate=0.5, max_depth=6, n_estimators=120.........\n",
      "[CV 3/20; 33/36] END learning_rate=0.5, max_depth=6, n_estimators=120;, score=0.750 total time=   1.7s\n",
      "[CV 4/20; 33/36] START learning_rate=0.5, max_depth=6, n_estimators=120.........\n",
      "[CV 4/20; 33/36] END learning_rate=0.5, max_depth=6, n_estimators=120;, score=0.748 total time=   1.7s\n",
      "[CV 5/20; 33/36] START learning_rate=0.5, max_depth=6, n_estimators=120.........\n",
      "[CV 5/20; 33/36] END learning_rate=0.5, max_depth=6, n_estimators=120;, score=0.748 total time=   1.7s\n",
      "[CV 6/20; 33/36] START learning_rate=0.5, max_depth=6, n_estimators=120.........\n",
      "[CV 6/20; 33/36] END learning_rate=0.5, max_depth=6, n_estimators=120;, score=0.750 total time=   1.7s\n",
      "[CV 7/20; 33/36] START learning_rate=0.5, max_depth=6, n_estimators=120.........\n",
      "[CV 7/20; 33/36] END learning_rate=0.5, max_depth=6, n_estimators=120;, score=0.747 total time=   1.7s\n",
      "[CV 8/20; 33/36] START learning_rate=0.5, max_depth=6, n_estimators=120.........\n",
      "[CV 8/20; 33/36] END learning_rate=0.5, max_depth=6, n_estimators=120;, score=0.754 total time=   1.7s\n",
      "[CV 9/20; 33/36] START learning_rate=0.5, max_depth=6, n_estimators=120.........\n",
      "[CV 9/20; 33/36] END learning_rate=0.5, max_depth=6, n_estimators=120;, score=0.748 total time=   1.7s\n",
      "[CV 10/20; 33/36] START learning_rate=0.5, max_depth=6, n_estimators=120........\n",
      "[CV 10/20; 33/36] END learning_rate=0.5, max_depth=6, n_estimators=120;, score=0.741 total time=   1.6s\n",
      "[CV 11/20; 33/36] START learning_rate=0.5, max_depth=6, n_estimators=120........\n",
      "[CV 11/20; 33/36] END learning_rate=0.5, max_depth=6, n_estimators=120;, score=0.747 total time=   1.7s\n",
      "[CV 12/20; 33/36] START learning_rate=0.5, max_depth=6, n_estimators=120........\n",
      "[CV 12/20; 33/36] END learning_rate=0.5, max_depth=6, n_estimators=120;, score=0.746 total time=   1.7s\n",
      "[CV 13/20; 33/36] START learning_rate=0.5, max_depth=6, n_estimators=120........\n",
      "[CV 13/20; 33/36] END learning_rate=0.5, max_depth=6, n_estimators=120;, score=0.750 total time=   1.7s\n",
      "[CV 14/20; 33/36] START learning_rate=0.5, max_depth=6, n_estimators=120........\n",
      "[CV 14/20; 33/36] END learning_rate=0.5, max_depth=6, n_estimators=120;, score=0.748 total time=   1.7s\n",
      "[CV 15/20; 33/36] START learning_rate=0.5, max_depth=6, n_estimators=120........\n",
      "[CV 15/20; 33/36] END learning_rate=0.5, max_depth=6, n_estimators=120;, score=0.750 total time=   1.7s\n",
      "[CV 16/20; 33/36] START learning_rate=0.5, max_depth=6, n_estimators=120........\n",
      "[CV 16/20; 33/36] END learning_rate=0.5, max_depth=6, n_estimators=120;, score=0.749 total time=   1.7s\n",
      "[CV 17/20; 33/36] START learning_rate=0.5, max_depth=6, n_estimators=120........\n",
      "[CV 17/20; 33/36] END learning_rate=0.5, max_depth=6, n_estimators=120;, score=0.750 total time=   1.7s\n",
      "[CV 18/20; 33/36] START learning_rate=0.5, max_depth=6, n_estimators=120........\n",
      "[CV 18/20; 33/36] END learning_rate=0.5, max_depth=6, n_estimators=120;, score=0.747 total time=   1.7s\n",
      "[CV 19/20; 33/36] START learning_rate=0.5, max_depth=6, n_estimators=120........\n",
      "[CV 19/20; 33/36] END learning_rate=0.5, max_depth=6, n_estimators=120;, score=0.747 total time=   1.6s\n",
      "[CV 20/20; 33/36] START learning_rate=0.5, max_depth=6, n_estimators=120........\n",
      "[CV 20/20; 33/36] END learning_rate=0.5, max_depth=6, n_estimators=120;, score=0.748 total time=   1.7s\n",
      "[CV 1/20; 34/36] START learning_rate=0.5, max_depth=7, n_estimators=5...........\n",
      "[CV 1/20; 34/36] END learning_rate=0.5, max_depth=7, n_estimators=5;, score=0.749 total time=   0.1s\n",
      "[CV 2/20; 34/36] START learning_rate=0.5, max_depth=7, n_estimators=5...........\n",
      "[CV 2/20; 34/36] END learning_rate=0.5, max_depth=7, n_estimators=5;, score=0.746 total time=   0.1s\n",
      "[CV 3/20; 34/36] START learning_rate=0.5, max_depth=7, n_estimators=5...........\n",
      "[CV 3/20; 34/36] END learning_rate=0.5, max_depth=7, n_estimators=5;, score=0.750 total time=   0.1s\n",
      "[CV 4/20; 34/36] START learning_rate=0.5, max_depth=7, n_estimators=5...........\n",
      "[CV 4/20; 34/36] END learning_rate=0.5, max_depth=7, n_estimators=5;, score=0.748 total time=   0.1s\n",
      "[CV 5/20; 34/36] START learning_rate=0.5, max_depth=7, n_estimators=5...........\n",
      "[CV 5/20; 34/36] END learning_rate=0.5, max_depth=7, n_estimators=5;, score=0.748 total time=   0.1s\n",
      "[CV 6/20; 34/36] START learning_rate=0.5, max_depth=7, n_estimators=5...........\n",
      "[CV 6/20; 34/36] END learning_rate=0.5, max_depth=7, n_estimators=5;, score=0.750 total time=   0.1s\n",
      "[CV 7/20; 34/36] START learning_rate=0.5, max_depth=7, n_estimators=5...........\n",
      "[CV 7/20; 34/36] END learning_rate=0.5, max_depth=7, n_estimators=5;, score=0.747 total time=   0.1s\n",
      "[CV 8/20; 34/36] START learning_rate=0.5, max_depth=7, n_estimators=5...........\n",
      "[CV 8/20; 34/36] END learning_rate=0.5, max_depth=7, n_estimators=5;, score=0.754 total time=   0.1s\n",
      "[CV 9/20; 34/36] START learning_rate=0.5, max_depth=7, n_estimators=5...........\n",
      "[CV 9/20; 34/36] END learning_rate=0.5, max_depth=7, n_estimators=5;, score=0.748 total time=   0.1s\n",
      "[CV 10/20; 34/36] START learning_rate=0.5, max_depth=7, n_estimators=5..........\n",
      "[CV 10/20; 34/36] END learning_rate=0.5, max_depth=7, n_estimators=5;, score=0.741 total time=   0.1s\n",
      "[CV 11/20; 34/36] START learning_rate=0.5, max_depth=7, n_estimators=5..........\n",
      "[CV 11/20; 34/36] END learning_rate=0.5, max_depth=7, n_estimators=5;, score=0.747 total time=   0.1s\n",
      "[CV 12/20; 34/36] START learning_rate=0.5, max_depth=7, n_estimators=5..........\n",
      "[CV 12/20; 34/36] END learning_rate=0.5, max_depth=7, n_estimators=5;, score=0.746 total time=   0.1s\n",
      "[CV 13/20; 34/36] START learning_rate=0.5, max_depth=7, n_estimators=5..........\n",
      "[CV 13/20; 34/36] END learning_rate=0.5, max_depth=7, n_estimators=5;, score=0.750 total time=   0.1s\n",
      "[CV 14/20; 34/36] START learning_rate=0.5, max_depth=7, n_estimators=5..........\n",
      "[CV 14/20; 34/36] END learning_rate=0.5, max_depth=7, n_estimators=5;, score=0.748 total time=   0.1s\n",
      "[CV 15/20; 34/36] START learning_rate=0.5, max_depth=7, n_estimators=5..........\n",
      "[CV 15/20; 34/36] END learning_rate=0.5, max_depth=7, n_estimators=5;, score=0.749 total time=   0.1s\n",
      "[CV 16/20; 34/36] START learning_rate=0.5, max_depth=7, n_estimators=5..........\n",
      "[CV 16/20; 34/36] END learning_rate=0.5, max_depth=7, n_estimators=5;, score=0.749 total time=   0.1s\n",
      "[CV 17/20; 34/36] START learning_rate=0.5, max_depth=7, n_estimators=5..........\n",
      "[CV 17/20; 34/36] END learning_rate=0.5, max_depth=7, n_estimators=5;, score=0.750 total time=   0.1s\n",
      "[CV 18/20; 34/36] START learning_rate=0.5, max_depth=7, n_estimators=5..........\n",
      "[CV 18/20; 34/36] END learning_rate=0.5, max_depth=7, n_estimators=5;, score=0.747 total time=   0.1s\n",
      "[CV 19/20; 34/36] START learning_rate=0.5, max_depth=7, n_estimators=5..........\n",
      "[CV 19/20; 34/36] END learning_rate=0.5, max_depth=7, n_estimators=5;, score=0.743 total time=   0.1s\n",
      "[CV 20/20; 34/36] START learning_rate=0.5, max_depth=7, n_estimators=5..........\n",
      "[CV 20/20; 34/36] END learning_rate=0.5, max_depth=7, n_estimators=5;, score=0.748 total time=   0.1s\n",
      "[CV 1/20; 35/36] START learning_rate=0.5, max_depth=7, n_estimators=50..........\n",
      "[CV 1/20; 35/36] END learning_rate=0.5, max_depth=7, n_estimators=50;, score=0.749 total time=   0.8s\n",
      "[CV 2/20; 35/36] START learning_rate=0.5, max_depth=7, n_estimators=50..........\n",
      "[CV 2/20; 35/36] END learning_rate=0.5, max_depth=7, n_estimators=50;, score=0.746 total time=   0.8s\n",
      "[CV 3/20; 35/36] START learning_rate=0.5, max_depth=7, n_estimators=50..........\n",
      "[CV 3/20; 35/36] END learning_rate=0.5, max_depth=7, n_estimators=50;, score=0.750 total time=   0.8s\n",
      "[CV 4/20; 35/36] START learning_rate=0.5, max_depth=7, n_estimators=50..........\n",
      "[CV 4/20; 35/36] END learning_rate=0.5, max_depth=7, n_estimators=50;, score=0.748 total time=   0.8s\n",
      "[CV 5/20; 35/36] START learning_rate=0.5, max_depth=7, n_estimators=50..........\n",
      "[CV 5/20; 35/36] END learning_rate=0.5, max_depth=7, n_estimators=50;, score=0.748 total time=   0.8s\n",
      "[CV 6/20; 35/36] START learning_rate=0.5, max_depth=7, n_estimators=50..........\n",
      "[CV 6/20; 35/36] END learning_rate=0.5, max_depth=7, n_estimators=50;, score=0.750 total time=   0.8s\n",
      "[CV 7/20; 35/36] START learning_rate=0.5, max_depth=7, n_estimators=50..........\n",
      "[CV 7/20; 35/36] END learning_rate=0.5, max_depth=7, n_estimators=50;, score=0.747 total time=   0.8s\n",
      "[CV 8/20; 35/36] START learning_rate=0.5, max_depth=7, n_estimators=50..........\n",
      "[CV 8/20; 35/36] END learning_rate=0.5, max_depth=7, n_estimators=50;, score=0.754 total time=   0.8s\n",
      "[CV 9/20; 35/36] START learning_rate=0.5, max_depth=7, n_estimators=50..........\n",
      "[CV 9/20; 35/36] END learning_rate=0.5, max_depth=7, n_estimators=50;, score=0.748 total time=   0.9s\n",
      "[CV 10/20; 35/36] START learning_rate=0.5, max_depth=7, n_estimators=50.........\n",
      "[CV 10/20; 35/36] END learning_rate=0.5, max_depth=7, n_estimators=50;, score=0.741 total time=   0.8s\n",
      "[CV 11/20; 35/36] START learning_rate=0.5, max_depth=7, n_estimators=50.........\n",
      "[CV 11/20; 35/36] END learning_rate=0.5, max_depth=7, n_estimators=50;, score=0.747 total time=   0.8s\n",
      "[CV 12/20; 35/36] START learning_rate=0.5, max_depth=7, n_estimators=50.........\n",
      "[CV 12/20; 35/36] END learning_rate=0.5, max_depth=7, n_estimators=50;, score=0.746 total time=   0.8s\n",
      "[CV 13/20; 35/36] START learning_rate=0.5, max_depth=7, n_estimators=50.........\n",
      "[CV 13/20; 35/36] END learning_rate=0.5, max_depth=7, n_estimators=50;, score=0.750 total time=   0.8s\n",
      "[CV 14/20; 35/36] START learning_rate=0.5, max_depth=7, n_estimators=50.........\n",
      "[CV 14/20; 35/36] END learning_rate=0.5, max_depth=7, n_estimators=50;, score=0.748 total time=   0.9s\n",
      "[CV 15/20; 35/36] START learning_rate=0.5, max_depth=7, n_estimators=50.........\n",
      "[CV 15/20; 35/36] END learning_rate=0.5, max_depth=7, n_estimators=50;, score=0.750 total time=   0.8s\n",
      "[CV 16/20; 35/36] START learning_rate=0.5, max_depth=7, n_estimators=50.........\n",
      "[CV 16/20; 35/36] END learning_rate=0.5, max_depth=7, n_estimators=50;, score=0.749 total time=   0.8s\n",
      "[CV 17/20; 35/36] START learning_rate=0.5, max_depth=7, n_estimators=50.........\n",
      "[CV 17/20; 35/36] END learning_rate=0.5, max_depth=7, n_estimators=50;, score=0.750 total time=   0.8s\n",
      "[CV 18/20; 35/36] START learning_rate=0.5, max_depth=7, n_estimators=50.........\n",
      "[CV 18/20; 35/36] END learning_rate=0.5, max_depth=7, n_estimators=50;, score=0.747 total time=   0.8s\n",
      "[CV 19/20; 35/36] START learning_rate=0.5, max_depth=7, n_estimators=50.........\n",
      "[CV 19/20; 35/36] END learning_rate=0.5, max_depth=7, n_estimators=50;, score=0.743 total time=   0.8s\n",
      "[CV 20/20; 35/36] START learning_rate=0.5, max_depth=7, n_estimators=50.........\n",
      "[CV 20/20; 35/36] END learning_rate=0.5, max_depth=7, n_estimators=50;, score=0.748 total time=   0.8s\n",
      "[CV 1/20; 36/36] START learning_rate=0.5, max_depth=7, n_estimators=120.........\n",
      "[CV 1/20; 36/36] END learning_rate=0.5, max_depth=7, n_estimators=120;, score=0.749 total time=   2.0s\n",
      "[CV 2/20; 36/36] START learning_rate=0.5, max_depth=7, n_estimators=120.........\n",
      "[CV 2/20; 36/36] END learning_rate=0.5, max_depth=7, n_estimators=120;, score=0.746 total time=   2.0s\n",
      "[CV 3/20; 36/36] START learning_rate=0.5, max_depth=7, n_estimators=120.........\n",
      "[CV 3/20; 36/36] END learning_rate=0.5, max_depth=7, n_estimators=120;, score=0.750 total time=   2.0s\n",
      "[CV 4/20; 36/36] START learning_rate=0.5, max_depth=7, n_estimators=120.........\n",
      "[CV 4/20; 36/36] END learning_rate=0.5, max_depth=7, n_estimators=120;, score=0.748 total time=   2.0s\n",
      "[CV 5/20; 36/36] START learning_rate=0.5, max_depth=7, n_estimators=120.........\n",
      "[CV 5/20; 36/36] END learning_rate=0.5, max_depth=7, n_estimators=120;, score=0.748 total time=   2.0s\n",
      "[CV 6/20; 36/36] START learning_rate=0.5, max_depth=7, n_estimators=120.........\n",
      "[CV 6/20; 36/36] END learning_rate=0.5, max_depth=7, n_estimators=120;, score=0.750 total time=   2.0s\n",
      "[CV 7/20; 36/36] START learning_rate=0.5, max_depth=7, n_estimators=120.........\n",
      "[CV 7/20; 36/36] END learning_rate=0.5, max_depth=7, n_estimators=120;, score=0.747 total time=   2.0s\n",
      "[CV 8/20; 36/36] START learning_rate=0.5, max_depth=7, n_estimators=120.........\n",
      "[CV 8/20; 36/36] END learning_rate=0.5, max_depth=7, n_estimators=120;, score=0.754 total time=   2.0s\n",
      "[CV 9/20; 36/36] START learning_rate=0.5, max_depth=7, n_estimators=120.........\n",
      "[CV 9/20; 36/36] END learning_rate=0.5, max_depth=7, n_estimators=120;, score=0.748 total time=   2.0s\n",
      "[CV 10/20; 36/36] START learning_rate=0.5, max_depth=7, n_estimators=120........\n",
      "[CV 10/20; 36/36] END learning_rate=0.5, max_depth=7, n_estimators=120;, score=0.741 total time=   1.9s\n",
      "[CV 11/20; 36/36] START learning_rate=0.5, max_depth=7, n_estimators=120........\n",
      "[CV 11/20; 36/36] END learning_rate=0.5, max_depth=7, n_estimators=120;, score=0.747 total time=   2.0s\n",
      "[CV 12/20; 36/36] START learning_rate=0.5, max_depth=7, n_estimators=120........\n",
      "[CV 12/20; 36/36] END learning_rate=0.5, max_depth=7, n_estimators=120;, score=0.746 total time=   1.9s\n",
      "[CV 13/20; 36/36] START learning_rate=0.5, max_depth=7, n_estimators=120........\n",
      "[CV 13/20; 36/36] END learning_rate=0.5, max_depth=7, n_estimators=120;, score=0.750 total time=   2.0s\n",
      "[CV 14/20; 36/36] START learning_rate=0.5, max_depth=7, n_estimators=120........\n",
      "[CV 14/20; 36/36] END learning_rate=0.5, max_depth=7, n_estimators=120;, score=0.748 total time=   1.9s\n",
      "[CV 15/20; 36/36] START learning_rate=0.5, max_depth=7, n_estimators=120........\n",
      "[CV 15/20; 36/36] END learning_rate=0.5, max_depth=7, n_estimators=120;, score=0.750 total time=   2.0s\n",
      "[CV 16/20; 36/36] START learning_rate=0.5, max_depth=7, n_estimators=120........\n",
      "[CV 16/20; 36/36] END learning_rate=0.5, max_depth=7, n_estimators=120;, score=0.749 total time=   2.0s\n",
      "[CV 17/20; 36/36] START learning_rate=0.5, max_depth=7, n_estimators=120........\n",
      "[CV 17/20; 36/36] END learning_rate=0.5, max_depth=7, n_estimators=120;, score=0.750 total time=   2.0s\n",
      "[CV 18/20; 36/36] START learning_rate=0.5, max_depth=7, n_estimators=120........\n",
      "[CV 18/20; 36/36] END learning_rate=0.5, max_depth=7, n_estimators=120;, score=0.747 total time=   1.9s\n",
      "[CV 19/20; 36/36] START learning_rate=0.5, max_depth=7, n_estimators=120........\n",
      "[CV 19/20; 36/36] END learning_rate=0.5, max_depth=7, n_estimators=120;, score=0.743 total time=   1.9s\n",
      "[CV 20/20; 36/36] START learning_rate=0.5, max_depth=7, n_estimators=120........\n",
      "[CV 20/20; 36/36] END learning_rate=0.5, max_depth=7, n_estimators=120;, score=0.748 total time=   1.9s\n",
      "Best cross-validation score: 0.7483518651660905\n",
      "Best parameters: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 5}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'XGBClassifier' object has no attribute 'grid_scores_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mBest parameters: \u001b[39m\u001b[39m{\u001b[39;00mgrid\u001b[39m.\u001b[39mbest_params_\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[39m#trust your CV!\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m best_parameters, score, _ \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(xgb_model\u001b[39m.\u001b[39;49mgrid_scores_, key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: x[\u001b[39m1\u001b[39m])\n\u001b[0;32m     21\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mF1:\u001b[39m\u001b[39m'\u001b[39m, score)\n\u001b[0;32m     22\u001b[0m \u001b[39mfor\u001b[39;00m param_name \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(best_parameters\u001b[39m.\u001b[39mkeys()):\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'XGBClassifier' object has no attribute 'grid_scores_'"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/code/phunter/xgboost-with-gridsearchcv\n",
    "# https://blog.dataiku.com/narrowing-the-search-which-hyperparameters-really-matter\n",
    "param_grid = {'learning_rate': [0.1, 0.3, 0.5],\n",
    "                'max_depth': [3, 5, 6, 7],\n",
    "                'n_estimators': [5, 50, 120]\n",
    "}\n",
    "xgb_model = xgb.XGBClassifier(  nthread=4, \n",
    "                                objective='binary:logistic', \n",
    "                                min_child_weight=1, \n",
    "                                subsample=0.8, \n",
    "                                tree_method=\"gpu_hist\", \n",
    "                                verbosity=1, \n",
    "                                seed=77)\n",
    "grid = GridSearchCV(xgb_model, param_grid, cv=cv, scoring='f1', verbose=10)\n",
    "grid.fit(X_train, y_train)\n",
    "print(f'Best cross-validation score: {grid.best_score_}')\n",
    "print(f'Best parameters: {grid.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7494237734606519\n",
      "XGBoost F1 score: 75%\n"
     ]
    }
   ],
   "source": [
    "# Predicting on the test set\n",
    "X_test = vect_fitted.transform(X_test_text)\n",
    "score_F1 = grid.score(X_test, y_test)  \n",
    "round_score_F1 = int(round(score_F1, 2)*100)\n",
    "print(score_F1)\n",
    "print(f'XGBoost F1 score: {round_score_F1}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_load_obj(grid, rf'6th run - XGBoost\\XGB-lr-01-md-3-nest-5-F1-{round_score_F1}%.pkl', mode='save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision, Recall, F1: (0.6158008658008658, 0.9571068124474348, 0.7494237734606519)\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.predict(X_test)\n",
    "prf1 = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
    "print(f'Precision, Recall, F1: {prf1[:3]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We see, that precision is not that good, but recall is good. We can try to move the treshhold to see if we can get better results.  \n",
    "Let's go back to the best results with LogisticRegression and see our presicion and recall."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moving Threshold for besst LogisticRegression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: <24019x10130 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 242922 stored elements in Compressed Sparse Row format>\n",
      "GridSearchCV(cv=RepeatedStratifiedKFold(n_repeats=4, n_splits=5, random_state=777),\n",
      "             estimator=LogisticRegression(max_iter=500, n_jobs=-1),\n",
      "             param_grid={'C': [0.01, 0.1, 1, 10, 100, 1000]}, scoring='f1')\n",
      "{'C': 1}\n"
     ]
    }
   ],
   "source": [
    "# Loading saved objects from the previous run\n",
    "first_run_lg = save_load_obj('', r'1st run\\LogReg-C-1-max_iter-500-F1-85%.pkl', mode='load')\n",
    "X_train = save_load_obj('', r'1st run\\X_train-transformed.pkl', mode='load')\n",
    "vect_fitted = save_load_obj('', r'1st run\\TfidfVect-X_train-fit-mindf-5-maxdf-02-ngram-2.pkl', mode='load')\n",
    "print(f'X_train: {repr(X_train)}')\n",
    "print(first_run_lg)\n",
    "print(first_run_lg.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Glance on our Precision and Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision, Recall, F1: (0.8168536394469085, 0.8777684328567423, 0.8462162162162162)\n"
     ]
    }
   ],
   "source": [
    "y_pred = first_run_lg.predict(X_test)\n",
    "prf1 = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
    "print(f'Precision, Recall, F1: {prf1[:3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot confusion matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "def plot_confusion_matrix(y_test, y_pred, model):\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=model.classes_)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Other', 'Business Tweet'])\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred, first_run_lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive Business tweets: 302\n",
      "False Positive Business tweets: 3265\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred, labels=first_run_lg.classes_)\n",
    "TP_biz_tweets = cm[1][1]\n",
    "FP_biz_tweets = cm[1][0]\n",
    "print(f'True Positive Business tweets: {TP_biz_tweets}')\n",
    "print(f'False Positive Business tweets: {FP_biz_tweets}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now let's move our treshhold and see how far we can optimize for Precision (We need our model to be as precise as possible, as we don't want to make many classifications as \"Business\" when they are not, to make customer experience better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Treshold</th>\n",
       "      <th>Biz Tweet ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.816854</td>\n",
       "      <td>0.877768</td>\n",
       "      <td>0.846216</td>\n",
       "      <td>0.50</td>\n",
       "      <td>7.181193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.837559</td>\n",
       "      <td>0.842725</td>\n",
       "      <td>0.840134</td>\n",
       "      <td>0.55</td>\n",
       "      <td>5.358289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.860012</td>\n",
       "      <td>0.792262</td>\n",
       "      <td>0.824748</td>\n",
       "      <td>0.60</td>\n",
       "      <td>3.813765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.888024</td>\n",
       "      <td>0.735913</td>\n",
       "      <td>0.804844</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2.786624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.909196</td>\n",
       "      <td>0.662461</td>\n",
       "      <td>0.766461</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.962625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.927770</td>\n",
       "      <td>0.579759</td>\n",
       "      <td>0.713596</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.379586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.481357</td>\n",
       "      <td>0.637697</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.928108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.954032</td>\n",
       "      <td>0.354920</td>\n",
       "      <td>0.517368</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.550196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.968009</td>\n",
       "      <td>0.229044</td>\n",
       "      <td>0.370438</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.297091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.980519</td>\n",
       "      <td>0.084665</td>\n",
       "      <td>0.155871</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.092496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Precision    Recall        F1  Treshold  Biz Tweet ratio\n",
       "0   0.816854  0.877768  0.846216      0.50         7.181193\n",
       "1   0.837559  0.842725  0.840134      0.55         5.358289\n",
       "2   0.860012  0.792262  0.824748      0.60         3.813765\n",
       "3   0.888024  0.735913  0.804844      0.65         2.786624\n",
       "4   0.909196  0.662461  0.766461      0.70         1.962625\n",
       "5   0.927770  0.579759  0.713596      0.75         1.379586\n",
       "6   0.944444  0.481357  0.637697      0.80         0.928108\n",
       "7   0.954032  0.354920  0.517368      0.85         0.550196\n",
       "8   0.968009  0.229044  0.370438      0.90         0.297091\n",
       "9   0.980519  0.084665  0.155871      0.95         0.092496"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['Precision', 'Recall', 'F1', 'Treshold'])\n",
    "for treshold in np.arange(0.5, 1, 0.05):\n",
    "    y_pred = (first_run_lg.predict_proba(X_test)[:, 1] >= treshold).astype(int)\n",
    "    prf1 = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=first_run_lg.classes_)\n",
    "    TP_biz_tweets = cm[1][1]\n",
    "    FP_biz_tweets = cm[1][0]\n",
    "    tru_biz_to_false_biz = TP_biz_tweets / FP_biz_tweets\n",
    "    # build a dataframe with Precision, Recall, F1, Treshold\n",
    "    data = {'Precision': prf1[0], 'Recall': prf1[1], 'F1': prf1[2], 'Treshold': treshold, 'Biz Tweet ratio': tru_biz_to_false_biz}\n",
    "    df = pd.concat([df, pd.DataFrame(data, index=[0])], ignore_index=True)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Looking on the table we can arbitrarily say we want our model to do 1:1 ratio of Correct Business to Incorrect Business classifications. Just not to waste data to much.   \n",
    "So, we can set our treshhold to 0.8 and get 0.94 precision and 0.63 recall.  \n",
    "let's run a model on this parameters and see what we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAGwCAYAAAAHVnkYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABY60lEQVR4nO3deVxUVf8H8M9lmWGdQVQYUESUVCz3epB6FHwywcwybTEt8XHLAhd8NLNScaVHc83S0pR6wrRNyyUVN9AktyLXSBFFE9BERVC2mfP7gx9XR3FknLkOjp/363Veee8999zvpQG+nHPuuZIQQoCIiIiIbMbB1gEQERERPeiYkBERERHZGBMyIiIiIhtjQkZERERkY0zIiIiIiGyMCRkRERGRjTEhIyIiIrIxJ1sHQPc3g8GAs2fPwtPTE5Ik2TocIiIygxACV65cgb+/PxwclOujKS4uRmlpqVXaUqlUcHFxsUpbNQkTMrLI2bNnERAQYOswiIjIAqdPn0b9+vUVabu4uBhBgR7IPae3Sns6nQ5ZWVl2l5QxISOLeHp6AgBO/doQGg+OgJN9er5JC1uHQKSIcpRhJ9bLP8uVUFpaitxzepza3xAaT8t+TxRcMSCw3UmUlpYyISO6UeUwpcbDweJvNKKayklytnUIRMr4/5cn3ospJx6eEjw8LbuOAfY7NYYJGRERESlOLwzQW/j2bL0wWCeYGogJGRERESnOAAEDLMvILD2/JuMYExEREZGNsYeMiIiIFGeAAZYOOFreQs3FhIyIiIgUpxcCemHZkKOl59dkHLIkIiIisjH2kBEREZHiOKnfNCZkREREpDgDBPRMyG6LQ5ZERERkdxISEvDYY4/B09MTPj4+6NGjBzIyMuTj+fn5GDZsGJo2bQpXV1c0aNAAw4cPx+XLl43akSTplrJixQqjOtu3b0fbtm2hVqsRHByMxMREs+NlQkZERESKqxyytLRUV0pKCmJiYvDLL78gOTkZZWVl6NKlC4qKigBUvIv57Nmz+OCDD3Do0CEkJiZiw4YNGDhw4C1tLVu2DDk5OXLp0aOHfCwrKwvdunVDp06dkJ6ejpEjR2LQoEHYuHGjWV8fDlkSERGR4u71U5YbNmww2k5MTISPjw/279+Pjh074pFHHsF3330nH2/cuDGmTZuGV199FeXl5XByup4ieXl5QafTVXmdRYsWISgoCLNmzQIAhISEYOfOnZgzZw4iIyOrHS97yIiIiOi+UlBQYFRKSkrueE7lUKS3t7fJOhqNxigZA4CYmBjUqVMH//jHP7B06VKIGxLDtLQ0dO7c2ah+ZGQk0tLSzLklJmRERESkPIOVCgAEBARAq9XKJSEhwfS1DQaMHDkSTzzxBB555JEq6/z999+YMmUKhgwZYrR/8uTJ+Prrr5GcnIxevXrhzTffxIcffigfz83Nha+vr9E5vr6+KCgowLVr1+74danEIUsiIiJSnN4KT1lWnn/69GloNBp5v1qtNnleTEwMDh06hJ07d1Z5vKCgAN26dUPz5s0RHx9vdGz8+PHyv9u0aYOioiLMnDkTw4cPv8u7qBp7yIiIiEhxemGdAgAajcaomErIYmNjsXbtWmzbtg3169e/5fiVK1cQFRUFT09PrFq1Cs7OzibvIzQ0FGfOnJGHSXU6HfLy8ozq5OXlQaPRwNXVtdpfHyZkREREZHeEEIiNjcWqVauwdetWBAUF3VKnoKAAXbp0gUqlwo8//ggXF5c7tpueno5atWrJSWBYWBi2bNliVCc5ORlhYWFmxcshSyIiIlLcjXPALGmjumJiYrB8+XL88MMP8PT0RG5uLgBAq9XC1dVVTsauXr2KL7/8Un5AAADq1q0LR0dHrFmzBnl5eWjfvj1cXFyQnJyM6dOnY/To0fJ1hg4digULFuCtt97CgAEDsHXrVnz99ddYt26dWffGhIyIiIgUZ4AEPSSL26iuhQsXAgAiIiKM9i9btgz9+/fHr7/+it27dwMAgoODjepkZWWhYcOGcHZ2xkcffYS4uDgIIRAcHIzZs2dj8ODBct2goCCsW7cOcXFxmDdvHurXr48lS5aYteQFwISMiIiI7JC4w5plERERd6wTFRWFqKioO14rIiICv/32m1nx3YwJGRERESnOICqKpW3YKyZkREREpDi9FYYsLT2/JuNTlkREREQ2xh4yIiIiUhx7yExjQkZERESKMwgJBmHhU5YWnl+TcciSiIiIyMbYQ0ZERESK45ClaUzIiIiISHF6OEBv4cCc3kqx1ERMyIiIiEhxwgpzyATnkBERERGRUthDRkRERIrjHDLTmJARERGR4vTCAXph4RwyO351EocsiYiIiGyMPWRERESkOAMkGCzsBzLAfrvImJARERGR4jiHzDQOWRIRERHZGHvIiIiISHHWmdTPIUsiIiKiu1Yxh8zCl4tzyJKIiIiIlMIeMiIiIlKcwQrvsuRTlkREREQW4Bwy05iQERERkeIMcOA6ZCZwDhkRERGRjbGHjIiIiBSnFxL0wsKFYS08vyZjQkZERESK01thUr+eQ5ZEREREpBT2kBEREZHiDMIBBgufsjTwKUsiIiKiu8chS9M4ZElERERkY+whIyIiIsUZYPlTkgbrhFIjsYeMiIiIFFe5MKylpboSEhLw2GOPwdPTEz4+PujRowcyMjKM6hQXFyMmJga1a9eGh4cHevXqhby8PKM62dnZ6NatG9zc3ODj44MxY8agvLzcqM727dvRtm1bqNVqBAcHIzEx0eyvDxMyIiIisjspKSmIiYnBL7/8guTkZJSVlaFLly4oKiqS68TFxWHNmjX45ptvkJKSgrNnz6Jnz57ycb1ej27duqG0tBS7du3C559/jsTEREyYMEGuk5WVhW7duqFTp05IT0/HyJEjMWjQIGzcuNGseCUh7PiRBVJcQUEBtFotLv7ZCBpP5vdknyL9W9s6BCJFlIsybMcPuHz5MjQajSLXqPw9sWB/KFw9LJspda2wHLHtdt9VvOfPn4ePjw9SUlLQsWNHXL58GXXr1sXy5cvxwgsvAAD++OMPhISEIC0tDe3bt8dPP/2EZ555BmfPnoWvry8AYNGiRRg7dizOnz8PlUqFsWPHYt26dTh06JB8rd69e+PSpUvYsGFDtePjb1AiIiJSnAGSVQpQkeTdWEpKSu54/cuXLwMAvL29AQD79+9HWVkZOnfuLNdp1qwZGjRogLS0NABAWloaWrRoISdjABAZGYmCggIcPnxYrnNjG5V1KtuoLiZkREREpDi9cLBKAYCAgABotVq5JCQkmLy2wWDAyJEj8cQTT+CRRx4BAOTm5kKlUsHLy8uorq+vL3Jzc+U6NyZjlccrj5mqU1BQgGvXrlX768OnLImIiOi+cvr0aaMhS7VabbJ+TEwMDh06hJ07dyod2l1jQkZERESKs87CsBXnazSaas8hi42Nxdq1a5Gamor69evL+3U6HUpLS3Hp0iWjXrK8vDzodDq5zp49e4zaq3wK88Y6Nz+ZmZeXB41GA1dX12rfG4csiYiISHEGIVmlVJcQArGxsVi1ahW2bt2KoKAgo+Pt2rWDs7MztmzZIu/LyMhAdnY2wsLCAABhYWE4ePAgzp07J9dJTk6GRqNB8+bN5To3tlFZp7KN6mIPGREREdmdmJgYLF++HD/88AM8PT3lOV9arRaurq7QarUYOHAgRo0aBW9vb2g0GgwbNgxhYWFo3749AKBLly5o3rw5XnvtNcyYMQO5ubl47733EBMTIw+TDh06FAsWLMBbb72FAQMGYOvWrfj666+xbt06s+JlQkZERESKM1hhyNKchWEXLlwIAIiIiDDav2zZMvTv3x8AMGfOHDg4OKBXr14oKSlBZGQkPv74Y7muo6Mj1q5dizfeeANhYWFwd3dHdHQ0Jk+eLNcJCgrCunXrEBcXh3nz5qF+/fpYsmQJIiMjzbo3rkNGFuE6ZPQg4DpkZK/u5Tpk0/d0gouF65AVF5bjnX9sUzReW+FvUCIiIiIb45AlERERKU4PCXpY9nJxS8+vyZiQERERkeIMwgEGYeEcMgvPr8ns986IiIiI7hPsISMiIiLF6WH5kKPeOqHUSEzIiIiISHEcsjSNCRkREREp7saXg1vShr2y3zsjIiIiuk+wh4yIiIgUJyDBYOEcMsFlL4iIiIjuHocsTbPfOyMiIiK6T7CHjIiIiBRnEBIMwrIhR0vPr8mYkBEREZHi9HCA3sKBOUvPr8ns986IiIiI7hPsISMiIiLFccjSNCZkREREpDgDHGCwcGDO0vNrMvu9MyIiIqL7BHvIiIiISHF6IUFv4ZCjpefXZEzIiIiISHGcQ2YaEzIiIiJSnBAOMFi40r7gSv1EREREpBT2kBEREZHi9JCgt/Dl4JaeX5MxISMiIiLFGYTlc8AMwkrB1EAcsiQiIiKyMfaQEd1jKz70wc/rvXD6uBoqFwOaP3oVA989i4DgErnOvLfq47cdnriQ5wxXNwNCHi3CwHfPosFDFXUK8h3xfmwgso664spFR2hrlyMs8jL+PS4H7p4GAMAHIxsg+WvvW67foMk1LN6ecW9ulgjAI6GFePHN83ioxVXU1pUjfkBDpG3Q3lBDoN+YPET1uQAPjR5H9rlj/tv1cTZLLdd4ZXge/tG5AI0evobyUgm9Qlrc+xshixisMKnf0vNrMvu9swdEYmIivLy8bB0GmeFAmge69/8bc9ceQ8KKTOjLgXdeaYziq9e/HR9qeQ3/mZONxSl/YNryTEBU1NHrK45LDkBY5GVMSjyBz3Yexei52fhthyfmjw2Q23hj8hl8lX5ILl/uOwzPWuXo+Mzle33L9IBzcTPgxGEXLHinfpXHX4o5j+cGnMeHb9fHiGceQvFVB0xffgLOaoNcx0klkLrGC+s+r3OvwiYrM0CySrFXTMhqiNOnT2PAgAHw9/eHSqVCYGAgRowYgQsXLsh1GjZsiLlz59ouSLKK6ctPoMvL+WjYtBiNHy7Gf+Zm49xfKhw74CrXefrVC2jRvgi6gFI81PIaosfm4PxZFfJOqwAAnl56dI++gCatrsG3fhnadChE9+i/cWi3u9yGu8YAb59yuRz73Q2FlxzRpfeFW2IiUtK+bRp8PsMPu4x6xSoJ9Bh0Hl/N80XaRi2yjrpixvAGqO1bhsejrv/x8L8PdFi1uC6y/nC5d4ET3UNMyGqAEydO4NFHH8WxY8fw1Vdf4fjx41i0aBG2bNmCsLAw5Ofn3/OYysrK7vk1H1RFBY4AKpKsqhRfdcCmld7QNShBXf+q/79cyHXCzz95oWVY4W2vs+Erb7TpcAW+9fn/lmoOXYNS1PYtx687POV9V6844o/f3BDS7qoNIyNrq1yp39Jir5iQ1QAxMTFQqVTYtGkTwsPD0aBBA3Tt2hWbN2/GX3/9hXfffRcRERE4deoU4uLiIEkSJMn4Q7lx40aEhITAw8MDUVFRyMnJMTq+ZMkShISEwMXFBc2aNcPHH38sHzt58iQkScLKlSsRHh4OFxcXJCUl3ZN7f9AZDMCiifXw8GOFaNis2OjYmsTaeC64BZ4Lbom9WzVIWJEJZ5XxI0YJbwTi2UYt0aftI3Dz0CPug9NVXudCrhP2btMgqs+9T+6JTPH2KQcAXDpvPKX50nknePvwjwd7UjmHzNJir+z3zu4T+fn52LhxI9588024uroaHdPpdOjbty9WrlyJ7777DvXr18fkyZORk5NjlHBdvXoVH3zwAf73v/8hNTUV2dnZGD16tHw8KSkJEyZMwLRp03D06FFMnz4d48ePx+eff250vbfffhsjRozA0aNHERkZWWW8JSUlKCgoMCp09xa8Ux+n/nDFuIWnbjn2r54X8fGmDHzw/THUb1SCaa83RGmxcSL++qS/sGBjBuKXncDZUyp8MqlelddJ/sYbHhq90RAQERHVHHzK0saOHTsGIQRCQkKqPB4SEoKLFy9Cr9fD0dERnp6e0Ol0RnXKysqwaNEiNG7cGAAQGxuLyZMny8cnTpyIWbNmoWfPngCAoKAgHDlyBJ988gmio6PleiNHjpTr3E5CQgImTZp0V/dKxha8Uw+7kzWYtep4lUOR7hoD3DWlqNeoFM3ankSvkEfw809adHr+klyncn5Yg4dK4Omlx3+efwh9Ruaitm+5XEcIYOOK2njyhfxbetiIbC3/XMWvIa+65cg/5yzv96pbjszDrrc7je5DBljhXZac1E9KE+Luf1G6ubnJyRgA+Pn54dy5cwCAoqIiZGZmYuDAgfDw8JDL1KlTkZmZadTOo48+esdrjRs3DpcvX5bL6dNVD5HR7QlRkYzt2qDFjG+OQ9egtFrnQEgoK739t2zlR+jmOgfSPHA2S42oVzhcSTVPbrYKF/Kc0OafV+R9bh56NGtzFUf3u9kwMrI2YYUnLIWZCVlqaiq6d+8Of39/SJKE1atXGx2vnAJ0c5k5c6Zcp2HDhrccf//9943aOXDgADp06AAXFxcEBARgxowZZn992ENmY8HBwZAkCUePHsXzzz9/y/GjR4+iVq1aqFu37m3bcHZ2NtqWJElO8AoLKyZ5L168GKGhoUb1HB0djbbd3d1xJ2q1Gmq1+o716PYWvFMf21bVQvyyE3D1MMg9BO6eeqhdBXJOqZDyoxfahV+B1rsc53Oc8fUCX6hcDfjHkxVDxHu2eOLieWc0bX0VLu4GnMpwwZIp/nj4sULoAowTvI1feaNZ26Jb5qgR3Ssubnr4B13/XOoCStHo4Wu4cskR5/9SYfWSunhlxDn8laVGbrYK0W/l4kKes9FTmXXrlcLTSw+feqVwcAQaPXwNAHA2S4Xiq463XJNqHoOwQg+ZmecXFRWhVatWGDBgQJUjQDfPt/7pp58wcOBA9OrVy2j/5MmTMXjwYHnb0/P6QygFBQXo0qULOnfujEWLFuHgwYMYMGAAvLy8MGTIkGrHyoTMxmrXro2nnnoKH3/8MeLi4ozmkeXm5iIpKQn9+vWDJElQqVTQ66t+Eu92fH194e/vjxMnTqBv377WDp/uwtr/X0dpTK+HjPb/Z042urycD5XagEO7PbBqcV0UXnaEV51ytGhfiDk/HINXnYqhSJWLwE9JtfFJfD2UlUqo61+KJ7pexsux54zaLCpwwM51Xhg65cy9uTmiKjRpdQ0zv7veIz900lkAwKaVtTArrgG+/qguXNwMGDHjDDw0ehze6453+zZCWcn13t5+o3PR5eWL8vbC5D8BAGN6NcaBNI97dCdUU9w8f/l2nQVdu3ZF165db9vOzVOAfvjhB3Tq1AmNGjUy2l/VdKFKSUlJKC0txdKlS6FSqfDwww8jPT0ds2fPZkJ2v1mwYAEef/xxREZGYurUqQgKCsLhw4cxZswY1KtXD9OmTQNQ0W2ampqK3r17Q61Wo06d6i2QOGnSJAwfPhxarRZRUVEoKSnBvn37cPHiRYwaNUrJW6MqbDybbvJ4bV05pn55wmSd1k8UYu6aY3e8lrvGgB9PHDAnPCKrO5DmgUj/ViZqSPhipg5fzKz6Fx4AzIprgFlxDawfHN0z1lypPyAgwGj/xIkTER8fb1HbeXl5WLdu3S0PvAHA+++/jylTpqBBgwbo06cP4uLi4ORUkUKlpaWhY8eOUKlUcv3IyEj897//xcWLF1GrVq1qXZ8JWQ3w0EMPYd++fZg4cSJeeukl5OfnQ6fToUePHpg4cSK8vStefzN58mS8/vrraNy4MUpKSqo972zQoEFwc3PDzJkzMWbMGLi7u6NFixYYOXKkgndFRER0nTWHLE+fPg2NRiPvt8ZUms8//xyenp63DG0OHz4cbdu2hbe3N3bt2oVx48YhJycHs2fPBlAxmhUUFGR0jq+vr3yMCdl9JjAwEImJiSbrtG/fHr///rvRvv79+6N///5G+3r06HFLstanTx/06dOnynYbNmxo0UMFRERE95JGozFKyKxh6dKl6Nu3L1xcjN8GceNIUsuWLaFSqfD6668jISHBqnOq+ZQlERERKa4mv8tyx44dyMjIwKBBg+5YNzQ0FOXl5Th58iSAinloeXl5RnUqt28376wqTMiIiIhIcZVDlpYWJXz22Wdo164dWrUyNdexQnp6OhwcHODj4wMACAsLQ2pqqtErB5OTk9G0adNqD1cCTMiIiIjIThUWFiI9PR3p6ekAgKysLKSnpyM7O1uuU1BQgG+++abK3rG0tDTMnTsXv//+O06cOIGkpCTExcXh1VdflZOtPn36QKVSYeDAgTh8+DBWrlyJefPmmf3QHOeQERERkeJssQ7Zvn370KlTJ3m7MkmKjo6W522vWLECQgi88sort5yvVquxYsUKxMfHo6SkBEFBQYiLizNKtrRaLTZt2oSYmBi0a9cOderUwYQJE8xa8gIAJMHZ3GSBgoICaLVaXPyzETSe7HAl+xTp39rWIRApolyUYTt+wOXLl60+Sb5S5e+JyJ+GwNlddecTTCgrKsXGrp8qGq+t8DcoERERkY1xyJKIiIgUZ4shy/sJEzIiIiJSnAAsXrbCnudYMSEjIiIixbGHzDTOISMiIiKyMfaQERERkeLYQ2YaEzIiIiJSHBMy0zhkSURERGRj7CEjIiIixbGHzDQmZERERKQ4ISQICxMqS8+vyThkSURERGRj7CEjIiIixRkgWbwwrKXn12RMyIiIiEhxnENmGocsiYiIiGyMPWRERESkOE7qN40JGRERESmOQ5amMSEjIiIixbGHzDTOISMiIiKyMfaQERERkeKEFYYs7bmHjAkZERERKU4AEMLyNuwVhyyJiIiIbIw9ZERERKQ4AyRIXKn/tpiQERERkeL4lKVpHLIkIiIisjH2kBEREZHiDEKCxIVhb4sJGRERESlOCCs8ZWnHj1lyyJKIiIjIxthDRkRERIrjpH7TmJARERGR4piQmcaEjIiIiBTHSf2mcQ4ZERER2aXU1FR0794d/v7+kCQJq1evNjrev39/SJJkVKKioozq5Ofno2/fvtBoNPDy8sLAgQNRWFhoVOfAgQPo0KEDXFxcEBAQgBkzZpgdKxMyIiIiUlzlU5aWFnMUFRWhVatW+Oijj25bJyoqCjk5OXL56quvjI737dsXhw8fRnJyMtauXYvU1FQMGTJEPl5QUIAuXbogMDAQ+/fvx8yZMxEfH49PP/3UrFg5ZElERESKq0ioLJ1DVvHfgoICo/1qtRpqtfqW+l27dkXXrl1NtqlWq6HT6ao8dvToUWzYsAF79+7Fo48+CgD48MMP8fTTT+ODDz6Av78/kpKSUFpaiqVLl0KlUuHhhx9Geno6Zs+ebZS43Ql7yIiIiOi+EhAQAK1WK5eEhIS7bmv79u3w8fFB06ZN8cYbb+DChQvysbS0NHh5ecnJGAB07twZDg4O2L17t1ynY8eOUKlUcp3IyEhkZGTg4sWL1Y6DPWRERESkOGs+ZXn69GloNBp5f1W9Y9URFRWFnj17IigoCJmZmXjnnXfQtWtXpKWlwdHREbm5ufDx8TE6x8nJCd7e3sjNzQUA5ObmIigoyKiOr6+vfKxWrVrVioUJGRERESlO/H+xtA0A0Gg0RgnZ3erdu7f87xYtWqBly5Zo3Lgxtm/fjieffNLi9s3BIUsiIiIiAI0aNUKdOnVw/PhxAIBOp8O5c+eM6pSXlyM/P1+ed6bT6ZCXl2dUp3L7dnPTqsKEjIiIiBRXOWRpaVHSmTNncOHCBfj5+QEAwsLCcOnSJezfv1+us3XrVhgMBoSGhsp1UlNTUVZWJtdJTk5G06ZNqz1cCTAhIyIiontBWKmYobCwEOnp6UhPTwcAZGVlIT09HdnZ2SgsLMSYMWPwyy+/4OTJk9iyZQuee+45BAcHIzIyEgAQEhKCqKgoDB48GHv27MHPP/+M2NhY9O7dG/7+/gCAPn36QKVSYeDAgTh8+DBWrlyJefPmYdSoUWbFyjlkREREpDxr9HCZef6+ffvQqVMnebsySYqOjsbChQtx4MABfP7557h06RL8/f3RpUsXTJkyxeghgaSkJMTGxuLJJ5+Eg4MDevXqhfnz58vHtVotNm3ahJiYGLRr1w516tTBhAkTzFryAmBCRkRERHYqIiICwsRqshs3brxjG97e3li+fLnJOi1btsSOHTvMju9GTMiIiIhIcXez0n5VbdgrJmRERESkOGuuQ2aPOKmfiIiIyMbYQ0ZERETKE5LZk/KrbMNOMSEjIiIixXEOmWkcsiQiIiKyMfaQERERkfKs+TJLO8SEjIiIiBTHpyxNq1ZC9uOPP1a7wWefffaugyEiIiJ6EFUrIevRo0e1GpMkCXq93pJ4iIiIyF7Z8ZCjpaqVkBkMBqXjICIiIjvGIUvTLHrKsri42FpxEBERkT0TVip2yuyETK/XY8qUKahXrx48PDxw4sQJAMD48ePx2WefWT1AIiIiIntndkI2bdo0JCYmYsaMGVCpVPL+Rx55BEuWLLFqcERERGQvJCsV+2R2QvbFF1/g008/Rd++feHo6Cjvb9WqFf744w+rBkdERER2gkOWJpmdkP31118IDg6+Zb/BYEBZWZlVgiIiIiJ6kJidkDVv3hw7duy4Zf+3336LNm3aWCUoIiIisjPsITPJ7JX6J0yYgOjoaPz1118wGAz4/vvvkZGRgS+++AJr165VIkYiIiK63wmpoljahp0yu4fsueeew5o1a7B582a4u7tjwoQJOHr0KNasWYOnnnpKiRiJiIiI7NpdvcuyQ4cOSE5OtnYsREREZKeEqCiWtmGv7vrl4vv27cPRo0cBVMwra9eundWCIiIiIjtjjTlgTMiuO3PmDF555RX8/PPP8PLyAgBcunQJjz/+OFasWIH69etbO0YiIiIiu2b2HLJBgwahrKwMR48eRX5+PvLz83H06FEYDAYMGjRIiRiJiIjoflc5qd/SYqfM7iFLSUnBrl270LRpU3lf06ZN8eGHH6JDhw5WDY6IiIjsgyQqiqVt2CuzE7KAgIAqF4DV6/Xw9/e3SlBERERkZziHzCSzhyxnzpyJYcOGYd++ffK+ffv2YcSIEfjggw+sGhwRERHRg6BaPWS1atWCJF0fty0qKkJoaCicnCpOLy8vh5OTEwYMGIAePXooEigRERHdx7gwrEnVSsjmzp2rcBhERERk1zhkaVK1ErLo6Gil4yAiIiJ6YN31wrAAUFxcjNLSUqN9Go3GooCIiIjIDrGHzCSzJ/UXFRUhNjYWPj4+cHd3R61atYwKERER0S2ElYoZUlNT0b17d/j7+0OSJKxevVo+VlZWhrFjx6JFixZwd3eHv78/+vXrh7Nnzxq10bBhQ0iSZFTef/99ozoHDhxAhw4d4OLigoCAAMyYMcO8QHEXCdlbb72FrVu3YuHChVCr1ViyZAkmTZoEf39/fPHFF2YHQERERKSEoqIitGrVCh999NEtx65evYpff/0V48ePx6+//orvv/8eGRkZePbZZ2+pO3nyZOTk5Mhl2LBh8rGCggJ06dIFgYGB2L9/P2bOnIn4+Hh8+umnZsVq9pDlmjVr8MUXXyAiIgL//ve/0aFDBwQHByMwMBBJSUno27evuU0SERGRvbPBU5Zdu3ZF165dqzym1WqRnJxstG/BggX4xz/+gezsbDRo0EDe7+npCZ1OV2U7SUlJKC0txdKlS6FSqfDwww8jPT0ds2fPxpAhQ6odq9k9ZPn5+WjUqBGAivli+fn5AIB//vOfSE1NNbc5IiIiegBUrtRvaQEqeqVuLCUlJVaJ8fLly5AkSX5Xd6X3338ftWvXRps2bTBz5kyUl5fLx9LS0tCxY0eoVCp5X2RkJDIyMnDx4sVqX9vshKxRo0bIysoCADRr1gxff/01gIqes5tvgIiIiMjaAgICoNVq5ZKQkGBxm8XFxRg7dixeeeUVowcUhw8fjhUrVmDbtm14/fXXMX36dLz11lvy8dzcXPj6+hq1Vbmdm5tb7eubPWT573//G7///jvCw8Px9ttvo3v37liwYAHKysowe/Zsc5sjIiKiB4EVn7I8ffq0UdKkVqstarasrAwvvfQShBBYuHCh0bFRo0bJ/27ZsiVUKhVef/11JCQkWHzdG5mdkMXFxcn/7ty5M/744w/s378fwcHBaNmypdUCIyIiIqqKRqOx2jJblcnYqVOnsHXr1ju2GxoaivLycpw8eRJNmzaFTqdDXl6eUZ3K7dvNO6uKReuQAUBgYCACAwMtbYaIiIjsmITrc8AsacOaKpOxY8eOYdu2bahdu/Ydz0lPT4eDgwN8fHwAAGFhYXj33XdRVlYGZ2dnAEBycjKaNm1q1nJg1UrI5s+fX+0Ghw8fXu26REREREopLCzE8ePH5e2srCykp6fD29sbfn5+eOGFF/Drr79i7dq10Ov18pwvb29vqFQqpKWlYffu3ejUqRM8PT2RlpaGuLg4vPrqq3Ky1adPH0yaNAkDBw7E2LFjcejQIcybNw9z5swxK1ZJCHHHfDUoKKh6jUkSTpw4YVYAdH8rKCiAVqvFG6nPQ+3hbOtwiBSRVXTnv5qJ7kdlRaVYH/UZLl++rNibdip/TwS+Pw0OLi4WtWUoLsapt9+tdrzbt29Hp06dbtkfHR2N+Pj42+Y327ZtQ0REBH799Ve8+eab+OOPP1BSUoKgoCC89tprGDVqlNH8sQMHDiAmJgZ79+5FnTp1MGzYMIwdO9ase6tWD1nlU5VEREREd8UGr06KiIiAqX6nO/VJtW3bFr/88ssdr9OyZUvs2LHDvOBuYvayF0RERERkXRZP6iciIiK6I75c3CQmZERERKS4G1fat6QNe8UhSyIiIiIbYw8ZERERKY9DlibdVQ/Zjh078OqrryIsLAx//fUXAOB///sfdu7cadXgiIiIyE4IKxU7ZXZC9t133yEyMhKurq747bff5DesX758GdOnT7d6gERERET2zuyEbOrUqVi0aBEWL14svyIAAJ544gn8+uuvVg2OiIiI7EPlpH5Li70yew5ZRkYGOnbseMt+rVaLS5cuWSMmIiIisjdCqiiWtmGnzO4h0+l0Ru+FqrRz5040atTIKkERERGRneEcMpPMTsgGDx6MESNGYPfu3ZAkCWfPnkVSUhJGjx6NN954Q4kYiYiIiOya2UOWb7/9NgwGA5588klcvXoVHTt2hFqtxujRozFs2DAlYiQiIqL7HBeGNc3shEySJLz77rsYM2YMjh8/jsLCQjRv3hweHh5KxEdERET2gOuQmXTXC8OqVCo0b97cmrEQERERPZDMTsg6deoESbr9Uw5bt261KCAiIiKyQ9ZYtoI9ZNe1bt3aaLusrAzp6ek4dOgQoqOjrRUXERER2RMOWZpkdkI2Z86cKvfHx8ejsLDQ4oCIiIiIHjR39S7Lqrz66qtYunSptZojIiIie8J1yEy660n9N0tLS4OLi4u1miMiIiI7wmUvTDM7IevZs6fRthACOTk52LdvH8aPH2+1wIiIiIgeFGYnZFqt1mjbwcEBTZs2xeTJk9GlSxerBUZERET0oDArIdPr9fj3v/+NFi1aoFatWkrFRERERPaGT1maZNakfkdHR3Tp0gWXLl1SKBwiIiKyR5VzyCwt9srspywfeeQRnDhxQolYiIiIiB5IZidkU6dOxejRo7F27Vrk5OSgoKDAqBARERFViUte3Fa155BNnjwZ//nPf/D0008DAJ599lmjVygJISBJEvR6vfWjJCIiovsb55CZVO2EbNKkSRg6dCi2bdumZDxERERED5xqJ2RCVKSl4eHhigVDRERE9okLw5pm1rIXNw5REhEREVUbhyxNMisha9KkyR2Tsvz8fIsCIiIiInrQmJWQTZo06ZaV+omIiIjuxBZDlqmpqZg5cyb279+PnJwcrFq1Cj169JCPCyEwceJELF68GJcuXcITTzyBhQsX4qGHHpLr5OfnY9iwYVizZg0cHBzQq1cvzJs3Dx4eHnKdAwcOICYmBnv37kXdunUxbNgwvPXWW2bFalZC1rt3b/j4+Jh1ASIiIiJbDFkWFRWhVatWGDBgwC3v4gaAGTNmYP78+fj8888RFBSE8ePHIzIyEkeOHIGLiwsAoG/fvsjJyUFycjLKysrw73//G0OGDMHy5csBAAUFBejSpQs6d+6MRYsW4eDBgxgwYAC8vLwwZMiQasda7YSM88eIiIjoftK1a1d07dq1ymNCCMydOxfvvfcennvuOQDAF198AV9fX6xevRq9e/fG0aNHsWHDBuzduxePPvooAODDDz/E008/jQ8++AD+/v5ISkpCaWkpli5dCpVKhYcffhjp6emYPXu2WQlZtReGrXzKkoiIiMhsli4Ke0MP282L0peUlJgdTlZWFnJzc9G5c2d5n1arRWhoKNLS0gAAaWlp8PLykpMxAOjcuTMcHBywe/duuU7Hjh2hUqnkOpGRkcjIyMDFixerHU+1EzKDwcDhSiIiIror1nyXZUBAALRarVwSEhLMjic3NxcA4Ovra7Tf19dXPpabm3tL7uPk5ARvb2+jOlW1ceM1qsOsOWREREREd8WKc8hOnz4NjUYj71ar1RY2bHtmv8uSiIiIyJY0Go1RuZuETKfTAQDy8vKM9ufl5cnHdDodzp07Z3S8vLwc+fn5RnWqauPGa1QHEzIiIiJSnhXnkFlDUFAQdDodtmzZIu8rKCjA7t27ERYWBgAICwvDpUuXsH//frnO1q1bYTAYEBoaKtdJTU1FWVmZXCc5ORlNmzZFrVq1qh0PEzIiIiJSnDXnkFVXYWEh0tPTkZ6eDqBiIn96ejqys7MhSRJGjhyJqVOn4scff8TBgwfRr18/+Pv7y2uVhYSEICoqCoMHD8aePXvw888/IzY2Fr1794a/vz8AoE+fPlCpVBg4cCAOHz6MlStXYt68eRg1apRZsXIOGREREdmlffv2oVOnTvJ2ZZIUHR2NxMREvPXWWygqKsKQIUNw6dIl/POf/8SGDRvkNcgAICkpCbGxsXjyySflhWHnz58vH9dqtdi0aRNiYmLQrl071KlTBxMmTDBryQsAkATXsyALFBQUQKvV4o3U56H2cLZ1OESKyCqqbesQiBRRVlSK9VGf4fLly0aT5K2p8vdEs2HT4ah2ufMJJuhLivHHh+8oGq+tsIeMiIiIFGeLVyfdTziHjIiIiMjG2ENGREREyrPBuyzvJ0zIiIiISHlMyEzikCURERGRjbGHjIiIiBQn/X+xtA17xYSMiIiIlMchS5OYkBEREZHiuOyFaZxDRkRERGRj7CEjIiIi5XHI0iQmZERERHRv2HFCZSkOWRIRERHZGHvIiIiISHGc1G8aEzIiIiJSHueQmcQhSyIiIiIbYw8ZERERKY5DlqYxISMiIiLlccjSJA5ZEhEREdkYe8iIiIhIcRyyNI0JGRERESmPQ5YmMSEjIiIi5TEhM4lzyIiIiIhsjD1kREREpDjOITONCRkREREpj0OWJnHIkoiIiMjG2ENGREREipOEgCQs6+Ky9PyajAkZERERKY9DliZxyJKIiIjIxthDRkRERIrjU5amMSEjIiIi5XHI0iQOWRIRERHZGBMyIiIiUlzlkKWlpboaNmwISZJuKTExMQCAiIiIW44NHTrUqI3s7Gx069YNbm5u8PHxwZgxY1BeXm7NL4uMQ5ZERESkvHs8ZLl3717o9Xp5+9ChQ3jqqafw4osvyvsGDx6MyZMny9tubm7yv/V6Pbp16wadToddu3YhJycH/fr1g7OzM6ZPn27ZfVSBCRkREREpzpqT+gsKCoz2q9VqqNVqo31169Y12n7//ffRuHFjhIeHy/vc3Nyg0+mqvNamTZtw5MgRbN68Gb6+vmjdujWmTJmCsWPHIj4+HiqVyrKbuQmHLImIiOi+EhAQAK1WK5eEhAST9UtLS/Hll19iwIABkCRJ3p+UlIQ6dergkUcewbhx43D16lX5WFpaGlq0aAFfX195X2RkJAoKCnD48GGr3xN7yIiIiEh5VhyyPH36NDQajbz75t6xm61evRqXLl1C//795X19+vRBYGAg/P39ceDAAYwdOxYZGRn4/vvvAQC5ublGyRgAeTs3N9fCG7kVEzIiIiK6J6y1jphGozFKyO7ks88+Q9euXeHv7y/vGzJkiPzvFi1awM/PD08++SQyMzPRuHFj6wRqBg5ZEhERkd06deoUNm/ejEGDBpmsFxoaCgA4fvw4AECn0yEvL8+oTuX27eadWYIJGRERESlPCOsUMy1btgw+Pj7o1q2byXrp6ekAAD8/PwBAWFgYDh48iHPnzsl1kpOTodFo0Lx5c7PjuBMOWRIREZHibPHqJIPBgGXLliE6OhpOTtdTnszMTCxfvhxPP/00ateujQMHDiAuLg4dO3ZEy5YtAQBdunRB8+bN8dprr2HGjBnIzc3Fe++9h5iYmDvOWbsbTMiIiIjILm3evBnZ2dkYMGCA0X6VSoXNmzdj7ty5KCoqQkBAAHr16oX33ntPruPo6Ii1a9fijTfeQFhYGNzd3REdHW20bpk1MSEjIiIi5dngXZZdunSBqGKYMyAgACkpKXc8PzAwEOvXrzfvoneJCRkREREpTjJUFEvbsFec1E9ERERkY+whI7rHin4V+PsLgWtHgfK/gQYfSNB0ur5ytP6qQN6HAgXbAf1lQOUP1O4twfuF63VODDHg6n7jdmv1Auq9c/1vrNIcgbMJAkX7AAc3oNYzgG+sBMlJApGS9OmlKFtxDYaMcogLBqinaeDU4fok6KKO56s8z/kNd6heqXiXYOkXRdCnlcJwvBxwluC+vo5R3bKfilGacKXKdtx+qA2pFvsbahwbDFneT+w+Idu+fTs6deqEixcvwsvLy9bhEMFwDXBpAtR6VkL2mFt/uuTOFijaC9SfIkHlDxT+Apx9X8CpLqAJv55M1Xoe8Bl6fdvB5XobQi9waoSAUx2g0TIJ5X8DZyYIwElAF8uEjJQligUcGjvB6WkXlLxXcMtx11W1jbb1u0tR+t8rcAq/4cm1csCpkxqGh51Rvr74ljac/qWG4z+M3yVYmlAAUQomYzWULZ6yvJ/Y9FPbv39/SJIkl9q1ayMqKgoHDhyw2jUef/xx5OTkQKvVWq1Na4mIiDC6/5tLRETEPY2nYcOGmDt37j295oPI8wkJvm86QPOvqhOjqwcAr2ckeDwqQeUvwbunBJeHgGuHjX8SObgAznUkuTh6XG+v8BegJAsImCLBtalUcc03JOR/DRjK7PgnGtUITu3VUA12h1PHqpcGcKjtYFT0O0vg0MYZDv6Och3VAHc4v+QGh8ZV9xtIasmoDckR0P9aBqduLlXWpxrARuuQ3S9s/mdEVFQUcnJykJOTgy1btsDJyQnPPPOM1dpXqVTQ6XRGLxOtKb7//nv53vfs2QOg4hHdyn2V79OiB4tbS+BKqkDZOQEhBAr3CpRmAx7tjT/Dl34Cjv7LgGMvGZD7oQGGa9d/UF09IOASDDjVvn6ORxhgKAJKMu/ZrRDdkcg3QJ9WCmcLE6nyDcWAiwSnCOuvD0V0L9g8IVOr1dDpdNDpdGjdujXefvttnD59GufPV8wx2L59OyRJwqVLl+Rz0tPTIUkSTp48CaDitQjdu3dHrVq14O7ujocfflh+TPXm8xMTE+Hl5YWNGzciJCQEHh4eclJ4oyVLliAkJAQuLi5o1qwZPv74Y/lYaWkpYmNj4efnBxcXFwQGBspvmhdCID4+Hg0aNIBarYa/vz+GDx9e5b17e3vL9163bl0AQO3ataHT6fDMM89g6dKlct0ePXrA2dkZhYWFAIAzZ85AkiT5FQ8lJSUYPXo06tWrB3d3d4SGhmL79u1G19u5cyc6dOgAV1dXBAQEYPjw4SgqKgJQ0Vt36tQpxMXFyT10VSkpKUFBQYFRIevye0uCOgjI6CpwOFTg1DABv7ES3Nte/3/iFSWh/hQJQZ9IqNtfwqX1wJnx1xOy8guAk7dxu5Xb5RfuxV0QVU/ZhmLATYLjbXrTqt3OumI4dVZDUte8P76pQuWQpaXFXtk8IbtRYWEhvvzySwQHB6N27dp3PuH/xcTEoKSkBKmpqTh48CD++9//wsPD47b1r169ig8++AD/+9//kJqaiuzsbIwePVo+npSUhAkTJmDatGk4evQopk+fjvHjx+Pzzz8HAMyfPx8//vgjvv76a2RkZCApKQkNGzYEAHz33XeYM2cOPvnkExw7dgyrV69GixYtzP5ahIeHywmVEAI7duyAl5cXdu7cCQBISUlBvXr1EBwcDACIjY1FWloaVqxYgQMHDuDFF19EVFQUjh07BqBiVeKoqCj06tULBw4cwMqVK7Fz507ExsYCqOitq1+/PiZPniz30FUlISEBWq1WLgEBAWbfG5mWvwK4eghoMEdCcJIEXZyEnP8KFO6+/pPIu6cEz8cluDwkwetpCfUnSSjYBpSctuOfVmSXytcXw+kpyxIp/aEyiFN6DlfWdMJKxU7ZfFL/2rVr5eSpqKgIfn5+WLt2LRwcqp8rZmdno1evXnLi06hRI5P1y8rKsGjRIvlt7rGxsUYr706cOBGzZs1Cz549AQBBQUE4cuQIPvnkE0RHRyM7OxsPPfQQ/vnPf0KSJAQGBhrFotPp0LlzZzg7O6NBgwb4xz/+Ue17qRQREYHPPvsMer0ehw4dgkqlwssvv4zt27cjKioK27dvR3h4uHzNZcuWITs7W36T/ejRo7FhwwYsW7YM06dPR0JCAvr27YuRI0cCAB566CHMnz8f4eHhWLhwIby9veHo6AhPT0+TL00dN24cRo0aJW8XFBQwKbMiQ7FA3kcCDT6Q4Nmh4heUy0NAcYbA3/8T8Ait+peW2//n/KWnAXUA4FQbuHbYuE55fsV/nar/tw6RovS/l0Jk6+EUr7GonfK1xXB4yAmOTZ2tFBnRvWfzHrJOnTohPT0d6enp2LNnDyIjI9G1a1ecOnWq2m0MHz4cU6dOxRNPPIGJEyfe8aEANzc3ORkDKl4kWvny0KKiImRmZmLgwIHw8PCQy9SpU5GZWTH5pn///khPT0fTpk0xfPhwbNq0SW7rxRdfxLVr19CoUSMMHjwYq1atQnl5uTlfEgBAhw4dcOXKFfz2229ISUlBeHg4IiIi5F6zlJQUedL/wYMHodfr0aRJE6OYU1JS5Jh///13JCYmGh2PjIyEwWBAVlZWteNSq9XQaDRGhaxHlFeUW74zHQFhYkHEaxkV/3WuGPmGW0sJxceB8vzrf04W7gYc3AG16b9XiO6Z8nXFcGjqBMfgu+8bEFcFyreVwOlp9o7VdByyNM3mPWTu7u7ysBtQMXdLq9Vi8eLFmDp1qtxTduOrD8rKyozaGDRoECIjI7Fu3Tps2rQJCQkJmDVrFoYNG1blNZ2djf+KkiRJbr9yjtbixYsRGhpqVM/RseIJoLZt2yIrKws//fQTNm/ejJdeegmdO3fGt99+i4CAAGRkZGDz5s1ITk7Gm2++iZkzZyIlJeWW65ri5eWFVq1aYfv27UhLS8NTTz2Fjh074uWXX8aff/6JY8eOyT1khYWFcHR0xP79++UYK1X2PhYWFuL111+vcj5bgwYNqh0XWU5/VaD09PXt0rPAtQwBRw2g8pPg1k4gd56ApAZUfkDRfuDSOkAXV9E7VnJa4PIGwPOfgKMWKD4G5MwScGsLuDxUUcejPaAOqphX5juiYr2zvI8FvF8CHFScY0PKElcFDH/pr2/n6KE/Vg5JI8HBt+JnlCgyoHx7CVQxVU8vMeTpIQoERJ4e0AP6YxV/2DrUc4Tkdv0zXL61GNALOHXhZP4azxpPSdrxU5Y2T8huJkkSHBwccO3aNQCQJ7vn5OSgVq1aACom9d8sICAAQ4cOxdChQzFu3DgsXrz4tgmZKb6+vvD398eJEyfQt2/f29bTaDR4+eWX8fLLL+OFF15AVFQU8vPz4e3tDVdXV3Tv3h3du3dHTEwMmjVrhoMHD6Jt27ZmxRIeHo5t27Zhz549mDZtGry9vRESEoJp06bBz88PTZo0AQC0adMGer0e586dQ4cOHapsq23btjhy5IhR8nszlUoFvV5/2+NkHdeOACdfv/5DJXd2xb+9ngHqT5IQMF1C3gKBM+8J6AsAZx3g+6YE7xcq6kvOQOEegQtfVaxp5uwLaJ8E6g68/ktKcpQQOA84myBwor+Ag2tF+75DmYyR8gwZZSgecVneLl1QBKAITlFqqN+p6FUv31ICCMDpyaoTqbLPilC+oUTeLh54EQDgMk8LxzbX1x8rX1cMx45qSJ42H/AhsojNE7KSkhLk5uYCAC5evIgFCxagsLAQ3bt3BwAEBwcjICAA8fHxmDZtGv7880/MmjXLqI2RI0eia9euaNKkCS5evIht27YhJCTkrmOaNGkShg8fDq1Wi6ioKJSUlGDfvn24ePEiRo0ahdmzZ8PPzw9t2rSBg4MDvvnmG+h0Onh5eSExMRF6vR6hoaFwc3PDl19+CVdXV6N5ZtUVERGBDz/8EHXr1kWzZs3kfQsWLMCLL74o12vSpAn69u2Lfv36YdasWWjTpg3Onz+PLVu2oGXLlujWrRvGjh2L9u3bIzY2FoMGDYK7uzuOHDmC5ORkLFiwAEDFOmSpqano3bs31Go16tSpU2VcZBmPRyU8sv/2iZFzHQn1429/XKWT0GjxnRMrlZ+EhvOZgNG959hGBffUuibrOD/rCudnXW97XP2OBup37nwt14W1zA2PbIQLw5pm8z8pNmzYAD8/P/j5+SE0NBR79+7FN998I8+PcnZ2xldffYU//vgDLVu2xH//+19MnTrVqA29Xo+YmBiEhIQgKioKTZo0MVqmwlyDBg3CkiVLsGzZMrRo0QLh4eFITExEUFAQAMDT0xMzZszAo48+isceewwnT57E+vXr4eDgAC8vLyxevBhPPPEEWrZsic2bN2PNmjVmPTVaqUOHDjAYDPLQJFCRkOn1+lsWjV22bBn69euH//znP2jatCl69OiBvXv3ysORLVu2REpKCv7880906NABbdq0wYQJE+SHAABg8uTJOHnyJBo3biz3TBIREVkFn7I0SRLCjgdkSXEFBQXQarV4I/V5qD34hBPZp6wiPppK9qmsqBTroz7D5cuXFXtIq/L3RFjUZDg5W7gAcFkx0jZMUDReW7H5kCURERHZPw5ZmsaEjIiIiJRnEBXF0jbsFBMyIiIiUp415oDZbz5m+0n9RERERA869pARERGR4iRYYQ6ZVSKpmZiQERERkfK4Ur9JHLIkIiIisjH2kBEREZHiuOyFaUzIiIiISHl8ytIkDlkSERER2Rh7yIiIiEhxkhCQLJyUb+n5NRkTMiIiIlKe4f+LpW3YKQ5ZEhEREdkYe8iIiIhIcRyyNI0JGRERESmPT1maxCFLIiIiUl7lSv2WlmqKj4+HJElGpVmzZvLx4uJixMTEoHbt2vDw8ECvXr2Ql5dn1EZ2dja6desGNzc3+Pj4YMyYMSgvL7fal+RG7CEjIiIiu/Twww9j8+bN8raT0/W0Jy4uDuvWrcM333wDrVaL2NhY9OzZEz///DMAQK/Xo1u3btDpdNi1axdycnLQr18/ODs7Y/r06VaPlQkZERERKc4WK/U7OTlBp9Pdsv/y5cv47LPPsHz5cvzrX/8CACxbtgwhISH45Zdf0L59e2zatAlHjhzB5s2b4evri9atW2PKlCkYO3Ys4uPjoVKpLLuZm3DIkoiIiJRnxSHLgoICo1JSUlLlJY8dOwZ/f380atQIffv2RXZ2NgBg//79KCsrQ+fOneW6zZo1Q4MGDZCWlgYASEtLQ4sWLeDr6yvXiYyMREFBAQ4fPmz1Lw8TMiIiIrqvBAQEQKvVyiUhIeGWOqGhoUhMTMSGDRuwcOFCZGVloUOHDrhy5Qpyc3OhUqng5eVldI6vry9yc3MBALm5uUbJWOXxymPWxiFLIiIiUpxkqCiWtgEAp0+fhkajkfer1epb6nbt2lX+d8uWLREaGorAwEB8/fXXcHV1tSwQBbCHjIiIiJRnxSFLjUZjVKpKyG7m5eWFJk2a4Pjx49DpdCgtLcWlS5eM6uTl5clzznQ63S1PXVZuVzUvzVJMyIiIiMjuFRYWIjMzE35+fmjXrh2cnZ2xZcsW+XhGRgays7MRFhYGAAgLC8PBgwdx7tw5uU5ycjI0Gg2aN29u9fg4ZElERETKu8cLw44ePRrdu3dHYGAgzp49i4kTJ8LR0RGvvPIKtFotBg4ciFGjRsHb2xsajQbDhg1DWFgY2rdvDwDo0qULmjdvjtdeew0zZsxAbm4u3nvvPcTExFSrR85cTMiIiIhIcff61UlnzpzBK6+8ggsXLqBu3br45z//iV9++QV169YFAMyZMwcODg7o1asXSkpKEBkZiY8//lg+39HREWvXrsUbb7yBsLAwuLu7Izo6GpMnT7boHm6HCRkRERHZnRUrVpg87uLigo8++ggfffTRbesEBgZi/fr11g6tSkzIiIiISHlmvvrotm3YKSZkREREpDwBwMJlL+z55eJMyIiIiEhx93oO2f2Gy14QERER2Rh7yIiIiEh5AlaYQ2aVSGokJmRERESkPE7qN4lDlkREREQ2xh4yIiIiUp4BgGSFNuwUEzIiIiJSHJ+yNI1DlkREREQ2xh4yIiIiUh4n9ZvEhIyIiIiUx4TMJA5ZEhEREdkYe8iIiIhIeewhM4kJGRERESmPy16YxISMiIiIFMdlL0zjHDIiIiIiG2MPGRERESmPc8hMYkJGREREyjMIQLIwoTLYb0LGIUsiIiIiG2MPGRERESmPQ5YmMSEjIiKie8AKCRnsNyHjkCURERGRjbGHjIiIiJTHIUuTmJARERGR8gwCFg858ilLIiIiIlIKe8iIiIhIecJQUSxtw04xISMiIiLlcQ6ZSUzIiIiISHmcQ2YS55ARERER2RgTMiIiIlJe5ZClpaWaEhIS8Nhjj8HT0xM+Pj7o0aMHMjIyjOpERERAkiSjMnToUKM62dnZ6NatG9zc3ODj44MxY8agvLzcKl+SG3HIkoiIiJQnYIU5ZNWvmpKSgpiYGDz22GMoLy/HO++8gy5duuDIkSNwd3eX6w0ePBiTJ0+Wt93c3OR/6/V6dOvWDTqdDrt27UJOTg769esHZ2dnTJ8+3bJ7uQkTMiIiIrI7GzZsMNpOTEyEj48P9u/fj44dO8r73dzcoNPpqmxj06ZNOHLkCDZv3gxfX1+0bt0aU6ZMwdixYxEfHw+VSmW1eDlkSURERMqz4pBlQUGBUSkpKbnj5S9fvgwA8Pb2NtqflJSEOnXq4JFHHsG4ceNw9epV+VhaWhpatGgBX19feV9kZCQKCgpw+PBha3xVZOwhIyIiIuUZDAAsXEfMUHF+QECA0e6JEyciPj7exGkGjBw5Ek888QQeeeQReX+fPn0QGBgIf39/HDhwAGPHjkVGRga+//57AEBubq5RMgZA3s7NzbXsXm7ChIyIiIjuK6dPn4ZGo5G31Wq1yfoxMTE4dOgQdu7cabR/yJAh8r9btGgBPz8/PPnkk8jMzETjxo2tG/QdcMiSiIiIlGfFIUuNRmNUTCVksbGxWLt2LbZt24b69eubDDE0NBQAcPz4cQCATqdDXl6eUZ3K7dvNO7tbTMiIiIhIefd42QshBGJjY7Fq1Sps3boVQUFBdzwnPT0dAODn5wcACAsLw8GDB3Hu3Dm5TnJyMjQaDZo3b27e/d8BhyyJiIjI7sTExGD58uX44Ycf4OnpKc/50mq1cHV1RWZmJpYvX46nn34atWvXxoEDBxAXF4eOHTuiZcuWAIAuXbqgefPmeO211zBjxgzk5ubivffeQ0xMzB2HSc3FhIyIiIiUd49fnbRw4UIAFYu/3mjZsmXo378/VCoVNm/ejLlz56KoqAgBAQHo1asX3nvvPbmuo6Mj1q5dizfeeANhYWFwd3dHdHS00bpl1sKEjIiIiBQnhAFCWPaUpTnnizsMbwYEBCAlJeWO7QQGBmL9+vXVvu7dYkJGREREyhPC8peDW7rSfw3GSf1ERERENsYeMiIiIlKesMIcMjvuIWNCRkRERMozGADJwpX6LZyDVpNxyJKIiIjIxthDRkRERMrjkKVJTMiIiIhIccJggLBwyNLSZTNqMg5ZEhEREdkYe8iIiIhIeRyyNIkJGRERESnPIACJCdntcMiSiIiIyMbYQ0ZERETKEwKApeuQ2W8PGRMyIiIiUpwwCAgLhyzv9MLw+xkTMiIiIlKeMMDyHjIue0FERERECmEPGRERESmOQ5amMSEjIiIi5XHI0iQmZGSRyr9WSovKbBwJkXLKrpbaOgQiRZQVVXy270XPUznKLF4Xthz2+7uGCRlZ5MqVKwCAz7qutXEkRER0t65cuQKtVqtI2yqVCjqdDjtz11ulPZ1OB5VKZZW2ahJJ2POALCnOYDDg7Nmz8PT0hCRJtg7H7hUUFCAgIACnT5+GRqOxdThEVsfP+L0lhMCVK1fg7+8PBwflnvMrLi5Gaal1eppVKhVcXFys0lZNwh4ysoiDgwPq169v6zAeOBqNhr+syK7xM37vKNUzdiMXFxe7TKKsicteEBEREdkYEzIiIiIiG2NCRnQfUavVmDhxItRqta1DIVIEP+P0oOKkfiIiIiIbYw8ZERERkY0xISMiIiKyMSZkRERERDbGhIzoPpCYmAgvLy9bh0EPsO3bt0OSJFy6dMnWoRDZJSZkRPfQ6dOnMWDAAPj7+0OlUiEwMBAjRozAhQsX5DoNGzbE3LlzbRck3Xf69+8PSZLkUrt2bURFReHAgQNWu8bjjz+OnJyce7KIqLkiIiKM7v/mEhERcU/j4fcw3Q0mZET3yIkTJ/Doo4/i2LFj+Oqrr3D8+HEsWrQIW7ZsQVhYGPLz8+95TGVl9vui3gdNVFQUcnJykJOTgy1btsDJyQnPPPOM1dqvfB9hTXxF2vfffy/f+549ewAAmzdvlvd9//33No6Q6M6YkBHdIzExMVCpVNi0aRPCw8PRoEEDdO3aFZs3b8Zff/2Fd999FxERETh16hTi4uLkv+5vtHHjRoSEhMDDw0P+BXyjJUuWICQkBC4uLmjWrBk+/vhj+djJkychSRJWrlyJ8PBwuLi4ICkp6Z7cOylPrVZDp9NBp9OhdevWePvtt3H69GmcP38eQNVDjunp6ZAkCSdPngQAnDp1Ct27d0etWrXg7u6Ohx9+GOvXr6/y/MphdEs+k6WlpYiNjYWfnx9cXFwQGBiIhIQEABXvWIyPj0eDBg2gVqvh7++P4cOHV3nv3t7e8r3XrVsXAFC7dm3odDo888wzWLp0qVy3R48ecHZ2RmFhIQDgzJkzkCQJx48fBwCUlJRg9OjRqFevHtzd3REaGort27cbXW/nzp3o0KEDXF1dERAQgOHDh6OoqAgA7vg9THRbgogUd+HCBSFJkpg+fXqVxwcPHixq1aol/v77b1G/fn0xefJkkZOTI3JycoQQQixbtkw4OzuLzp07i71794r9+/eLkJAQ0adPH7mNL7/8Uvj5+YnvvvtOnDhxQnz33XfC29tbJCYmCiGEyMrKEgBEw4YN5Tpnz55V/uZJcdHR0eK5556Tt69cuSJef/11ERwcLPR6vRBCiG3btgkA4uLFi3K93377TQAQWVlZQgghunXrJp566ilx4MABkZmZKdasWSNSUlKqPN8an8mZM2eKgIAAkZqaKk6ePCl27Nghli9fLoQQ4ptvvhEajUasX79enDp1SuzevVt8+umnd/xaVH7Of/vtNyGEEKNGjRLdunUTQghhMBiEt7e3qFOnjvjpp5/kGOvVqyefP2jQIPH444+L1NRUcfz4cTFz5kyhVqvFn3/+KYQQ4vjx48Ld3V3MmTNH/Pnnn+Lnn38Wbdq0Ef379xdCVHyvV/U9THQnTMiI7oFffvlFABCrVq2q8vjs2bMFAJGXlycCAwPFnDlzjI4vW7ZMABDHjx+X93300UfC19dX3m7cuLH8y6zSlClTRFhYmBDi+i+quXPnWuemqMaIjo4Wjo6Owt3dXbi7uwsAws/PT+zfv1+uU52ErEWLFiI+Pr7Ka1SVkFn6mRw2bJj417/+JQwGwy3XmzVrlmjSpIkoLS0162txc0L2448/Cq1WK8rLy0V6errQ6XRixIgRYuzYsUKIigSsMok8deqUcHR0FH/99ZdRm08++aQYN26cEEKIgQMHiiFDhhgd37Fjh3BwcBDXrl0TQogqv4eJ7oRDlkT3kLDgxRhubm5o3LixvO3n54dz584BAIqKipCZmYmBAwfCw8NDLlOnTkVmZqZRO48++uhdx0A1V6dOnZCeno709HTs2bMHkZGR6Nq1K06dOlXtNoYPH46pU6fiiSeewMSJE+/4UICln8n+/fsjPT0dTZs2xfDhw7Fp0ya5rRdffBHXrl1Do0aNMHjwYKxatQrl5eXmfEkAAB06dMCVK1fw22+/ISUlBeHh4YiIiJCHIVNSUuRJ/wcPHoRer0eTJk2MYk5JSZFj/v3335GYmGh0PDIyEgaDAVlZWWbHR1TJydYBED0IgoODIUkSjh49iueff/6W40ePHkWtWrXk+S9VcXZ2NtqWJElO8CrnwyxevBihoaFG9RwdHY223d3d7+oeqGZzd3dHcHCwvL1kyRJotVosXrwYU6dOhYNDxd/fN/5RcPNDHYMGDUJkZCTWrVuHTZs2ISEhAbNmzcKwYcOqvKaln8m2bdsiKysLP/30EzZv3oyXXnoJnTt3xrfffouAgABkZGRg8+bNSE5OxptvvomZM2ciJSXlluua4uXlhVatWmH79u1IS0vDU089hY4dO+Lll1/Gn3/+iWPHjiE8PFyO2dHREfv377/l+8bDw0Ou8/rrr1c5n61BgwbVjovoZkzIiO6B2rVr46mnnsLHH3+MuLg4uLq6ysdyc3ORlJSEfv36QZIkqFQq6PV6s9r39fWFv78/Tpw4gb59+1o7fLoPSZIEBwcHXLt2DQDkZD8nJwe1atUCUDGp/2YBAQEYOnQohg4dinHjxmHx4sW3TchMqe5nUqPR4OWXX8bLL7+MF154AVFRUcjPz4e3tzdcXV3RvXt3dO/eHTExMWjWrBkOHjyItm3bmhVLeHg4tm3bhj179mDatGnw9vZGSEgIpk2bBj8/PzRp0gQA0KZNG+j1epw7dw4dOnSosq22bdviyJEjRsnvze7me5iICRnRPbJgwQI8/vjjiIyMxNSpUxEUFITDhw9jzJgxqFevHqZNmwagYg2j1NRU9O7dG2q1GnXq1KlW+5MmTcLw4cOh1WoRFRWFkpIS7Nu3DxcvXsSoUaOUvDWqAUpKSpCbmwsAuHjxIhYsWIDCwkJ0794dQEUvbUBAAOLj4zFt2jT8+eefmDVrllEbI0eORNeuXdGkSRNcvHgR27ZtQ0hIyF3HdKfP5OzZs+Hn54c2bdrAwcEB33zzDXQ6Hby8vJCYmAi9Xo/Q0FC4ubnhyy+/hKurKwIDA82OIyIiAh9++CHq1q2LZs2ayfsWLFiAF198Ua7XpEkT9O3bF/369cOsWbPQpk0bnD9/Hlu2bEHLli3RrVs3jB07Fu3bt0dsbCwGDRoEd3d3HDlyBMnJyViwYAGAu/8epgecbaewET1YTp48KaKjo4Wvr69wdnYWAQEBYtiwYeLvv/+W66SlpYmWLVsKtVotKr9Fly1bJrRarVFbq1atEjd/CyclJYnWrVsLlUolatWqJTp27Ci+//57IcStk53JfkRHRwsAcvH09BSPPfaY+Pbbb43q7dy5U7Ro0UK4uLiIDh06iG+++cZoUn9sbKxo3LixUKvVom7duuK1116TP5tVTeq39DP56aefitatWwt3d3eh0WjEk08+KX799Ve5rdDQUKHRaIS7u7to37692Lx58x2/FlV9ziufcn755ZdviXXRokVG55eWlooJEyaIhg0bCmdnZ+Hn5yeef/55ceDAAbnOnj17xFNPPSU8PDyEu7u7aNmypZg2bZp8vKrvYaI7kYSwYJYxEREREVmMT1kSERER2RgTMiIiIiIbY0JGREREZGNMyIiIiIhsjAkZERERkY0xISMiIiKyMSZkRERERDbGhIyIiIjIxpiQEdF9r3///ujRo4e8HRERgZEjR97zOLZv3w5JknDp0qXb1pEkCatXr652m/Hx8WjdurVFcZ08eRKSJFX57koiqhmYkBGRIvr37w9JkuQXpgcHB2Py5MkoLy9X/Nrff/89pkyZUq261UmiiIiUxpeLE5FioqKisGzZMpSUlGD9+vWIiYmBs7Mzxo0bd0vd0tJSqFQqq1zX29vbKu0QEd0r7CEjIsWo1WrodDoEBgbijTfeQOfOnfHjjz8CuD7MOG3aNPj7+6Np06YAgNOnT+Oll16Cl5cXvL298dxzz+HkyZNym3q9HqNGjYKXlxdq166Nt956Cze/kvfmIcuSkhKMHTsWAQEBUKvVCA4OxmeffYaTJ0+iU6dOAIBatWpBkiT0798fAGAwGJCQkICgoCC4urqiVatW+Pbbb42us379ejRp0gSurq7o1KmTUZzVNXbsWDRp0gRubm5o1KgRxo8fj7KyslvqffLJJwgICICbmxteeuklXL582ej4kiVLEBISAhcXFzRr1gwff/yx2bEQke0wISOie8bV1RWlpaXy9pYtW5CRkYHk5GSsXbsWZWVliIyMhKenJ3bs2IGff/4ZHh4eiIqKks+bNWsWEhMTsXTpUuzcuRP5+flYtWqVyev269cPX331FebPn4+jR4/ik08+gYeHBwICAvDdd98BADIyMpCTk4N58+YBABISEvDFF19g0aJFOHz4MOLi4vDqq68iJSUFQEXi2LNnT3Tv3h3p6ekYNGgQ3n77bbO/Jp6enkhMTMSRI0cwb948LF68GHPmzDGqc/z4cXz99ddYs2YNNmzYgN9++w1vvvmmfDwpKQkTJkzAtGnTcPToUUyfPh3jx4/H559/bnY8RGQjgohIAdHR0eK5554TQghhMBhEcnKyUKvVYvTo0fJxX19fUVJSIp/zv//9TzRt2lQYDAZ5X0lJiXB1dRUbN24UQgjh5+cnZsyYIR8vKysT9evXl68lhBDh4eFixIgRQgghMjIyBACRnJxcZZzbtm0TAMTFixflfcXFxcLNzU3s2rXLqO7AgQPFK6+8IoQQYty4caJ58+ZGx8eOHXtLWzcDIFatWnXb4zNnzhTt2rWTtydOnCgcHR3FmTNn5H0//fSTcHBwEDk5OUIIIRo3biyWL19u1M6UKVNEWFiYEEKIrKwsAUD89ttvt70uEdkW55ARkWLWrl0LDw8PlJWVwWAwoE+fPoiPj5ePt2jRwmje2O+//47jx4/D09PTqJ3i4mJkZmbi8uXLyMnJQWhoqHzMyckJjz766C3DlpXS09Ph6OiI8PDwasd9/PhxXL16FU899ZTR/tLSUrRp0wYAcPToUaM4ACAsLKza16i0cuVKzJ8/H5mZmSgsLER5eTk0Go1RnQYNGqBevXpG1zEYDMjIyICnpycyMzMxcOBADB48WK5TXl4OrVZrdjxEZBtMyIhIMZ06dcLChQuhUqng7+8PJyfjHznu7u5G24WFhWjXrh2SkpJuaatu3bp3FYOrq6vZ5xQWFgIA1q1bZ5QIARXz4qwlLS0Nffv2xaRJkxAZGQmtVosVK1Zg1qxZZse6ePHiWxJER0dHq8VKRMpiQkZEinF3d0dwcHC167dt2xYrV66Ej4/PLb1Elfz8/LB792507NgRQEVP0P79+9G2bdsq67do0QIGgwEpKSno3LnzLccre+j0er28r3nz5lCr1cjOzr5tz1pISIj8gEKlX3755c43eYNdu3YhMDAQ7777rrzv1KlTt9TLzs7G2bNn4e/vL1/HwcEBTZs2ha+vL/z9/XHixAn07dvXrOsTUc3BSf1EVGP07dsXderUwXPPPYcdO3YgKysL27dvx/Dhw3HmzBkAwIgRI/D+++9j9erV+OOPP/Dmm2+aXEOsYcOGiI6OxoABA7B69Wq5za+//hoAEBgYCEmSsHbtWpw/fx6FhYXw9PTE6NGjERcXh88//xyZmZn49ddf8eGHH8oT5YcOHYpjx45hzJgxyMjIwPLly5GYmGjW/T700EPIzs7GihUrkJmZifnz51f5gIKLiwuio6Px+++/Y8eOHRg+fDheeukl6HQ6AMCkSZOQkJCA+fPn488//8TBgwexbNkyzJ4926x4iMh2mJARUY3h5uaG1NRUNGjQAD179kRISAgGDhyI4uJiucfsP//5D1577TVER0cjLCwMnp6eeP755022u3DhQrzwwgt488030axZMwwePBhFRUUAgHr16mHSpEl4++234evri9jYWADAlClTMH78eCQkJCAkJARRUVFYt24dgoKCAFTM6/ruu++wevVqtGrVCosWLcL06dPNut9nn30WcXFxiI2NRevWrbFr1y6MHz/+lnrBwcHo2bMnnn76aXTp0gUtW7Y0WtZi0KBBWLJkCZYtW4YWLVogPDwciYmJcqxEVPNJ4nYzYYmIiIjonmAPGREREZGNMSEjIiIisjEmZEREREQ2xoSMiIiIyMaYkBERERHZGBMyIiIiIhtjQkZERERkY0zIiIiIiGyMCRkRERGRjTEhIyIiIrIxJmRERERENvZ/7ylenxF8OpYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_t08 = (first_run_lg.predict_proba(X_test)[:, 1] >= 0.8).astype(int)\n",
    "plot_confusion_matrix(y_test, y_pred_t08, first_run_lg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can use this model for predictions and expecct to have 94% precision - meaning that 94% of the tweets we classify as \"Business\" are actually \"Business\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d18874cd3773cfd573a514287f61a1082a06a599e2b06271f81ffa5d73d1385"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
